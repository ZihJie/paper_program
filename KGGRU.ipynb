{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/fchollet/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.compat.v1.set_random_seed(1234)\n",
    "\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os, json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取KG資料並轉呈DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_from_file(dict,filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as dict_file:\n",
    "            for line in dict_file:\n",
    "                (key, value) = line.strip().split('\\t')\n",
    "                value = value[1:-1].split(', ')\n",
    "                #print部分為檢查用\n",
    "                #print(key)\n",
    "                #print(type(value))\n",
    "                #print(\"-\"*50)\n",
    "                dict[key] = value\n",
    "    except IOError as ioerr:\n",
    "        print(\"檔案 %s 不存在\" % (filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = {}\n",
    "relation = {}\n",
    "load_dict_from_file (entity,'entityVector(20d).txt')\n",
    "load_dict_from_file (relation,'relationVector(20d).txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將每日相對應的tuple依日期做成DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取資料\n",
    "t = open('Workday_tuple_ex.txt','r')\n",
    "\n",
    "#建立之後要存每日tuple embedding 的df\n",
    "\n",
    "col = []\n",
    "\n",
    "col.append('Date')\n",
    "\n",
    "for i in range(20):\n",
    "    col.append('h'+str(i))\n",
    "for i in range(20):\n",
    "    col.append('r'+str(i))\n",
    "for i in range(20):\n",
    "    col.append('t'+str(i))\n",
    "    \n",
    "t_df = pd.DataFrame(columns=col)\n",
    "\n",
    "\n",
    "for lines in t :\n",
    "    dict = {}\n",
    "    triple = lines[15:].replace('\\n','').lower().split(\"-----\")\n",
    "    date = lines[:10].replace('/','-')\n",
    "    \n",
    "    dict['Date'] = date\n",
    "    \n",
    "    \n",
    "    for i in range(20):\n",
    "        dict['h'+str(i)] = float(entity[triple[0]][i][:11])\n",
    "    for i in range(0,20):\n",
    "        dict['r'+str(i)] = float(relation[triple[1]][i][:11])\n",
    "    for i in range(0,20):\n",
    "        dict['t'+str(i)] = float(entity[triple[2]][i][:11])\n",
    "        \n",
    "    #print(dict)\n",
    "    \n",
    "    new = pd.DataFrame.from_dict(dict,orient='index').T\n",
    "    t_df = t_df.append(new,ignore_index = True)\n",
    "    #print(date + 'is success')\n",
    "    #print('-'*50)\n",
    "\n",
    "\n",
    "t.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取股票基本資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Financedata_2010_2017.csv').drop(index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>h6</th>\n",
       "      <th>h7</th>\n",
       "      <th>h8</th>\n",
       "      <th>h9</th>\n",
       "      <th>...</th>\n",
       "      <th>t10</th>\n",
       "      <th>t11</th>\n",
       "      <th>t12</th>\n",
       "      <th>t13</th>\n",
       "      <th>t14</th>\n",
       "      <th>t15</th>\n",
       "      <th>t16</th>\n",
       "      <th>t17</th>\n",
       "      <th>t18</th>\n",
       "      <th>t19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>0.003753</td>\n",
       "      <td>-0.061194</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-0.008688</td>\n",
       "      <td>0.034293</td>\n",
       "      <td>-0.122504</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>-0.050838</td>\n",
       "      <td>0.027879</td>\n",
       "      <td>-0.017599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206682</td>\n",
       "      <td>0.163777</td>\n",
       "      <td>0.207068</td>\n",
       "      <td>-0.006461</td>\n",
       "      <td>-0.095581</td>\n",
       "      <td>-0.240886</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>0.194482</td>\n",
       "      <td>-0.215781</td>\n",
       "      <td>0.033561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>-0.001908</td>\n",
       "      <td>0.16936</td>\n",
       "      <td>-0.149103</td>\n",
       "      <td>-0.176466</td>\n",
       "      <td>-0.027815</td>\n",
       "      <td>-0.123676</td>\n",
       "      <td>-0.058595</td>\n",
       "      <td>-0.006972</td>\n",
       "      <td>-0.221047</td>\n",
       "      <td>-0.150802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217279</td>\n",
       "      <td>0.277375</td>\n",
       "      <td>-0.200983</td>\n",
       "      <td>-0.129322</td>\n",
       "      <td>-0.019745</td>\n",
       "      <td>-0.056881</td>\n",
       "      <td>-0.093435</td>\n",
       "      <td>-0.071449</td>\n",
       "      <td>0.157066</td>\n",
       "      <td>0.166301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-15</th>\n",
       "      <td>0.021459</td>\n",
       "      <td>-0.033728</td>\n",
       "      <td>-0.294758</td>\n",
       "      <td>0.110112</td>\n",
       "      <td>-0.247826</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>-0.197307</td>\n",
       "      <td>-0.042394</td>\n",
       "      <td>-0.206166</td>\n",
       "      <td>0.040407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134641</td>\n",
       "      <td>-0.104574</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.171218</td>\n",
       "      <td>0.094562</td>\n",
       "      <td>-0.223247</td>\n",
       "      <td>-0.105234</td>\n",
       "      <td>0.025836</td>\n",
       "      <td>-0.100109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-18</th>\n",
       "      <td>0.003753</td>\n",
       "      <td>-0.061194</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-0.008688</td>\n",
       "      <td>0.034293</td>\n",
       "      <td>-0.122504</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>-0.050838</td>\n",
       "      <td>0.027879</td>\n",
       "      <td>-0.017599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068993</td>\n",
       "      <td>-0.158613</td>\n",
       "      <td>0.174185</td>\n",
       "      <td>0.060032</td>\n",
       "      <td>-0.091786</td>\n",
       "      <td>-0.136601</td>\n",
       "      <td>0.108272</td>\n",
       "      <td>0.323887</td>\n",
       "      <td>0.080587</td>\n",
       "      <td>-0.029605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-20</th>\n",
       "      <td>0.08009</td>\n",
       "      <td>0.040884</td>\n",
       "      <td>-0.281486</td>\n",
       "      <td>0.069456</td>\n",
       "      <td>-0.01982</td>\n",
       "      <td>-0.192148</td>\n",
       "      <td>-0.061628</td>\n",
       "      <td>-0.016081</td>\n",
       "      <td>0.065825</td>\n",
       "      <td>-0.063559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>0.268101</td>\n",
       "      <td>-0.158374</td>\n",
       "      <td>0.048328</td>\n",
       "      <td>-0.071583</td>\n",
       "      <td>0.091998</td>\n",
       "      <td>0.077005</td>\n",
       "      <td>-0.057104</td>\n",
       "      <td>-0.207202</td>\n",
       "      <td>0.233467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-08</th>\n",
       "      <td>0.003753</td>\n",
       "      <td>-0.061194</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-0.008688</td>\n",
       "      <td>0.034293</td>\n",
       "      <td>-0.122504</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>-0.050838</td>\n",
       "      <td>0.027879</td>\n",
       "      <td>-0.017599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06842</td>\n",
       "      <td>-0.224826</td>\n",
       "      <td>0.058274</td>\n",
       "      <td>0.164628</td>\n",
       "      <td>0.099241</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.221877</td>\n",
       "      <td>0.273071</td>\n",
       "      <td>0.022025</td>\n",
       "      <td>0.283097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-15</th>\n",
       "      <td>0.003753</td>\n",
       "      <td>-0.061194</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-0.008688</td>\n",
       "      <td>0.034293</td>\n",
       "      <td>-0.122504</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>-0.050838</td>\n",
       "      <td>0.027879</td>\n",
       "      <td>-0.017599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189409</td>\n",
       "      <td>0.165701</td>\n",
       "      <td>0.04745</td>\n",
       "      <td>-0.1374</td>\n",
       "      <td>-0.003431</td>\n",
       "      <td>-0.162824</td>\n",
       "      <td>-0.231707</td>\n",
       "      <td>0.250417</td>\n",
       "      <td>0.209026</td>\n",
       "      <td>-0.044619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-20</th>\n",
       "      <td>0.003753</td>\n",
       "      <td>-0.061194</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-0.008688</td>\n",
       "      <td>0.034293</td>\n",
       "      <td>-0.122504</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>-0.050838</td>\n",
       "      <td>0.027879</td>\n",
       "      <td>-0.017599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179821</td>\n",
       "      <td>0.087551</td>\n",
       "      <td>-0.140082</td>\n",
       "      <td>0.116075</td>\n",
       "      <td>-0.169729</td>\n",
       "      <td>-0.094234</td>\n",
       "      <td>-0.165941</td>\n",
       "      <td>0.095547</td>\n",
       "      <td>0.104598</td>\n",
       "      <td>-0.085236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>-0.185496</td>\n",
       "      <td>-0.011414</td>\n",
       "      <td>-0.125117</td>\n",
       "      <td>0.149422</td>\n",
       "      <td>-0.219629</td>\n",
       "      <td>0.197519</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.056382</td>\n",
       "      <td>-0.024503</td>\n",
       "      <td>0.144826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>-0.154644</td>\n",
       "      <td>0.097905</td>\n",
       "      <td>0.026366</td>\n",
       "      <td>0.06594</td>\n",
       "      <td>-0.107328</td>\n",
       "      <td>0.137433</td>\n",
       "      <td>0.133538</td>\n",
       "      <td>0.214204</td>\n",
       "      <td>-0.243038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>-0.145049</td>\n",
       "      <td>0.182966</td>\n",
       "      <td>0.113749</td>\n",
       "      <td>-0.128842</td>\n",
       "      <td>-0.213464</td>\n",
       "      <td>-0.145179</td>\n",
       "      <td>-0.099398</td>\n",
       "      <td>-0.066657</td>\n",
       "      <td>-0.045808</td>\n",
       "      <td>-0.084848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102609</td>\n",
       "      <td>-0.034461</td>\n",
       "      <td>0.19808</td>\n",
       "      <td>-0.273266</td>\n",
       "      <td>-0.101901</td>\n",
       "      <td>0.029716</td>\n",
       "      <td>0.143222</td>\n",
       "      <td>0.340799</td>\n",
       "      <td>0.13217</td>\n",
       "      <td>0.20304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  h0        h1        h2        h3        h4        h5  \\\n",
       "Date                                                                     \n",
       "2010-01-05  0.003753 -0.061194  0.007576 -0.008688  0.034293 -0.122504   \n",
       "2010-01-07 -0.001908   0.16936 -0.149103 -0.176466 -0.027815 -0.123676   \n",
       "2010-01-15  0.021459 -0.033728 -0.294758  0.110112 -0.247826 -0.063979   \n",
       "2010-01-18  0.003753 -0.061194  0.007576 -0.008688  0.034293 -0.122504   \n",
       "2010-01-20   0.08009  0.040884 -0.281486  0.069456  -0.01982 -0.192148   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2017-12-08  0.003753 -0.061194  0.007576 -0.008688  0.034293 -0.122504   \n",
       "2017-12-15  0.003753 -0.061194  0.007576 -0.008688  0.034293 -0.122504   \n",
       "2017-12-20  0.003753 -0.061194  0.007576 -0.008688  0.034293 -0.122504   \n",
       "2017-12-26 -0.185496 -0.011414 -0.125117  0.149422 -0.219629  0.197519   \n",
       "2017-12-27 -0.145049  0.182966  0.113749 -0.128842 -0.213464 -0.145179   \n",
       "\n",
       "                  h6        h7        h8        h9  ...       t10       t11  \\\n",
       "Date                                                ...                       \n",
       "2010-01-05  0.094773 -0.050838  0.027879 -0.017599  ...  0.206682  0.163777   \n",
       "2010-01-07 -0.058595 -0.006972 -0.221047 -0.150802  ... -0.217279  0.277375   \n",
       "2010-01-15 -0.197307 -0.042394 -0.206166  0.040407  ... -0.134641 -0.104574   \n",
       "2010-01-18  0.094773 -0.050838  0.027879 -0.017599  ... -0.068993 -0.158613   \n",
       "2010-01-20 -0.061628 -0.016081  0.065825 -0.063559  ... -0.000848  0.268101   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2017-12-08  0.094773 -0.050838  0.027879 -0.017599  ...   0.06842 -0.224826   \n",
       "2017-12-15  0.094773 -0.050838  0.027879 -0.017599  ...  0.189409  0.165701   \n",
       "2017-12-20  0.094773 -0.050838  0.027879 -0.017599  ... -0.179821  0.087551   \n",
       "2017-12-26  0.002816  0.056382 -0.024503  0.144826  ...  0.006759 -0.154644   \n",
       "2017-12-27 -0.099398 -0.066657 -0.045808 -0.084848  ... -0.102609 -0.034461   \n",
       "\n",
       "                 t12       t13       t14       t15       t16       t17  \\\n",
       "Date                                                                     \n",
       "2010-01-05  0.207068 -0.006461 -0.095581 -0.240886  0.006775  0.194482   \n",
       "2010-01-07 -0.200983 -0.129322 -0.019745 -0.056881 -0.093435 -0.071449   \n",
       "2010-01-15  0.004896  0.023171  0.171218  0.094562 -0.223247 -0.105234   \n",
       "2010-01-18  0.174185  0.060032 -0.091786 -0.136601  0.108272  0.323887   \n",
       "2010-01-20 -0.158374  0.048328 -0.071583  0.091998  0.077005 -0.057104   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2017-12-08  0.058274  0.164628  0.099241  0.005491  0.221877  0.273071   \n",
       "2017-12-15   0.04745   -0.1374 -0.003431 -0.162824 -0.231707  0.250417   \n",
       "2017-12-20 -0.140082  0.116075 -0.169729 -0.094234 -0.165941  0.095547   \n",
       "2017-12-26  0.097905  0.026366   0.06594 -0.107328  0.137433  0.133538   \n",
       "2017-12-27   0.19808 -0.273266 -0.101901  0.029716  0.143222  0.340799   \n",
       "\n",
       "                 t18       t19  \n",
       "Date                            \n",
       "2010-01-05 -0.215781  0.033561  \n",
       "2010-01-07  0.157066  0.166301  \n",
       "2010-01-15  0.025836 -0.100109  \n",
       "2010-01-18  0.080587 -0.029605  \n",
       "2010-01-20 -0.207202  0.233467  \n",
       "...              ...       ...  \n",
       "2017-12-08  0.022025  0.283097  \n",
       "2017-12-15  0.209026 -0.044619  \n",
       "2017-12-20  0.104598 -0.085236  \n",
       "2017-12-26  0.214204 -0.243038  \n",
       "2017-12-27   0.13217   0.20304  \n",
       "\n",
       "[1008 rows x 60 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>7.622500</td>\n",
       "      <td>7.660714</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>7.643214</td>\n",
       "      <td>6.593423</td>\n",
       "      <td>493729600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>7.664286</td>\n",
       "      <td>7.699643</td>\n",
       "      <td>7.616071</td>\n",
       "      <td>7.656429</td>\n",
       "      <td>6.604822</td>\n",
       "      <td>601904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>7.656429</td>\n",
       "      <td>7.686786</td>\n",
       "      <td>7.526786</td>\n",
       "      <td>7.534643</td>\n",
       "      <td>6.499765</td>\n",
       "      <td>552160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.466071</td>\n",
       "      <td>7.520714</td>\n",
       "      <td>6.487749</td>\n",
       "      <td>477131200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>7.510714</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.466429</td>\n",
       "      <td>7.570714</td>\n",
       "      <td>6.530882</td>\n",
       "      <td>447610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>43.669998</td>\n",
       "      <td>43.855000</td>\n",
       "      <td>43.625000</td>\n",
       "      <td>43.752499</td>\n",
       "      <td>42.103676</td>\n",
       "      <td>65397600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>42.700001</td>\n",
       "      <td>42.867500</td>\n",
       "      <td>42.419998</td>\n",
       "      <td>42.642502</td>\n",
       "      <td>41.035507</td>\n",
       "      <td>132742000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>42.525002</td>\n",
       "      <td>42.695000</td>\n",
       "      <td>42.427502</td>\n",
       "      <td>42.650002</td>\n",
       "      <td>41.042721</td>\n",
       "      <td>85992800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>42.750000</td>\n",
       "      <td>42.962502</td>\n",
       "      <td>42.619999</td>\n",
       "      <td>42.770000</td>\n",
       "      <td>41.158192</td>\n",
       "      <td>65920800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>42.630001</td>\n",
       "      <td>42.647499</td>\n",
       "      <td>42.305000</td>\n",
       "      <td>42.307499</td>\n",
       "      <td>40.713127</td>\n",
       "      <td>103999600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Open       High        Low      Close  Adj Close  \\\n",
       "1     2010-01-04   7.622500   7.660714   7.585000   7.643214   6.593423   \n",
       "2     2010-01-05   7.664286   7.699643   7.616071   7.656429   6.604822   \n",
       "3     2010-01-06   7.656429   7.686786   7.526786   7.534643   6.499765   \n",
       "4     2010-01-07   7.562500   7.571429   7.466071   7.520714   6.487749   \n",
       "5     2010-01-08   7.510714   7.571429   7.466429   7.570714   6.530882   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "2009  2017-12-22  43.669998  43.855000  43.625000  43.752499  42.103676   \n",
       "2010  2017-12-26  42.700001  42.867500  42.419998  42.642502  41.035507   \n",
       "2011  2017-12-27  42.525002  42.695000  42.427502  42.650002  41.042721   \n",
       "2012  2017-12-28  42.750000  42.962502  42.619999  42.770000  41.158192   \n",
       "2013  2017-12-29  42.630001  42.647499  42.305000  42.307499  40.713127   \n",
       "\n",
       "         Volume  \n",
       "1     493729600  \n",
       "2     601904800  \n",
       "3     552160000  \n",
       "4     477131200  \n",
       "5     447610800  \n",
       "...         ...  \n",
       "2009   65397600  \n",
       "2010  132742000  \n",
       "2011   85992800  \n",
       "2012   65920800  \n",
       "2013  103999600  \n",
       "\n",
       "[2013 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整理之後要跟股票資料concate的DF(日期比照所有股票資料，無tuple的zero padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero padding\n",
    "f_col = col.copy()\n",
    "\n",
    "f_df =  pd.DataFrame(index = range(0,2014),columns = f_col)\n",
    "for i in range(1,2014):\n",
    "    if df['Date'][i] in t_df.index :\n",
    "        for j in range(20):\n",
    "            f_df['h'+str(j)][i] = t_df.loc[df['Date'][i]]['h'+str(j)]\n",
    "            f_df['r'+str(j)][i] = t_df.loc[df['Date'][i]]['r'+str(j)]\n",
    "            f_df['t'+str(j)][i] = t_df.loc[df['Date'][i]]['t'+str(j)]\n",
    "    else:\n",
    "        for j in range(20):\n",
    "            f_df['h'+str(j)][i] = float(0)\n",
    "            f_df['r'+str(j)][i] = float(0)\n",
    "            f_df['t'+str(j)][i] = float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>h6</th>\n",
       "      <th>h7</th>\n",
       "      <th>h8</th>\n",
       "      <th>...</th>\n",
       "      <th>t10</th>\n",
       "      <th>t11</th>\n",
       "      <th>t12</th>\n",
       "      <th>t13</th>\n",
       "      <th>t14</th>\n",
       "      <th>t15</th>\n",
       "      <th>t16</th>\n",
       "      <th>t17</th>\n",
       "      <th>t18</th>\n",
       "      <th>t19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>-0.061194</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-0.008688</td>\n",
       "      <td>0.034293</td>\n",
       "      <td>-0.122504</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>-0.050838</td>\n",
       "      <td>0.027879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206682</td>\n",
       "      <td>0.163777</td>\n",
       "      <td>0.207068</td>\n",
       "      <td>-0.006461</td>\n",
       "      <td>-0.095581</td>\n",
       "      <td>-0.240886</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>0.194482</td>\n",
       "      <td>-0.215781</td>\n",
       "      <td>0.033561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001908</td>\n",
       "      <td>0.16936</td>\n",
       "      <td>-0.149103</td>\n",
       "      <td>-0.176466</td>\n",
       "      <td>-0.027815</td>\n",
       "      <td>-0.123676</td>\n",
       "      <td>-0.058595</td>\n",
       "      <td>-0.006972</td>\n",
       "      <td>-0.221047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217279</td>\n",
       "      <td>0.277375</td>\n",
       "      <td>-0.200983</td>\n",
       "      <td>-0.129322</td>\n",
       "      <td>-0.019745</td>\n",
       "      <td>-0.056881</td>\n",
       "      <td>-0.093435</td>\n",
       "      <td>-0.071449</td>\n",
       "      <td>0.157066</td>\n",
       "      <td>0.166301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.185496</td>\n",
       "      <td>-0.011414</td>\n",
       "      <td>-0.125117</td>\n",
       "      <td>0.149422</td>\n",
       "      <td>-0.219629</td>\n",
       "      <td>0.197519</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.056382</td>\n",
       "      <td>-0.024503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>-0.154644</td>\n",
       "      <td>0.097905</td>\n",
       "      <td>0.026366</td>\n",
       "      <td>0.06594</td>\n",
       "      <td>-0.107328</td>\n",
       "      <td>0.137433</td>\n",
       "      <td>0.133538</td>\n",
       "      <td>0.214204</td>\n",
       "      <td>-0.243038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.145049</td>\n",
       "      <td>0.182966</td>\n",
       "      <td>0.113749</td>\n",
       "      <td>-0.128842</td>\n",
       "      <td>-0.213464</td>\n",
       "      <td>-0.145179</td>\n",
       "      <td>-0.099398</td>\n",
       "      <td>-0.066657</td>\n",
       "      <td>-0.045808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102609</td>\n",
       "      <td>-0.034461</td>\n",
       "      <td>0.19808</td>\n",
       "      <td>-0.273266</td>\n",
       "      <td>-0.101901</td>\n",
       "      <td>0.029716</td>\n",
       "      <td>0.143222</td>\n",
       "      <td>0.340799</td>\n",
       "      <td>0.13217</td>\n",
       "      <td>0.20304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2014 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date        h0        h1        h2        h3        h4        h5  \\\n",
       "0     NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1     NaN       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2     NaN  0.003753 -0.061194  0.007576 -0.008688  0.034293 -0.122504   \n",
       "3     NaN       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4     NaN -0.001908   0.16936 -0.149103 -0.176466 -0.027815 -0.123676   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "2009  NaN       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2010  NaN -0.185496 -0.011414 -0.125117  0.149422 -0.219629  0.197519   \n",
       "2011  NaN -0.145049  0.182966  0.113749 -0.128842 -0.213464 -0.145179   \n",
       "2012  NaN       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2013  NaN       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "            h6        h7        h8  ...       t10       t11       t12  \\\n",
       "0          NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "1          0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "2     0.094773 -0.050838  0.027879  ...  0.206682  0.163777  0.207068   \n",
       "3          0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "4    -0.058595 -0.006972 -0.221047  ... -0.217279  0.277375 -0.200983   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2009       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "2010  0.002816  0.056382 -0.024503  ...  0.006759 -0.154644  0.097905   \n",
       "2011 -0.099398 -0.066657 -0.045808  ... -0.102609 -0.034461   0.19808   \n",
       "2012       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "2013       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "           t13       t14       t15       t16       t17       t18       t19  \n",
       "0          NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2    -0.006461 -0.095581 -0.240886  0.006775  0.194482 -0.215781  0.033561  \n",
       "3          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "4    -0.129322 -0.019745 -0.056881 -0.093435 -0.071449  0.157066  0.166301  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2009       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2010  0.026366   0.06594 -0.107328  0.137433  0.133538  0.214204 -0.243038  \n",
       "2011 -0.273266 -0.101901  0.029716  0.143222  0.340799   0.13217   0.20304  \n",
       "2012       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2013       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[2014 rows x 61 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_df = f_df.drop(index = 0)\n",
    "d_df = d_df.drop(columns = 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將df轉成array\n",
    "t_array = d_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_df.to_csv(\"f_df_notech.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 後續在colab中，加上所需的技術指標，之後再轉成csv，在進行讀取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_csv('f_df_withtech.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage change of adj price 取代 adj close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df = pd.DataFrame()\n",
    "\n",
    "#基本資料\n",
    "tech_df['Open'] = total_df['Open']\n",
    "tech_df['High'] = total_df['High']\n",
    "tech_df['Low'] = total_df['Low']\n",
    "tech_df['Close'] = total_df['Close']\n",
    "tech_df['Adj Close'] = total_df['Adj Close']\n",
    "tech_df['Volume'] = total_df['Volume']\n",
    "#技術指標\n",
    "tech_df['Adx'] = total_df['Adx']\n",
    "tech_df['Rsi'] = total_df['Rsi']\n",
    "tech_df['Sar'] = total_df['Sar']\n",
    "tech_df['Adj-1'] = total_df['Adj Close'].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAP = []\n",
    "\n",
    "for index, row in tech_df.iterrows():\n",
    "    if (index == 0):\n",
    "        PCAP.append(0)\n",
    "    else:\n",
    "        PCAP.append((row['Adj Close']-row['Adj-1'])/row['Adj-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df['PCAP'] = PCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df = tech_df.drop(columns=['Adj-1','Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adx</th>\n",
       "      <th>Rsi</th>\n",
       "      <th>Sar</th>\n",
       "      <th>PCAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.622500</td>\n",
       "      <td>7.660714</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>7.643214</td>\n",
       "      <td>493729600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.664286</td>\n",
       "      <td>7.699643</td>\n",
       "      <td>7.616071</td>\n",
       "      <td>7.656429</td>\n",
       "      <td>601904800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.656429</td>\n",
       "      <td>7.686786</td>\n",
       "      <td>7.526786</td>\n",
       "      <td>7.534643</td>\n",
       "      <td>552160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.699643</td>\n",
       "      <td>-0.015906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.562500</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.466071</td>\n",
       "      <td>7.520714</td>\n",
       "      <td>477131200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.699643</td>\n",
       "      <td>-0.001849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.510714</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.466429</td>\n",
       "      <td>7.570714</td>\n",
       "      <td>447610800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.690300</td>\n",
       "      <td>0.006648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>43.669998</td>\n",
       "      <td>43.855000</td>\n",
       "      <td>43.625000</td>\n",
       "      <td>43.752499</td>\n",
       "      <td>65397600</td>\n",
       "      <td>15.311032</td>\n",
       "      <td>60.293137</td>\n",
       "      <td>42.316421</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>42.700001</td>\n",
       "      <td>42.867500</td>\n",
       "      <td>42.419998</td>\n",
       "      <td>42.642502</td>\n",
       "      <td>132742000</td>\n",
       "      <td>15.205238</td>\n",
       "      <td>46.549483</td>\n",
       "      <td>44.299999</td>\n",
       "      <td>-0.025370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>42.525002</td>\n",
       "      <td>42.695000</td>\n",
       "      <td>42.427502</td>\n",
       "      <td>42.650002</td>\n",
       "      <td>85992800</td>\n",
       "      <td>15.107000</td>\n",
       "      <td>46.637989</td>\n",
       "      <td>44.262399</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>42.750000</td>\n",
       "      <td>42.962502</td>\n",
       "      <td>42.619999</td>\n",
       "      <td>42.770000</td>\n",
       "      <td>65920800</td>\n",
       "      <td>14.517060</td>\n",
       "      <td>48.118303</td>\n",
       "      <td>44.225551</td>\n",
       "      <td>0.002813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>42.630001</td>\n",
       "      <td>42.647499</td>\n",
       "      <td>42.305000</td>\n",
       "      <td>42.307499</td>\n",
       "      <td>103999600</td>\n",
       "      <td>14.449465</td>\n",
       "      <td>43.149848</td>\n",
       "      <td>44.189440</td>\n",
       "      <td>-0.010814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open       High        Low      Close     Volume        Adx  \\\n",
       "0      7.622500   7.660714   7.585000   7.643214  493729600   0.000000   \n",
       "1      7.664286   7.699643   7.616071   7.656429  601904800   0.000000   \n",
       "2      7.656429   7.686786   7.526786   7.534643  552160000   0.000000   \n",
       "3      7.562500   7.571429   7.466071   7.520714  477131200   0.000000   \n",
       "4      7.510714   7.571429   7.466429   7.570714  447610800   0.000000   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2008  43.669998  43.855000  43.625000  43.752499   65397600  15.311032   \n",
       "2009  42.700001  42.867500  42.419998  42.642502  132742000  15.205238   \n",
       "2010  42.525002  42.695000  42.427502  42.650002   85992800  15.107000   \n",
       "2011  42.750000  42.962502  42.619999  42.770000   65920800  14.517060   \n",
       "2012  42.630001  42.647499  42.305000  42.307499  103999600  14.449465   \n",
       "\n",
       "            Rsi        Sar      PCAP  \n",
       "0      0.000000   0.000000  0.000000  \n",
       "1      0.000000   7.585000  0.001729  \n",
       "2      0.000000   7.699643 -0.015906  \n",
       "3      0.000000   7.699643 -0.001849  \n",
       "4      0.000000   7.690300  0.006648  \n",
       "...         ...        ...       ...  \n",
       "2008  60.293137  42.316421  0.000000  \n",
       "2009  46.549483  44.299999 -0.025370  \n",
       "2010  46.637989  44.262399  0.000176  \n",
       "2011  48.118303  44.225551  0.002813  \n",
       "2012  43.149848  44.189440 -0.010814  \n",
       "\n",
       "[2013 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.95924134, -0.96457297, -0.95718584, ..., -1.        ,\n",
       "        -1.        ,  0.16399997],\n",
       "       [-0.95697694, -0.96248562, -0.95550269, ..., -1.        ,\n",
       "        -0.65756207,  0.18028724],\n",
       "       [-0.95740273, -0.963175  , -0.96033934, ..., -1.        ,\n",
       "        -0.65238631,  0.01415333],\n",
       "       ...,\n",
       "       [ 0.93212703,  0.91394104,  0.93025536, ...,  0.03178927,\n",
       "         0.99830248,  0.16565603],\n",
       "       [ 0.94431971,  0.9282843 ,  0.94068306, ...,  0.06453879,\n",
       "         0.99663891,  0.19050441],\n",
       "       [ 0.93781697,  0.91139409,  0.92361938, ..., -0.04538015,\n",
       "         0.99500862,  0.06212937]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將股票基本資料及技術指標進行標準化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mmc = MinMaxScaler(feature_range=(-1,1)) # default (0, 1) for sigmoid function\n",
    "mmc.fit(tech_df)\n",
    "tech_array = mmc.transform(tech_df)\n",
    "tech_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將 標準化完的array 跟 每日tuple的array 合在一起"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將整理好的 array 再轉乘df 再進行合併"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tea_df  = pd.DataFrame(tech_array)\n",
    "ta_df  = pd.DataFrame(t_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "taa_df = pd.concat([tea_df, ta_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_array = taa_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 69)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y的製作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = total_df\n",
    "total_df['T+1'] = tmp['Adj Close'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [0], [0], [1], [0], [0], [1], [0], [0], [1]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the trend on T+1 and T+30\n",
    "\n",
    "\n",
    "y = []\n",
    "\n",
    "for index, row in total_df.iterrows():\n",
    "    _tmp = []\n",
    "    if (row['T+1']-row['Adj Close'] > 0):\n",
    "        _tmp.append(1)\n",
    "    else:\n",
    "        _tmp.append(0)\n",
    "        \n",
    "    y.append(_tmp)\n",
    "    \n",
    "#djia.head(5)\n",
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.asarray(y)\n",
    "y.reshape(2013,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windows size 設定5天"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 69)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5天做一個 window\n",
    "def train_windows(df, df1, ref_day=5, predict_day=1):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for i in range(df.shape[0]-ref_day):\n",
    "        X_train.append(np.array(df.iloc[i:i+ref_day,:]))\n",
    "        Y_train.append(df1.iloc[i])\n",
    "    return np.array(X_train), np.array(Y_train)\n",
    "X, Y=train_windows(pd.DataFrame(final_array),pd.DataFrame(y),5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4d1177d5c857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m \u001b[0;31m#转换为张量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_to_floatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_to_floatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K #转换为张量\n",
    "\n",
    "X = K.cast_to_floatx(X)\n",
    "#\n",
    "Y = K.cast_to_floatx(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 切割成train,test,valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#分割資料\n",
    "_X_train, X_test_std, _y_train, y_test = train_test_split(X, Y, train_size = 0.8, shuffle = False, stratify = None)\n",
    "\n",
    "#X_train_std, X_validate_std, y_train, y_validate = train_test_split(_X_train, _y_train, train_size = 0.8, shuffle = False, stratify = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 5, 69)\n",
      "(402, 5, 69)\n"
     ]
    }
   ],
   "source": [
    "print(_X_train.shape)\n",
    "print(X_test_std.shape)\n",
    "#print(X_validate_std.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "config.gpu_options.allow_growth = True \n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, TimeDistributed, LSTM, GRU\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "    \n",
    "def create_GRU_model(optimizer='adam', kernel_init='normal', recurrent_init='normal', bias_init='zero', batch_size=1):\n",
    "    model = Sequential()\n",
    "    #input method: batch_input_shape=(batch, timesteps/lags, features)\n",
    "    #  or input_shape=(timesteps/lags, features) , model.fit(X, y, epochs=n, batch_size=b, verbose=2)\n",
    "    model.add(GRU(64, input_shape = (_X_train.shape[1], _X_train.shape[2]), return_sequences=True, activation='sigmoid', \n",
    "                   recurrent_activation='hard_sigmoid', use_bias=True, \n",
    "                   kernel_initializer=kernel_init, recurrent_initializer=recurrent_init, bias_initializer=bias_init,\n",
    "                   kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, \n",
    "                   activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
    "                   dropout=0.0, recurrent_dropout=0.0, implementation=1, return_state=False, \n",
    "                   go_backwards=False, stateful=False, unroll=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(128, return_sequences=True, activation='sigmoid', recurrent_activation='hard_sigmoid', use_bias=True, \n",
    "                   kernel_initializer=kernel_init, recurrent_initializer=recurrent_init, bias_initializer=bias_init, \n",
    "                   kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
    "                   kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, \n",
    "                   implementation=1, return_state=False, go_backwards=False, stateful=False, unroll=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    \n",
    "    # The last layer of LSTM, return_sequences = False\n",
    "    model.add(GRU(256, return_state=False, activation='sigmoid', recurrent_activation='hard_sigmoid', use_bias=True, \n",
    "                    kernel_initializer=kernel_init, recurrent_initializer=recurrent_init, bias_initializer=bias_init, \n",
    "                    kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
    "                    kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, \n",
    "                    implementation=1, return_sequences=False, go_backwards=False, stateful=False, unroll=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=kernel_init))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.8491 - accuracy: 0.5112\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.8023 - accuracy: 0.5286\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.8057 - accuracy: 0.5237\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.7998 - accuracy: 0.5286\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.7734 - accuracy: 0.5423\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 0s 276us/step - loss: 0.7622 - accuracy: 0.5486\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.7504 - accuracy: 0.5511\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.7421 - accuracy: 0.5704\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.7285 - accuracy: 0.5635\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.7508 - accuracy: 0.5560\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.7386 - accuracy: 0.5710\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 0s 274us/step - loss: 0.7470 - accuracy: 0.5442\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.7099 - accuracy: 0.5803\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.7295 - accuracy: 0.5585\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.7099 - accuracy: 0.5822\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.7156 - accuracy: 0.5760\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.7283 - accuracy: 0.5585\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.7363 - accuracy: 0.5598\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 0s 275us/step - loss: 0.7254 - accuracy: 0.5660\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.7020 - accuracy: 0.5872\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6961 - accuracy: 0.5897\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.7197 - accuracy: 0.5691\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.7106 - accuracy: 0.5940\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.7177 - accuracy: 0.5592\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.7083 - accuracy: 0.5704\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.7040 - accuracy: 0.5909\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6936 - accuracy: 0.5722\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6941 - accuracy: 0.6002\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.7028 - accuracy: 0.5685\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 0s 274us/step - loss: 0.6881 - accuracy: 0.5834\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.7005 - accuracy: 0.5816\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6800 - accuracy: 0.6002\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6968 - accuracy: 0.5890\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6942 - accuracy: 0.5797\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.7091 - accuracy: 0.5679\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6805 - accuracy: 0.6152\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 0s 274us/step - loss: 0.6963 - accuracy: 0.5834\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.6951 - accuracy: 0.5747\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.7045 - accuracy: 0.5834\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6804 - accuracy: 0.5996\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6827 - accuracy: 0.5959\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6918 - accuracy: 0.5965\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6892 - accuracy: 0.5928\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6868 - accuracy: 0.5965\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6858 - accuracy: 0.5884\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6983 - accuracy: 0.5934\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.6752 - accuracy: 0.6052\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6984 - accuracy: 0.5872\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6844 - accuracy: 0.5996\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6738 - accuracy: 0.6065\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6876 - accuracy: 0.5953\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.6868 - accuracy: 0.6002\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6841 - accuracy: 0.6177\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6928 - accuracy: 0.5978\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6761 - accuracy: 0.6171\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6992 - accuracy: 0.5884\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6941 - accuracy: 0.6015\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6932 - accuracy: 0.5909\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6851 - accuracy: 0.6009\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6632 - accuracy: 0.6027\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6679 - accuracy: 0.6214\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6784 - accuracy: 0.6034\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6707 - accuracy: 0.6183\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6477 - accuracy: 0.6339\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6713 - accuracy: 0.6208\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.6849 - accuracy: 0.6002\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6627 - accuracy: 0.6233\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6682 - accuracy: 0.6196\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6638 - accuracy: 0.6270\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6796 - accuracy: 0.6077\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6803 - accuracy: 0.6096\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6551 - accuracy: 0.6314\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6614 - accuracy: 0.6121\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6749 - accuracy: 0.6071\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6614 - accuracy: 0.6239\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6645 - accuracy: 0.6208\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6580 - accuracy: 0.6177\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6635 - accuracy: 0.6208\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6648 - accuracy: 0.6208\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6652 - accuracy: 0.6196\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 0s 274us/step - loss: 0.6584 - accuracy: 0.6370\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6570 - accuracy: 0.6264\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6525 - accuracy: 0.6339\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6533 - accuracy: 0.6208\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6470 - accuracy: 0.6239\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6511 - accuracy: 0.6370\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6586 - accuracy: 0.6158\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6574 - accuracy: 0.6258\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6536 - accuracy: 0.6339\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6508 - accuracy: 0.6276\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.6515 - accuracy: 0.6333\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 0s 274us/step - loss: 0.6348 - accuracy: 0.6469\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6648 - accuracy: 0.6301\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6604 - accuracy: 0.6146\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 0s 274us/step - loss: 0.6512 - accuracy: 0.6264\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6448 - accuracy: 0.6283\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6454 - accuracy: 0.6370\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6526 - accuracy: 0.6283\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6464 - accuracy: 0.6488\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6502 - accuracy: 0.6326\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.6371 - accuracy: 0.6364\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6422 - accuracy: 0.6426\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6299 - accuracy: 0.6613\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6398 - accuracy: 0.6507\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6427 - accuracy: 0.6407\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6524 - accuracy: 0.6345\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6464 - accuracy: 0.6407\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6545 - accuracy: 0.6420\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6248 - accuracy: 0.6569\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6441 - accuracy: 0.6482\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6364 - accuracy: 0.6550\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6390 - accuracy: 0.6494\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6333 - accuracy: 0.6507\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6216 - accuracy: 0.6382\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 0s 275us/step - loss: 0.6253 - accuracy: 0.6544\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6223 - accuracy: 0.6563\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.6232 - accuracy: 0.6650\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6295 - accuracy: 0.6569\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.6481 - accuracy: 0.6420\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6295 - accuracy: 0.6681\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6253 - accuracy: 0.6438\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6450 - accuracy: 0.6364\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6209 - accuracy: 0.6588\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6116 - accuracy: 0.6588\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.6198 - accuracy: 0.6625\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6287 - accuracy: 0.6563\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6379 - accuracy: 0.6445\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6040 - accuracy: 0.6694\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6270 - accuracy: 0.6526\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6224 - accuracy: 0.6600\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6099 - accuracy: 0.6625\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6099 - accuracy: 0.6706\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.6074 - accuracy: 0.6694\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6054 - accuracy: 0.6712\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6164 - accuracy: 0.6681\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6172 - accuracy: 0.6631\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6274 - accuracy: 0.6606\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6195 - accuracy: 0.6550\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6155 - accuracy: 0.6519\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6146 - accuracy: 0.6687\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5930 - accuracy: 0.6887\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.5958 - accuracy: 0.6843\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6025 - accuracy: 0.6812\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.6045 - accuracy: 0.6687\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6080 - accuracy: 0.6831\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5760 - accuracy: 0.6949\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5992 - accuracy: 0.6762\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6019 - accuracy: 0.6712\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.5993 - accuracy: 0.6806\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5946 - accuracy: 0.6912\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5935 - accuracy: 0.6880\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5833 - accuracy: 0.6912\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5904 - accuracy: 0.6936\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.6061 - accuracy: 0.6837\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.6000 - accuracy: 0.6694\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 0s 269us/step - loss: 0.5817 - accuracy: 0.6949\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5958 - accuracy: 0.6849\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5987 - accuracy: 0.6775\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5886 - accuracy: 0.6837\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5836 - accuracy: 0.6874\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5800 - accuracy: 0.7042\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5768 - accuracy: 0.7130\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5764 - accuracy: 0.6837\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5733 - accuracy: 0.7011\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 0s 269us/step - loss: 0.5812 - accuracy: 0.6936\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.5644 - accuracy: 0.7067\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5689 - accuracy: 0.7024\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5667 - accuracy: 0.7011\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5905 - accuracy: 0.6768\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.5778 - accuracy: 0.7049\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5706 - accuracy: 0.7049\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5562 - accuracy: 0.7161\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5718 - accuracy: 0.7049\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5725 - accuracy: 0.7042\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5817 - accuracy: 0.6968\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5694 - accuracy: 0.7030\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5670 - accuracy: 0.7086\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5601 - accuracy: 0.7098\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5620 - accuracy: 0.7073\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5587 - accuracy: 0.7179\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5510 - accuracy: 0.7229\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5621 - accuracy: 0.7042\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.5531 - accuracy: 0.7192\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5440 - accuracy: 0.7260\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5693 - accuracy: 0.7092\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5366 - accuracy: 0.7347\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5520 - accuracy: 0.7092\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.5542 - accuracy: 0.7242\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5457 - accuracy: 0.7167\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5530 - accuracy: 0.7279\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5356 - accuracy: 0.7354\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5378 - accuracy: 0.7273\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5295 - accuracy: 0.7379\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5288 - accuracy: 0.7341\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5631 - accuracy: 0.7061\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5302 - accuracy: 0.7403\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5298 - accuracy: 0.7435\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.5301 - accuracy: 0.7316\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5226 - accuracy: 0.7447\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5140 - accuracy: 0.7428\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5228 - accuracy: 0.7422\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5407 - accuracy: 0.7217\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.5139 - accuracy: 0.7447\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.5309 - accuracy: 0.7347\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5035 - accuracy: 0.7628\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.5158 - accuracy: 0.7584\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5104 - accuracy: 0.7410\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5168 - accuracy: 0.7372\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5333 - accuracy: 0.7323\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4955 - accuracy: 0.7615\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 0s 274us/step - loss: 0.5081 - accuracy: 0.7347\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5217 - accuracy: 0.7466\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.5045 - accuracy: 0.7528\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.5047 - accuracy: 0.7553\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5001 - accuracy: 0.7453\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4974 - accuracy: 0.7559\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5193 - accuracy: 0.7460\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.5027 - accuracy: 0.7565\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4874 - accuracy: 0.7540\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4946 - accuracy: 0.7584\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.4749 - accuracy: 0.7684\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4869 - accuracy: 0.7565\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.4985 - accuracy: 0.7553\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4950 - accuracy: 0.7522\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.4763 - accuracy: 0.7796\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.4873 - accuracy: 0.7684\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.4728 - accuracy: 0.7765\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.4668 - accuracy: 0.7790\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4894 - accuracy: 0.7634\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4919 - accuracy: 0.7553\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.4661 - accuracy: 0.7783\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.4767 - accuracy: 0.7808\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4757 - accuracy: 0.7721\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.4652 - accuracy: 0.7740\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.4792 - accuracy: 0.7621\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4686 - accuracy: 0.7677\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4798 - accuracy: 0.7690\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.4678 - accuracy: 0.7777\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.4616 - accuracy: 0.7783\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.4860 - accuracy: 0.7746\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4601 - accuracy: 0.7852\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.4721 - accuracy: 0.7752\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 0s 273us/step - loss: 0.4410 - accuracy: 0.7883\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 0s 270us/step - loss: 0.4744 - accuracy: 0.7821\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.4445 - accuracy: 0.7908\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 0s 272us/step - loss: 0.4685 - accuracy: 0.7877\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 0s 271us/step - loss: 0.4419 - accuracy: 0.7852\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 0s 280us/step - loss: 0.4527 - accuracy: 0.7783\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 0s 283us/step - loss: 0.4469 - accuracy: 0.7833\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 0s 281us/step - loss: 0.4474 - accuracy: 0.7914\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 0s 280us/step - loss: 0.4575 - accuracy: 0.7827\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 0s 281us/step - loss: 0.4681 - accuracy: 0.7696\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 0s 292us/step - loss: 0.4396 - accuracy: 0.7983\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 0s 285us/step - loss: 0.4398 - accuracy: 0.7889\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 0s 282us/step - loss: 0.4601 - accuracy: 0.7727\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 0s 286us/step - loss: 0.4372 - accuracy: 0.7877\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 0s 287us/step - loss: 0.4201 - accuracy: 0.8095\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 0s 288us/step - loss: 0.4287 - accuracy: 0.8020\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 0s 298us/step - loss: 0.4242 - accuracy: 0.8076\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 0s 295us/step - loss: 0.4051 - accuracy: 0.8057\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 0s 294us/step - loss: 0.4318 - accuracy: 0.7970\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 0s 294us/step - loss: 0.4276 - accuracy: 0.8020\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 0s 296us/step - loss: 0.4221 - accuracy: 0.7933\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 0s 293us/step - loss: 0.4188 - accuracy: 0.8126\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 0s 292us/step - loss: 0.4257 - accuracy: 0.8020\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 0s 294us/step - loss: 0.4130 - accuracy: 0.8082\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 0s 299us/step - loss: 0.4225 - accuracy: 0.8120\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 0s 292us/step - loss: 0.3847 - accuracy: 0.8319\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 0s 292us/step - loss: 0.4342 - accuracy: 0.7983\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 0s 293us/step - loss: 0.4352 - accuracy: 0.7945\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 0s 293us/step - loss: 0.4155 - accuracy: 0.8132\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 0s 291us/step - loss: 0.4116 - accuracy: 0.7976\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 0s 295us/step - loss: 0.3989 - accuracy: 0.8144\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 0s 294us/step - loss: 0.3824 - accuracy: 0.8225\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 0s 296us/step - loss: 0.4046 - accuracy: 0.8120\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 0s 292us/step - loss: 0.4077 - accuracy: 0.8107\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 0s 289us/step - loss: 0.4137 - accuracy: 0.8082\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 0s 301us/step - loss: 0.4129 - accuracy: 0.8051\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 0s 296us/step - loss: 0.4054 - accuracy: 0.8213\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 0s 292us/step - loss: 0.3895 - accuracy: 0.8120\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 0s 293us/step - loss: 0.3987 - accuracy: 0.8200\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 0s 293us/step - loss: 0.3845 - accuracy: 0.8219\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 0s 294us/step - loss: 0.3815 - accuracy: 0.8238\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 0s 297us/step - loss: 0.3992 - accuracy: 0.8113\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 0s 293us/step - loss: 0.3905 - accuracy: 0.8319\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 0s 293us/step - loss: 0.4019 - accuracy: 0.8020\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 0s 293us/step - loss: 0.3918 - accuracy: 0.8225\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 0s 294us/step - loss: 0.4080 - accuracy: 0.8051\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 0s 295us/step - loss: 0.3994 - accuracy: 0.8095\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 0s 292us/step - loss: 0.3952 - accuracy: 0.8138\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 0s 290us/step - loss: 0.3900 - accuracy: 0.8213\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 0s 292us/step - loss: 0.3819 - accuracy: 0.8213\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 0s 299us/step - loss: 0.3729 - accuracy: 0.8275\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 0s 295us/step - loss: 0.3834 - accuracy: 0.8325\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 0s 293us/step - loss: 0.3864 - accuracy: 0.8176\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 0s 291us/step - loss: 0.3825 - accuracy: 0.8225\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 0s 291us/step - loss: 0.3566 - accuracy: 0.84180s - loss: 0.3727 - accu\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 0s 294us/step - loss: 0.3484 - accuracy: 0.8493\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 0s 298us/step - loss: 0.3697 - accuracy: 0.8300\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 0s 295us/step - loss: 0.3546 - accuracy: 0.8288\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "準確率 : 0.8159203980099502\n"
     ]
    }
   ],
   "source": [
    "# 無valid\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\n",
    "optimizers = adam\n",
    "kernel_init = 'glorot_uniform'\n",
    "recurrent_init = 'glorot_uniform'\n",
    "bias_init ='zero'\n",
    "epochs = 300\n",
    "batches = 80\n",
    "\n",
    "model_GRU = create_GRU_model(optimizer=optimizers, batch_size=batches, kernel_init=kernel_init, \n",
    "                 recurrent_init=recurrent_init, bias_init=bias_init)\n",
    "\n",
    "history = model_GRU.fit(_X_train,_y_train,\n",
    "           epochs=epochs,\n",
    "           batch_size=batches)\n",
    "\n",
    "#畫出LOSS圖\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model train loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper right')\n",
    "#plt.savefig('plot.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "preds = model_GRU.predict(X_test_std)\n",
    "actuals = y_test\n",
    "\n",
    "#格式轉換\n",
    "change_pred = []\n",
    "for i in range(len(preds)):\n",
    "    if(preds[i][0]>0.5):\n",
    "        change_pred.append(1)\n",
    "    else:\n",
    "        change_pred.append(0)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(actuals,change_pred)\n",
    "print(\"準確率 : \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T+1 report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78       192\n",
      "           1       0.79      0.83      0.81       210\n",
      "\n",
      "    accuracy                           0.80       402\n",
      "   macro avg       0.80      0.80      0.80       402\n",
      "weighted avg       0.80      0.80      0.80       402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "threshold = 0.5\n",
    "preds = np.where(preds >= threshold, 1, 0)\n",
    "\n",
    "t1r = list(map(int,preds[:,0]))\n",
    "t1t = list(map(int,y_test[:,0]))\n",
    "\n",
    "print('T+1 report\\n %s'%(metrics.classification_report(t1r, t1t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, 5, 64)             25728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 5, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 5, 64)             0         \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 5, 128)            74112     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 5, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 256)               295680    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 397,569\n",
      "Trainable params: 396,673\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將參數儲存至 HDF5 檔案\n",
    "model_GRU.save('KGGRU(7985).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "準確率 : 0.8731343283582089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = model_GRU.predict(X_test_std)\n",
    "actuals = y_test\n",
    "\n",
    "#格式轉換\n",
    "change_pred = []\n",
    "for i in range(len(preds)):\n",
    "    if(preds[i][0]>0.5):\n",
    "        change_pred.append(1)\n",
    "    else:\n",
    "        change_pred.append(0)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(actuals,change_pred)\n",
    "print(\"準確率 : \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他的準確率判斷\n",
    "from sklearn import metrics\n",
    "print(\"準確率 : \" + str(accuracy))\n",
    "print('T+1 report\\n %s'%(metrics.classification_report(actuals, change_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, 5, 64)             25728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 5, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 5, 64)             0         \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 5, 128)            74112     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 5, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 256)               295680    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 397,569\n",
      "Trainable params: 396,673\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將參數儲存至 HDF5 檔案\n",
    "model_LSTM.save('KLSTM(6517).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "# 從 HDF5 檔案中載入模型\n",
    "loaded_model = keras.models.load_model('KGGRU(7985).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = loaded_model.predict(X_test_std)\n",
    "actuals = y_test\n",
    "\n",
    "#格式轉換\n",
    "change_pred = []\n",
    "for i in range(len(preds)):\n",
    "    if(preds[i][0]>0.5):\n",
    "        change_pred.append(1)\n",
    "    else:\n",
    "        change_pred.append(0)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(actuals,change_pred)\n",
    "print(\"準確率 : \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = loaded_model.evaluate(X_test_std, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41312772035598755, 0.7562189102172852]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOy9edhuWVUf+FvvvXVroJirBKSqLFBQEcGCUkFMq+0QEAMiPkaIbYwDGgW72yHRdELnwcfE1tg+UdEEbUNrorYmrQGkgyNOgEIhDhSWFMVQJVMVYGFNt+793t1/nLP2+q1hn/Pe4vtCfTzvvs/9znnP2Wfvtaff+u211z5HWmvYh33Yh33Yh+MfNh9tAfZhH/ZhH/bhcMIe0PdhH/ZhHz5Gwh7Q92Ef9mEfPkbCHtD3YR/2YR8+RsIe0PdhH/ZhHz5GwsmPVsaXXHJJu/LKKz9a2e/DPuzDPhzLcM0119zSWru0uvdRA/Qrr7wSb3jDGz5a2e/DPuzDPhzLICLvHN3bm1z2YR/2YR8+RsIe0PdhH/ZhHz5Gwh7Q92Ef9mEfPkbCHtD3YR/2YR8+RsIe0PdhH/ZhHz5Gwiqgi8jPiMj7ReQvBvdFRH5URK4XkT8TkSccvpj7sA/7sA/7sBZ2YegvBfDUhftPA/Co+f/zAPzkRy7WPuzDPuzDPpxrWPVDb639nohcuRDlmQB+tk3v4X2diDxARB7WWnvPIcnowlv+6FW49c9fNcl23gX49Gd9Ny6+7wNwx++/GH/x1rdj2xoe8JlfhWsPLsOzrno4Xvnn78UnPPgi3HLbaTzlEffHn/zav8epJ34NTrazuOL6n8W173g30IATJwQff/8LceMH7+h5PfT+F+CuMwd4wEWn8I5bbscNH/dFeOoXfhEe9N4/xJkb/gBvuulvcP8Lz8MJEdzn/JN4xwduB+a3Ed/vwvPwKQ+9L95049/g1MkNHvvx98fpswd4xwfuwEWnTuDi80/igRedAj7+Ktx15+14+btO4bKbfw8P+vQvxum3vw6P/bRPxzU3vA8HN18PALj8wRfj4Vd/GfC238E7br4VF5x3Au/8wB1oreHKS+6DW+88g/NPbvDeW+9y9XXq5AYPvf8FOO/EBpdefD5w6SfjzNkz+LM3XYOLTp3Apz7lGcCVTwEA/O5f3YxHXnIf/O1dZ/Hf3vxePOPxD8NGBO/98F244ebbcffZLR71kItxzdveh6tu/U085JGfjvPOvxCf+LjPAf76jfijt38QF19yGT78mp+BbM/ixAnBZQ+8CNvW8P4Pn8bpMwcAgJse/GQ8efMW3Hjz3+CRD30APu5xfxfvfuMrIABu+tAdODiYKvG8Exs8/vL748YP3YlLLj6F208f4B233I4rHnwRbvzgnWit4dEPvS8A4I7TB/jg7adxx91THiKCyx90Id71gTvm84vwrg/cDghwxYPug3d98Pbe7pc98CK01vA3d5zBox9yMd71wTtxy22ncdkDp+evvOQ+eN+Zi3D31d+E+588i0uvfSmuu/H9EBF82sffDx++6wze+aHTuPILvxEP+4RPBgB86Pa78dobPoArb/5tPPzOt+KgbXHH3Vt84LbTAIAHX3w+TmwEN33wDjzwPqfwCQ+6CG+66W9wcNBw2YMuwntvvQsXn38Cn/Lkp+Nv3/4GXPv2v0ZrDZ/ysPviYNtwy4OegLve85d4yMnbe5287bbzcedV34gveezDcOMH78ANt9yOz3v0pXjPrXfiLe/5MA62wOXn3Yo73/7HePwX/QP85zfehE996P1w99mz2L7pF3De456N377+w5N8d7wNn3zLb/Z+dOl9z8flD7oIr3/vAW688DG46pMejk++8nK8+3d+Gu/64G2pTvtYOnkBPu1Z34X7vvePcNc7Xo8/++tbccnF5+P202dx++mzrp8+/glPwontGdz2nr/C2/Hx+PRHXo4P3u9T8McfuAAXnLfBJ33cxb2tXvqad+DkiQ0+8dL74H4XnIe3vv9v8ZjbX4/73fJG3PTBO3CwtXo8e7DFFZfcF6c+82vxJ7dejIfd+Apccuc7+vg5sRF8/AMvxI0fsLH/kPtdgEdccp/++63vvw2XP/BC3HLb3bjpQ3cAF9wXT/yqf4bNyVP4L9fchK94wsNx8sQG7//bu/Bbv/XreMQtr8aVl9wHH77zDE6e2OCW207jcQ+/P265/W5cdGqDB131TODhTzxn/FsLssv70GdAf0Vr7bHFvVcA+IHW2h/Mv38LwD9traVdQyLyPEwsHldcccUT3/nOoX/8MLzu516Iz7r+R7GRSe4/+ZwX46qrPwf40at6nF9pn4f/9fQ34xUv+Fx82Y/9AS46dQLnndjgP37Bnfj03/5a/P3t9+OxD70Q/+L93wEA2DZZzXcjDf/l4HNx5u/9JL76mucC7/vz1edEAK1emaP26hZggwacvBA4eydub+fjPnIad7ZTuFDu7nJtpPWjxt1VZi/MnN+JU2jbs5C2neS5/LMh3/DrAIAnfN9v4FlXPRy33HYa//VN78ZzP/sKbLcNL/vTd3egvOC8DZ58cA3+w6kfwu3tArz1os/AZ/zTVwH/99/DH77tg3gdHofv3Pz8UMaNNFdGAMDJC4Czd5XxtQ5FZl0Zu6s+ckiv9ec2Y5kB4GnbH8EzLrsT//jd/wzAVD6Va4OG117xPDz5638IAPDSP3w7/uXLr8U1538LHiwfxhayKOMw37luOD9BK/sJAPyd0z+C3//XX4/v/7Vr8cvX3IQ3vfBL8MO/fh1e8ns34MzBFt9+3svwAvl/8Bdf/zY88ydfh/ucOoFH4ia8fPOdeP72u/CKu58AEeAHTr4Ef//Eq61NtP8AuL2dj7de9AR8xmf9D8Dv/h/DvqgyvfFJ/xZPeMu/AW69cTHudnMKm+1UpoMmOHHyPFxz+dfhK6/7fJx/coN/+OQr8b1f+ql4+y234wv+zasBABedOgEBcPvdB/jN8/8JPkluSnmoHK+78lvx3Os+F9ee+oe4QM4sjyEx80WD74NaD9d92a/gtks/A8/+ydfiF5/3JDzpkQ/Gz/zB2/GwV30Tnnbi9Sl9oS6wefoPA5/5DeP8F4KIXNNau7q6dxg7RataKbtua+0lAF4CAFdfffU9GoJP+p9eBOBFePub/wiP+OUvQdueBbYT2Hz73c/Hd533S/33XTMjvPPMAQTA9mDqLGfPnkE7mIr+nLv/N/yTb/kmPOsnXgMR4FMfej+88n/+O/j2X/gTvPzP3t0b8rdPfQdOYos7tw3YnsX7Hv4l+Oy3fZ1VgkwVccO/fjp+4tXX4wf/23X4z9/yZHzlv3stAOBNL/xivOLP3oN//qt/ARHgK666DD98wf8FvPFnAQAXYpLtfJzpaW6k4bVX/mP8+Nkvx0tvejrOmwf2E7Y/hw+dOYHWgFMnNjiz3XY5v+Kqy/DDX/V4AMCr3vxefPPPXQMR4PMffSn+wxWvAn7/hyFo+D/PfCWu3lyHz90e9AY8c7DF2YMtzm6npjk4aDi7bbhzrkcAOH12iwtPbGeZT2PTZpZ1cBYncXZqjw3wpn90Pb78J//YKbIff+5VeOpvfBHO//C7AQBffvpF+NXzXwicPY0Py33x+NP/Hq0BL3v+U3Db6bN47k/9EX7xeU/Cc3/qdfiWz/tEXPueD+PV193cwe/UiQ2e/cTLcNeZA/zqm/4arQE/+OzH4Ysf8xBc9X2/AZGJ5d99djudbza4+2Dbn/+Vb/2c3u4q44uf+wR828+/sbdpa8CXnXgtfvy8H5v6zXZqn2ee+QH86cEV+O6/+8n43etuxi+852nA1hin1uEJHOB1lzwb/+nBL8Ar5v6kaWueAPDTX3s1vvFn3+Da8z+d9/34HFwLAfA1d38v/lgej6950ifg6X/5Pbjqtt8DALzgzPPx8oPPwTNP/CH+7Xkvxkls57ZsODvPdM4cNNx9MKXZtmdw4mTDmYOpTe84c4ADuRs4BWwPzuCTPu5i/OZ3fB7wKy8H3nkFNv/Ln+Nf/Opf4Nf+/D34qc9+P574mm/Fhbh7avftWZzFCXzS6Z/rdfWr3/YUfPmL/xAiwKds3oP/77zvRDuY4t5w+bPxP7712b2Ovv9Zj8U/+OxPwG//5fvwV//xO/HNJ18x1Z2ch5M4g3ZwBm17Fq1N/e7MXJ6D7banwX1z0w7w8u2T8IIz3+7q8dQJwV+d9xy07VlsG3ACW7z47DPwQ2e/2sn7iZdOZf+uX/5TvOb6W/Ca7/1CANNs6wnf9xt44Zc9Bv/vn9yES973Grz05L9COzjbZTrbZWs4iS2ubVfi6Xf/K6ekf+grH4cf/53r8bjLHoAf+0wjoIcZDgPQbwJwOf2+DMC7DyHd3UJrmdrM+mQeU1MUPXEXpiDz6IrJcHRgYkaN0o9xJai2bfP3mzvvvwAYi9BjHSx3ZvpRzko2uzUo5HyLWXDTf6Ec4mRtPS6nJ3A/XdAyRpmquCo7l5nLDjS01obPVnIYqOZ2byyVbyITpOeNKW9EwXKfiTKmvqYngamL66jaJtRPij5qeVjbxPv9XisSKQTkmXxv97K89FvrKMQdBQmVK2gQkrMV/cQnG+oqtJX1zcbRinT8KLF6zOXqfdKNg7o/6/NH+ZW4w3BbfBmAr529XZ4E4Najsp+7IJPo3CGnqpTeYNvU4SbNLmjUAIINAbGCcgRnaLqzAmnFxEQBQuZ7Ln8Twi7kTHKa2Mw5W1xWFJuQBCfJt1rIT+sqwmoaOBUgc36EspOUCva5a031QuWglFqIp3Wogybo4DmP4rr4OtiMKgS57uZi5GsEMD03UgaTDLEuTbFZrYyDDnKWyYEKuLzcjnrOMqqiyQlp7C2xXE7B9xDpRWXct/t5HJT13eq40mX29dPcuMhKY1SXQnlsyj7QinhCz9sxDtUp/zaTBLHfAbyn+62WsZlCPqqwytBF5BcAfD6AS0TkJgD/O4DzAKC19u8AvBLAlwK4HsAdAP7RUQkb5JrPtr0229wl+53mBxizCNP84hvVTIYutDldUx2FTCENr1B8Qzb3xDg00QHFQGhhI3GQ0HkAcD9cZyWRZGxu4FQl9UAYAT3nbfIAjLbbEphm85Ufg7NcXpqNSJqg+R7gZdXsrR9kGavyGtGzzDq77/9jXYanV0ax3t5IXScT8RAXl+PE5DubTPeU7GzTNUGjem+9ERTgGGilnBkHQqFKXeOOyIfEshIZKPIYEVxVnoCvRz3XMc/xvLx2LGdqUB4mdiPUManBLLeOrSNE9F28XJ6zcr8B+LZDk2jH0Acj1ZBCirEUi9+ohzPTinXbWUMCpKkbaDo1Q7eYKf8kT8MuDN3zBn02d9Yog38i59dZY5hF8DgdTQ89SOr97QymM9PcVAw9lGNwzrEqlmly8Fxrfk4XMyiO3dNWtN8xVOVtJLmWT2iGaMra16U+08acjfLN8laA3kLfayEu931jj5Z3NTZ6mTpt0ZRtLEzsNDLnZYbugA/x+cCIOWVXB55wxGs+PbsTAX1LdzdSx3MzBjd2qU5bI+sAGU7JNCRUdxxsNnd0iH58d4p2tmII1DAz2s5CwgAjDc2svtTSITtNt2nnrBho0PrR5NOiPDswdMhmGlB0iblVFINZZ2U24vyTmaDZMMV8rBl6zZomhqeAvgtDr7vfxNCneFtu25bjxXoNWQQFJ2YW20WXzsGBZTAWax1NDJ2e6dFaKXuVy5pc4rNwsrHS6XKRYu5p6P2RyaVg6Cpdc3XZSmLj5OdpVstjxhixNymOGHrLl3x6pGByHwgzKGXymxivqOfOwn3bo/nZrMaRAT6syX8Y4RgDOk3niKEzpLGteepTsw2dFvMgAQTTiV3o8McrIz4KxQyLogEco017FAR+ijg9uyNDp/OcX2Fygdmr5wtl5ytt6Igml6praWmmMDS5kJK1he2sXjbirNpzvr5lWLHwvQj8XY6ivMa2LTcBM3RNcUvPGOttTVYH8e4MPV/PMppy5nt8f+uUYBWTGTrmvpBoDuI4iAp0kqVm88aIY5m473jCwccYOJ3I0IkWUOw8frQMtQ1dicvc9thanyTZRqO6z+b2gJ6DYxLEtpl1Rht6f9YhlZSsItpX1ZQzPVYzVwMzpPwjOO7O0NXXmYHQwvKiaJy6eiBgNg4glS2CpeUZBz6ApvA8ZprnZEPXODSVjQNBFwlZSGb3UxyvrJkV1jb0ccuKCkLpNPovLdalgcyqyYXKZNe8Et+IEgNJzyWTC92szCtsQ3cmFzaT0FhoALaFDT0rU25HSqtCsQEjduy2GMNDk4szpdj1jY6f1nz9hHjWbwQsEbPwBr/OYPc8vlQmWZvNHR2iH2NAp87iGolt6L5RvH1UR9ymtDtX5gpm6Es2dMuTO2PotLva0GUeIhTVe7nENIrCIDP0SZ7I0P3Ym9hE7ny+01hvVy+XbaugchZnyEApnhBgLphczIbOg8nnHQcss8JzZeiuFcOCX9Ufpnx2M7nUDN3LYAzd5zDdJ6WjYhUA2FM/Vy+XxCyNRHE65aKoQWEhuY7Yj5yhc6qZoft5gM42WPnz2B/b0OHantn7dFSlUQB6G+u2wwrHFtDBnYXYNlcl9dn5urktcq1Wdud6cmk29KrB4oKqyz8olJ0ZOiTZGLdO3jBIajwns4DmPw/fchZBIFpIFD1H+sOw+VHN0D1keLdFHlgWT+uwWkySmdo5BiqhDuKAlTpel6MEdGK/1Neme6wcyeTS12vUqrocuolmweSiTLZm6CqVXalt6DNDJ1bgGTrsoc7Q5/RdhWVFJhIUua5zDZSeX8+gMsWZQCjjKHgbejVT4BlMBn4e+5586ePN1QOP6VjXNUOnNI4oHFtAj/Y59L8jP/TmBpklJCUI1gzdWq1qlKgMRiafLuw5MHQ//bbbyeTiHuWB3zxjh681jZMW04qCujwp8gTDOqgqhQdX5q2XluS2aLYomm2PGwW4cL1cE5l/MCvc3W3Rs9+elhDris+0Hm0C9J0Zes7X5Brb0DubZjZZ5FP1zRLQE0M3Vmvp+D6VGXrXDqikYcn9bOSe2tBbWY/d5DL7unCqoz0omXwZgNMqXVKoSvxGbGHP0AdBtCWiDZ1Ygl+URI83c7/+TAWCyYauwNoZ7ACwwGBEz4eGjDbtcTBm5soyh93dFv2V2g/dA4Eyihg2dI0ZoZpcoueQl60GdM6F1UHa7ctyiLrxkTxRQY8AZ8jQc3kd+9V34GAzA5H+87CUVfnyKDaAqevEiEfczyAuLhNsY4+591TlnOqdxlVn0Nk9tDI1xfbtY2luvKFHjHhl4eL5TOe/dV0y8alMLtLI5NIVICspu+YZum/X0g+dmPpoPlaRqMMOxxbQw6tz5jPtkrnTMqD6Ct+doevwrTrn9IxnctmGHtjGjgzdQ5xne5mhxwFm+Uf7dQVCDXBAULGJamOR2g41xapkccGyjUwuFK95LZjkiAw95sseM8mGXsi4zNCJac4ymhLMylGf2Y2ht16mmK+VJDPlluIa6EX2aGVAcFuciY4MGDqojO6ZAOhxLLk2HLs4Jhu685BiM5Y/xjDeKaqloPLT7CPJ45vS2cdB49btFNW4fQzk3rW3oS8E11maVap6owDBbXG6Mj0LrlU/tLlROUQvlwoNTBlIyr9+l8e5MPRasGUbekJ097OZIE5Gx9CLzlfPAszkMslczWB8XW9HrAx5llW5LXZADbLFQSrFvZENvUJ0Z3Lp922R3GTIvNzDyHrw9eYL0k0fhZ293FhUAKDVa6NrrR8NzxtVFtMmyzmZHsVJjLjOFeuA9234OUQ9Lsw+XQf2JYo29Kmve5NLbH+aMNQzNW1nYujJdt4ZegXokdYdfji2gE6rN/AMve60UwQeZMy0KFnXrCFLfapY4OFHov1Xs/adtuUeVQUx4Jie88/EDZkODhyex/xGDJ0UT6u7n3NbdDZ0YydlycQLNTS5SK7DSrlsNhVD97bxKcvMyqNyMTmKgdyfaeiMkQFWUx8w9C1qgHB5NCtTzJdLFtcShiaXQZkM8LOXi5YL4Y7MiB49WpjF6zUPpFy4JYbu0x5vLFLZ67rkdLgep34S21pid+w/4kY+ViStmWunbwtSFMBwYxGbwo4iHFtA752B7VgdnZWhB07RAb3Zu1xmW6gl7NPvz0r0Q68Bn485//p8OSwz9GxDj4OO8/PMLjN0zANX4wxMLk46BnR9qtZVXt0uebmYYnV+6FGO2YbOdzJDJxUtfqfoYN2qCMR+HUNXgNUVEa8c9Zlz8XIZbSzyCiQrwoqhT8cWFF4eG2sMfep/oS8MbOgeH22L/GxjLMuedoq6hslKcheGPnZbNPLH/QFROqc0fR+UBbdFtAYZvDFVn98z9CK4zkLakU0umaAz9WSGnhu1guu+NDRg6D2dbg7ivD1TahRvKajdN3ozaKh2upHIw/y0rmL3UhZiMudQvpwLYVF0VD8DwErub/NPG8TZJ77vFHWAlduOmaAsxOPS+GsFwCh6MZkoNLZGWbehT8choINMPO5JcXENsOo27Ck6t0U7LtrQ3ThR1u0lrGzo6HFr8pFNLvds6z/LnF7ONRfCmVzg+4CzoXOqrg9yubY2VpwEo41FWcEedji2gO5MLsEePmbI2x6LOdSoUUOGvWOPdCwDR8w/TZUDYx4G8YMk29BrGUxizc8zpG7x7uDtjypjydCJgTBDNxUx8HKhv0BwW2wx3hxnQbnoZKyFa3Ha796x09u3tvNX5WW2HfuNgvXIy2V6EdQODJ30RExjOhdaM8igzyOAL2SFpwydTC4yYugm05ROUGwlQ/ezip5WaUPnY90v3Kynnw7GH0ixBTHiUqX20Wo9SGhccG6dlBFhi0rGqq3qW23P0Eeh3ikqjqHHRVG2a9qPuFNU3LE/S+kOGXqXDSn/DBQNJeoVqTqTywpDPzcvl34n2An1vO5+dafhRdFBSTwF3On1udtCri6HmMmDcskKWvK9MUPP8jv2S8g7mUDUbTE80/zzqzZ0KlPMN8rngV5DZOgqRwuxsuL2fujMqm0stNbyy7kCEw3Ni7hTNNa4Z8RUbhn4oYe+GsOqySUx9LDeMpoxhHUcxh4/VrRGBmtsUN12dJB+jAE92ucUtJiFjBh67OQZBBPWzuku7hQVGwAx/wbfkOfE0Jk7JQBP0ct72YaO3sn1t8Zz0/VzYOirfujwlGhpp+guNnQprmfWxTZ0GoxStDFGDJ05FzP06LYYX861DEActJyjD1z0mdqQoQdADyCU89uma07JJRt6ZOg54aHHVWFvn/Iz9eqVFFeC04x8KOQfuy026AzEyF/sA6zsi2w7gJdkMjL0wezvKMEcONaAzkyCGom6Sao8smtSQml6luLQlTaPkKpZIkP3AB69E1AjSpWqYwyDQVPcTR+4SAydAL0AgJqfh05D6xLOy6Uo23SpZqAjUC7XPSheVDoTS6zZPjNI31OoOOkKQ3ijrei8FT+z6WlgW79ct6EroI8Y+mjrv1czUeZcP/OPta3/jqGT0nLPnBtDTwp5xNDv8etzLZ38gQtl6JpW9nPy8kTy5VX5dH2b7qniqPtRGyrYwwrHF9C1KRxDXzO5WMe1DQs1a4iA1P3Q51/1oqhPMe5UdSwk2LSHQcLW/4F9OMoQz1HY0Jmb22DxvrXljkLHakwhCKwzVyWLYDsyuXAeo52iWvZogkgsEdymrHTrWUQ12kqGLgR0rYVaRKiD0RC3oOVc9EPHbPpY2FiUvFxCDa17udC4CtPVxJwj65aoTJdfYOYYMV0fmys8+Yhh2Q9dR5G1lDfH+bHvs7A65Q9c2B2Wzc8UvPzTA0fpiX5sAd3mVMzQAR3mwIrJpd8abxV3QchtcWBD74ymg5HX8veUofuXWo0Z0ZSkv7+Un2foFo/3GK4ydJfabHIZgWVg6MNvipKiGr0+V8selY5QGtORdorSzGFU9TWz0mdYCP3wCG0hCu3d+yHWWdmqyYUZuovjwTbb0HO9TddHfuicu/hnXLTMukeMd7ShhtuIx9N2aEPPcnjRl00u/mnp/1wBUCgYpxxtjFUeKw06yykAXf/vGXoVaobubLSJoduTfeopS+YBn9/U0NosSwxdwcjl7rr0rjZ09aM2/eOZR5ayLkO2ofuNRV02AoCxDZ3zs8gSBkuWzbfPiJUxCG/dYGouTkxjuq552ZFB3l0vqn9psDlLr7ZLZ13i7rNvyy4mFy3noh86tE1yHKt5LUeGMC7DufqhA/49/Bpn1G7T77hTNFa4KYyRC2tUkuFSSm1kctE1DlNOYy+XiOhJOfa1MvvABVsGZYAPfTa3B/QcxjZ0nnbGmtvaMwOGMnw5FwJDL8BAwsmSC+DODF2il4vPL4F6TbcQd4p2uEkMnfl5zYY27qrnTd3kUtVPYC5DP3SK5XziE0OXfJ1Yn0Z0O0Udc68GXS6xr3uCNW3n+X9sYN9Dl0fxTu9ykbicn+OuM/SMius2dImPwCRhQPfjJn1TNPRhb7Pmsqwx9FFd2vX6bYu+fkYzCjaudvFh7Vgx9ObSXbGhr/SFjyQcf0APPdbZ0ANFb1vtuJzQjh+4EFbcO9rQt74zuk67qw29zwyo91N+WUx/3/JjyQx+Izw0EnT0gQtXX0Sb/MaiqiROBDQI/HeOqFzKCrc2UCJw65PeRmzgrUdrU/sVB7PJVFzTjyFMVHxObH7b4lxHLdSlDmwt5ypD1745msF0hu77Xja5zH3LKWiuH81v9IELGleRobsyNHB19OcrhOwM3QfL17dGXnxVkQhZi8DjpHwfutEY6MK9N1Faeb1u9qTCuS122UxGcWWndFpWsIcdjjGgVztFJyTonTZUnFsU7bUafVH1angWYjbUgQ09LqgmP/TYkjswdO10eUjOkkeCXiinnn9i6NZznZklsLwYNpU0HdC1HeqyIH1r1AOSlkuvDxdFIX3gNX9jzovzZBnsuKvJxXqKAYLa47X3cV1O6RB4tHFdajCTC+cbG7ciBpH1Nt+G4YF1P3QutVeO/DI1KVh3/MBFdu+LshKAOkBf8XJBHZZt6DL3UU1jwcsFsY71mWhDt3rk8bPoh36k/PxYA7rX/oB27vGiKGhR1GzoNQjWNvRlqEsM3XXGVnSSdUDvzMzxKDtdsjX2j8cAACAASURBVLiM2B6QWSP775yLDZ2H2VT708AtbeiBorPVfcjQG8vlkMkWCf3l+ZiZuMf2WsbUZ2B1r6oHAJrmrzo+PtPC82sMvZtcaqYKfedQi+AXZfSucVEBdPn5c1oVoK/Y0GWOE01lLPLGuS1mBeUIB51vZXCH+mUV1jYWeT905LFPyj7vGYFBTS8X7zuwo1eDJL6aaPYMPYfRN0V5up/w3DCcnvEv5zLW4BtE0+VFsCRTTyPnn23oDSVFrFJlBiN+AC26LbL8zecXWaVn6Bwn9z5XXzTKzORSF03CdeP0kaEjt2Gc3GBWsa1eLOXqql7IdU8Zup/ZqaJWM5Nnk87ksjKKNdnxBy4A86rJoO8WStm2G8xm1dhgqkCjp98xRhqBNrqM+v4oYSDEGvA29IEiC6SIjzEw8cmAjgFD9ypej458ORrXXLm4nlXcoQ29jcfUYYVjC+jVN0W7yUUGDL16HzqjB3znDhnCnNRGNvTAaIKWv+deLsbw/BS3Yuj+frzb8+9g6gfbxO60c9Yr8u71uY4jmsmlKtkkj3dVrABdwQsYvz5Xyz5m6HoMbosFc+ewzNCJXsnGLcpmkwsD+phVxnx9m3nVqYTCEwN/FOqhPW+XirZt8YGLAUPvMsZ0kukxmAA78NnXwVDcdjuhMZGsXEJPOqrApo7IvK1nGlYsmeMiGZuObW5X7bMNHuwJGSob+vxnb0OvwpChWwdd3ljUE6pBMLbH3PalLTxFVTCivNFyJ9mRoTsGExZxkpgOF5m15fwc7yCG4eC6KKpU581MLn2wVE8OTAqjFhl94ELjJNu65KPQPXe/EDF/FIUBHWBdpurQ6sizSWaDa2N43W1xYyaeiqGT0mHQjwrA6pXrMqoFH9sISsXQA8Hgp3ljUSwPiBGLz3lbNQyoTOVdz4xHO0X56dEsbTQqta9VDB1U3yLjjUV7G/ogVDb0OErH70MH4ocKKOX5bwS/c9gpOmTonF7DuOv4RJVbsHw9H4mDJMtT5ZcWRTkmg0HR/YYMXWzADBl6tTDryucH2hJDR59K0/Wi/UYfuNjVhm5pN/RZntiiLIDZHLHE0JeHcbeh1+uBXea0FtPrT+ME0IgKr2TodnRmEvF1WdnQfd3zuAQ2G31eGXoIzIi5b8poUdSTjyq5bnJJH7jwZa0XRf0ATgue8zX+nrHdiwqyYuiqbI8O0o8/oDutOzXR0A/drW70lEoQHC6KzsiyBOiWXVQo4XwnPLcdgjGTkmQOWH9k6K15j+Xahj4yuVB2TE1gg2poQw+svLIBc7zRzEHLnm3o8Wg57vaBi1xg5tqW0aaXtn/gIjxr/XCdoa++y4UUSMVghwwd0Ybu24uvRcNHZug+x3WGrmN0YHLpx5gz9wWvJDXnOpjM64uilduiP0awNoY+/sCFui2OGfqS/B95OP6AzuAs0r8sBOzotrjSqP1ZKLDmjmzP6gCQlH+yoZe5VEFCh/fMM9vQ6dwxdH+3/w6jpKmwQALRMo8ADOaHXik8j6JqpKHsU7n863NbGWfZhk7gHspQ1f6aycUBofAgjQyd1IB4GatQvculNq34uqpMLugxC0XY63UA6IxmNLMBiveUB2KT3Gg78I1s6F5haNiubCwaISKbXMp3uTTv5ZIZuj8msFaCQ9gz+sBFzdAxXJc6rHD8AT0xdOqAiSHbBy6EntmNoWsnhtPMXiaWIrsthpE4ZNMx0WhjNHlytxnb0BsimLJnBk9nXUcuGXqFemxAKQRDbJ3p3AZCVqoAv8sleFRAGXoQkZj5dOSLgbkX9V8virK0szxqCmsqg6RnjFjsYkNXhp7z1YLYIuyAxQNOpp6GU3han6ONRTn3iqGbH7oT0fW5bnJZMJF0mQcM3ZlcAmOu0jMvF7tu73IJXi6eX7gZw5RfAOs2K2oyyWSGPtdxNbRbox50NOHkEaZ9pKHcKSoepCq2BfhpXLShVzZYAPZN0ekXqhbrHaIYAB+RDV2oK4YemN8uyMyE82MJFdDh2LjGc4yk6H7lN0U73259sBRFSUos2oA1XsXQI6J3Nz7HNr3a4LRi9ufO0K2viS5Sci0l8CEYWbWhT8e1T9AB0W0xy8itFk1SXaZtvjYxdBpX0YYei5AYOlyl2trFipeLACNAjw6EKloV1vzQqdf33lqutSSG7mcJ/i2Set2IUVRQ/Gzrf44m7MTQReSpInKdiFwvIt9T3L9CRH5HRP5ERP5MRL708EWNec47RekveiMZq3Oh/MDFYKdoag9lZC11ZHvWD4DYEdJmhR0ZOoj7xgG0yND5Zsiv9bQKFkIDp+p7Ui2KdoauJpfiObqqHhN1uYw983bvXRh6L2IH8WBDV+CTuvqXbOjaEiwnM3Tvh+4t72tDuH6XCxcMzsQTZePceOEt4kdP3ilBO/oeUgPcFLdi6IEcrdrQLWdOZzvaKdrSpZCe1Xq1U1SiyWXI0EN+/fdU+fYMuS1Ghl4BekjvKMIqoIvICQAvBvA0AI8B8BwReUyI9s8B/FJr7SoAXw3gJw5b0EKu6cR9JUb6VBjI0+dup5wio/8qQLDi331RFHWjZIa+1nTrgK52SRPXM4pFG3picpGh0+8CAEZA5DdjNHeuJo7hGywVqIPACbzm09FOUfYyWbShDxh6NA9oWDK5xMJou0TlCHiZGmQIQjHf4fvQsaH8MptlShPbrcq7/mJR8/0ptKEzuaAmNv7xaEMP+Y0Y+i5EZxC68g3jBDRj0ngjMjTKXuvVv3bE7vljxdCXZxiHEXZh6J8F4PrW2g2ttbsB/CKAZ4Y4DcD95vP7A3j34Yk4CLQw4WtoweTSBw11+aSl61a1LfhTnlWDGStEyv8ef7Go5xuhqgalEUOPNvQOxclO6H1rK8ZavsulT2LXjEk1Mx+7LapcmYlXbnxxp+8kE7HyLoWUQq6aXNjdVeXi6U1/xpQdz3pGYfVdLvPsIq4lRACRWfE1V29e6U7X8zVm5fMUcs56OnrvGmXosd0CkALdhj72cvH31hZFRzXJKnX4tsUwPvwQ9OWt2Dfb0HU2xJEmho7FvvXR3in6cAA30u+b5msc/iWArxGRmwC8EsALqoRE5Hki8gYRecPNN998D8R1aU1H1ryzeUJ/p0XRzlOZw/it/xGU+caq22KXDSn/zJqWYc+CMrMC0AtBK48dzd/Dr2eVSdmAJ5QxD/5lvb1Pw4uZQ3+uD5YFQIeB8NIHLjAzdGc+iPqYZGFTzsjkUs+qDCzV2qRpsddTdLHr4Cm7M/TR1n+tujFDJ0BHaMPIrFEDOjXPlAIpRQA4iPXfojKNDF2Vw5oferSUOyZCp1l2Dhva0DP6SLRRMun/WH4Olo3RuEblEl4UddLXY5v78lGFXQC9Qp0o0nMAvLS1dhmALwXwcyLptXporb2ktXZ1a+3qSy+99NylZaG6DX1LNeSrMlUcd+L+yMBtcUDAl9apLR1J+UdA2pWhGxPNgsW321XPcv7ehq6dXH/nMo06nlsUbblLIwwUvmoM3T/lQIdAuA3k47JH4ItHbtPqOoeqzNa76BfXZfPKUZ8a9sOFfBd3igZ5Cqlo1tArrqyf2obewn3PatNHooOM0W1xE15iNbKhR4Y+WhRdY+hcmupdLs4PvS14uQyAvfWmN5NLvKeKvJzBh7hHEXYB9JsAXE6/L0M2qXwDgF8CgNbaawFcAOCSwxBwFEq3xbmFzm1RtGYVycsFAn016a4M3efv+e50aweG3m21NUNPNvRqugEFxGrQNH8gMAjkl/Ko6s5z/l0ZugFSZOgqDzH00GadsTploEdm4nnUjtwWVzcWEXmQubC9NwUF3k1/WGfofY8EK+HYXlK5Lfq43bWW7lcM3ff/1o9LDN0XYSp1Mrk4JeS1cqyCkc16aHJZBESfRzStRN8THQ1+7M/HQMi4xjwx4kVR66e+1nJJjhDPdwL01wN4lIg8QkROYVr0fFmI8y4AXwgAIvKpmAD9I7OprAQ3GGmQMZ9d+gSdKYFdP3AhbjDUXi4+jeS2eI8YOtvu4b6UVNrQB1PIzNBB01C4ktkztcnFd5oZDJp3W6zLMkmokgI2xCIw6E+/scinJfMMI3uoZ6Y+PSPueiXl6sYiHcBCi5RdwXvwYfBYG8S12yILj55D/XFtA3Q2s7SgaTrZ2eZrOnrsQVWKMstIbTR36FjzbizN+++ZFYcizcfxTtG4LhHPUrnamKGbWVAJWpydGwmY4hhI67GhWdrM0GHPCClDDv1jLUdI0VcBvbV2FsDzAbwKwFswebO8WUReJCLPmKN9J4BvEpE/BfALAL6uHaXUsGlPZOi8er30tkXrxAO3xfCkptuKjtyfTQNgoQvuaENv/WPEJUQtMnS+FWcE5uVSdFrupEUzRs8Wn2Ir5ZqlJYaO8qjx1mzomkeyEUs8imtTfr3urjZ0owvcb2YgamqEq9wWDWR2fpfLgKH38oa+V3q5kJLLNvT5uZHJpWLo87VkQw8y5j0R81Ft6PE+pc9gzwzdr0v4vlrltei2CA/o/ByX0+rI54u5Llc3Fklsu7lcR4qIU9hpY1Fr7ZWYFjv52gvp/FoATzlc0ZZD+XKueZSyd4ELnaG3fq4fKoClMKefcoS4YbLO0LMNPQD8jgx9ip8BvVrYi4y0FBBwXXv6S8DpznNY+ki0QAfPqH5qZj7ycokLUzFOBHoJZ8wasw09y1jb0I39sgDTW/WontwCnsk8mrFU+a5+4CJcb+mayaTp+iJp2xYfuBACdGboIa/+a42hy8zqFdBD3XrzkoXR2xaruJZ3c/fGG4ssjWRDD2QgkY6mz1Wv7qZ0B8p73Y35Iw8fU1v/2wpD91v/e0pluqUftWM7406nj/q3LQZmFRjzUlBbrUscNSiNGXoe1s7k0lm5n0bWbKjqmGZyiXI4eYKCigwzyu4ZumeVqrodqARWyWYpHsCVDz/nl0s2y9SBkN0WFfy8wmbwWBvLtR86F2y6FwE6e7nMfc21Ideb1me+5vtTQ0S45IceiY3w81Yjq26LgdGOvVzSpVwufdYBtZpcfLy4vmKLtMbAU76qCeYLBvYWV6SVvvRLM4zDCsd36/8ma8l+b67m8etzuWfWNvQY7N0dAxcsZDBJbovM2HnALASRTZ8sTs+tMXR/n/P3kVX5BYbBgNHOYet/0xSb29zlyzI9wfmZfLFcCiImnwduZehx6388BrfFwDpjWDe5aP7SgaIrR37GgQfKeqzyHZlcVPIWQDSbXJrLr3oHjl6P1+ZGtAKEulrbWJQZutbY2tZ/b0Mf+6E3d3Rp9TgelAH2Q7d5KVDMIocM3fJ1NnRH8HzcqofdW/zQ79VBGg91e6UpUNmsGNC5Q2dEH5lcMGAb9GhPb/Fti7sydAk7RcMgL6KX97MNfU6zswYCH3deiZTZnQ4WHTY10zQNlBh68+WKIBI3ZnUWlWTzx4k12jXH3EuGnq95kwsDwlxXTRm5Bx9vQ8/pVvnu9IELRwyyjG4dJMQ3mQZfLOKUow099bfmGiC60fa+MNj6zwqDq2fotrgTQ89ty6/PJcnzekssXaPIsLrsZJLIBMe9t/uh32vD9BY76rEzRahYyHwhnaf3TxQanu806jgxMIjE/OPiVOMetRTm8nS7Ik8Rw5RxKI/KnWzoNpS4Qzq2XhR0U2XZmCvuwtDj0ceTUIeR5WrZM2BJONLMCT5ebUMfjzaZy2kCmGJk85UK3JWSg5I69He58GtMUv5TeSsvF2dyCRywZuh8rfV7Zsq02NGNrz9TMnRPjmZqVZeHurRj6K5PF4COHDzz9m3dP3DRgpcLyQ2S3dcBK825d/cBwBuLSKGgNrlsF+Q/rHCsAd0YpjUma+JteF0Fm1x6B5D4kWh/7M/KDgw9aPr4YfXRIFsK3bQwmBEktTMA+MzQq6fnjtnsfHnweIauamKkqwR2I5CfDAzzb63DavFT1VEE+ngUurm6UzS/4oRks74m2m8aulkjMUAa5KteLv2NAjVDb12B1G3CI4DELNYe9Eb1+txlhr7dRua8slNUW3LNhh76Ymvk5eJ0pJKPcV2aOyLLVS2KSgLwCPCrW/95raIfx0vgaztdDyMcc0C3igUA+4rMFJI91P1mEPBgwkekOyFvF8N3kEUbevOMeRzUbTHLsfpyroz2Xh4EoeafnqHnzjdQGTQsa5PLdC3xoi6Pi6cgMrSh68aebMf0qVtaUYVV5Vj9SLQhJ/rrezHqDwZka0N4J7dFaPuMGXqW3edcrS85E1pB4fXSQSxFa+GjFxFIlQkXWhJwytWNzMGwWMJBZ3KBjUWVvw3igY+BDNiMoPVjc08szRYytHJfPqpwrAF9CrnjjTcWEUPXxop2vwFDt+dG9sCCoTsA97L6mAshyJd8eQcyTOfjjjf0QwcziVqkTWVDb+yHPiiKy9/k4KPGs4VlTb4G7gz0ehy3j96v4tQ2dJIr9Dc/cyAF3swFcOtvlWFtY5G5rwZikFhvXBRFuG/y8TN8jLlbW2SGvhR67yre7MiyeO4MtLWXc5UK3M8Cog0d/W49W4jylPnNba3p8YI8RZnyqGZ/HOmIwrEG9G63dDb0utPqExqtnycvF3FHujEP4HXAivbfKbd7ZkNXhjn2Qx8DvAPQ5q9o17bpsE0Hud8tsV8+VzCPg9M9R0gdbefJy6XLPQYZA1QGp1AfAldzrHQrKZffhz6B2HbOpS9SollfdJLuztCNbOR8uSw8SbAcKA78kMhtaO0cg6sTmkEu29C9fP5tizND7wShKM+csfdyqVS/nS57uagcds/eh87xrGNEEhDfxR9x2O2B0TPjNUOatmfoK8GqR88mk8vIbbEvhKK53hk7IR8trNvQ4wDwfuiRWU26fDXItHhnz9bAt1QWzTGbXEYMXWWuLbYlk2vsh55Z0vScVyh8jGVIbouh/vqiKDKoxCMPVH89Zb1uctGSiPaI1s1UUYHyBrddd4qO3oeuH+cYuy0ayHCdxDb0ax7+2rRT1EGjEyPvFB2/5mGKo2taE0PfDvqD9z8JgB5IUbiUyjDl59X1tHiuVMNQw/SJyqHx0eNM+Xkl6D4SHZSMMvSqXnhcHVU41oA+q3bH0N2iaCLo1HG1uSLDHfZP22oODIAopOFMLvDMYmeGLprvPIScvb+wodPvJbdFrQXPJY1x+ud8GH+CzhZFY25dtrQoWgO7/mLfXQfcMJsy30iATrUgoMEb2KSGVZNLXwDVrfh6X8CCMGDsZkPP3cE9M3Rb9PVnbotEdxIQe1Dx9dMjEEGZZYzMuQUvl7CIarpBd4rWY43795TyaOu/P7q0eFwmhl6tZpDJjSsAXEe9pACqD3lbr/RgXZO1PUNfCbZpgYYcteT4feiwZ0InNHbpG6SJ9BcS0dMuZBs6d8ZgcnExF4Kou2TFZHMaku5Tfo6h6+45zz4iANTlrBgfqQip65AlHJlcIhjEOuSyKcD51MUfxafJQF+FRYYuqpZNkXr5vawORlZG8VZnOK7NMgC2cD3ybZXCKWgH6L69+RrQGNERx8JBSqd+TwwTG2dyKcptMtO4jYpjUNaYBksdx4ESvRjPy+07X6cQ8yHNoop1nZ7uAlk4QoJ+3AEdDmRnCuimVf4BY+gGqZ6FRFC2IOAvHS0xdD3h/Fv8TQxoOdhb/aJkEQBcAeDLED+oocCQ6oqnkcT0XBbVefN+6DFeFy3Z0D2wx8HlZw4x37w0V5nMGORTOy+x4iI3nU53k88sQO+LlM657BRtQDerVLK0bnpr8N6wFUNnoKlNLuONRQZWkaH7+q8Yuh6FYpmiK9cE5vic9uhdLktuf8kc5tofRF5Mlso8x+U1PPdjZEO71K1/Gvivbiw6Qo5+zAE9djXvhz5aFO0jECCGXgO7BXFp1szVs0OXf2BKuzJ0s9VmBKo+cCGDHxVDdwDvych8PvJDh4tlRwO8kF2X1xg6y8Es2D/r3ofObFBNUW1l6z/ZzVkDxni9NBVDd5eMCBiP0zL7BubeucbK1H95xNBF6m+KItYfmlN+maHnQhXVA8/QpyvblM4A0On3pOjWP3DhyQb7oe/G0B1QU+v0mRzUsu7jZTmo72nKneC0EKHwQw9jwElIffmowvEH9EZfLJpbT6sybRLpDN1rdPs7ZuidcS0sisY0OH+/VKUJrgM6ug1dH/MM/J7a0J1dl5lLCx2v6Hzum6Jap828XKr8e+4OXS200A4a+sYiZOAumWNgiRH6JESMZqGljUUODBQoms4e4tZyq+HtLlv/t6q8c75OlkgMgiKOgJ1mMFqG8n3ozT8flOu2eenQ8roGxxdgNr+tMXQv49DksoDo3Be8aY1nAC3Fi3JwOSJYa9/YuJ2inuA1VeTF0OZNckcVjjWgW4jgrAPJ11y1U7TNK9axMfOrZzcB0HNYtqH7h3Zl6NmG7hC7AM3MmKb8m7swscaCafA0EqNyZnZnnJ/YSalsPKNUGcKEKdnQo8kFAVDdDcpaTSN27kVLCmTJhg7Mi6KWntZRfGoa2GPlH8NkQ/eL3L5Y0oFpceu/ZIbOCS3Z0CcvF87dM1jH0Atik8fQ/GvwQjuOP7Khx9230zG3kWfe3P48flrZJtYXvEKKYL1kQ/dHqzsO+9fnroQ+zR3Y0Je8XCKkJnZRjEGGnur7inmnqM+axdnVhi7YACKWX7CRLzN0yi9c8XyabYHcOT0r1rDm5RLNGhbXELU/FWzqcRrs3n/hgElbOtiIA1K7wU3qbtTOy14u2m+k27u1jnjxDwgsGijrMeVLymd6jhtzlj3YraOi7zXiFHShpAZrI6UNfb60+pHocKIjUd0WY5ZCjTTycqmmI1VV+tmTebAoh9D2ifGm8oWxH7LWujIvl42PAAb/scllG9I7inD8Ad1REHE7Pxc3FkV72ApzmwZUAwZfX3Fp9DHh2UX6wMUOzM0Yuj7HjKhwW3SPBroXwKJLExdCiZnUXS+zO5DJZWxDNwmNoQfJR3UYFKLZ0P0Aj+2Xfc8Dgw9tsLaxSN0yVZkaQ+dWsoEN6EvklkO3oburrLzF5Wf56POcFrVhqh+tz8GiaMHQOV3/TACuYh3Ke7mE0gnHs5BMO7GsyEHonh8Ds2JpXgKON1LyMb/oh85jmsePcCJckoXZ/WGFYw7o89/e02aOITqQQtXRR6I9z/UAMJ+E3JQPzkmVLMEfVz9wsQtD7zb0akaQAWlXhj5dY4ZOIE49uSpn1Wm0Tr0bYwFPgZGPvVymwJ4ByYYuQV4w2xIXT7PO7ezLsfqBCyi7m357wPQMncFj1Ybemk4wKV8KqthDm5ReLpRfnBkaQ81K2QG6Y+jTMbkttgb/2uMuav89mUAGJhf4eL0uJKepIvHRp0VKQ1gGGz9u/wnCYjmdRKeGbkPvgK4CbdMaRuuy5PG6f33uSmhK0bQ6iQEC42/4MYTE6ZaPQ3nBprz6O6UbdEHaWOR+141eJcrLbclmmeQO9/U5RhgoQ+802JtZWOaCT4z80Dey7OXC7ZPYT3gmmq0SMHXm5eWrWJdzW5Q6noY1k4u0rfUF8e0SFajfzrI8irdtlo9S8WY9taG39dfnxjWRoAgBlNdCjH7elWsiBINdur0t5w66ytCDDX3I0LMyylKrDd0amhVGXNjmZyPAR0Xd37dTuC16c1BD7vz7D1zsENQMohW0QTeNYO2LRZ4TrtvQzWILjBiz7xFp67+TpcwkpxkZumMv2W2RL2SfZg8WbqiwsmFwX5iJTOcVjZcUr8szZOihHeZn3NsWW0zLT3uBqv2CyWWlneuFKw8GUzGUMetAFifgpD9r2augDN1byai95tf1pn4Ujp2hkxwlQ3eAXjF0EEOfLpUMnQmEHl0ZgL71v+gR+pdlHH8k2h99StwHPFjrTC7vE2DFM1bymaHP8anrc8p1798z9NUwKUNm6NEPPT7AfMqeoYNjcy7InOM5MHSfv2dK0+kOgI6xlwvbhJHu+h9RgTiAb3EL8zIQebOKj+QZesXIRoDOcXIdpneSCDWJky0r6KpORu1clde3dTMWSBjOjDw+tZsNfQYfl4IXu68ZBJXKuXU/9NTXODZSm+nR9xBfR8mG3iJDD8A4ExHZYeu/Ixup4/rTui4982YZzIsmLopWclg5kjmlQ4ba0Ldh3HhFniRclP9wwjEH9Fm3D6bdmW0ZjFmDb9wzI+bW9KvrCwsbcQq3xNDLTKoQFj7TtDVF94BvzzXEQeNs6M3iLTEhwL+z2892Zh/1MLCdrKHMrGL5mfKbokGe/k1PBpo4OOmH24h1Dgyd2a8qLAUNk8/zzHvG0BfaejZfNHiTRGVyiXJ40FUAqj5wQfXhbOjTpfxyru2AoZsicASr4kgUT8O2SNOVqqhM68niysGLyQnQCzl8Wh6s7Z31RIRaiItZqZYmlz1DXwx+zRqALJtceFHUnpkPK9MuiLESnzdH8cw0fuCCR9bOrkuittMivwAAUW43GAqGXg0QBoBof0URPyrUDfPoKBsZ/c3/PDJ0/9DID51NHks2ScfWkJVurNX1ty3aG4FExCmcCD7efXa5vfu7XEZMVYEpsOIWjsbQ9bpvH/ZKitcUfrkEoHJFk0ucLQxt0q3vDnNh+IGLwTxlcZc2A6qIS1u5ORO5RgKOXioWwbr3jTTTZYZuLRGD9a2jQ/RjDeiAwO0U7UOCB1L1lHPa2zkv3daxa1j8SPQ55l4B+rk9D1SdTO/ydLANQFRD3lhEgC5bRCAID+8uNMZ+6JrUGvvlhVD9vUt+dVqYP4xiaZp8EhRjgKVVhr58X/MHRj3QlA6rnVEbVmohe7ksyegowfx8QPR+fWRDr8NoY1HPuShQMgOGc13jqOKNR4XPzxZFCfGDkmnAbKuvAH0s/2GFYw3oZb3QtHr0kWjV1FsU067BVLzHWGiUyFAO6yPRlG14fW7uNg680uqUZ3/Oy6UDQL3JyOXhzjMDHNrQ6W/kKtVSkjLSKKPGE5UxPMN5J3uq1PE01H7oVFaQDZ3is2nBxUZeOAAAIABJREFUnrF7a2NYvZBik1nB7PW5WDC5TGkxu/RtWDN0O3ru6ZlrssU3b3KJeN6Z8YBZex5uv4bvQ08sOKeVbehTpU6laSkely9iQPrAheKHVC/nsuPI5LL3Q18J0YbewqJoZj3ERNBco/bOSPY/9+RsyuEBPAqRvQEZHHd1W2Q/WicoFKACaObxVebnQSYy9PhclKmFc2LoaDSVDc8RYmQgyuxO4Bl6tJX3D1y4614xcB0JyRTtpRpqt0Vjv31j0Qy+mbXOZ83qqSG7V8awbZWC9qpT/ay826I/qicWg1Dlcz72ciH0DoPjwEkzadJFG7qoohu8nIsA1QP66BN0Y0B0fugwRO+KV/+KxYuSp5frab7N48n6By64Nizsd4quBJvmWneeeok2gK8407CNOnEAAMQTu8Aml7JThQ6RPhIdBvwuDF02G/hFowDohZR8fyk/z9BNUH5N6U7TW2dD33JrFLJ5IE82dI7PNuqCiUvPumCbBNwMNNFtMQq5vrFIGfr0jxdFI0PXpLet7i8xX2WTMV8AkI3a0KPC9fUYvVwyQ5+fq+zqTsrM0P3bFmOP9gA9HefnextGdWXjhdPJ3y5Vmf3Rp0WAKjQORBXGdDe6N7K8sRwxn/xVKVKWDqxrsrb/wMUOgaf8uujGA8kHBXHT2mnqnYliz4nBq2YJmlbO/x5/4AK8Sg/nKaC+2C52vD/IL3u5EADQM1U5udNsxMfaOCCIwpmAEUIqM41n6HGDzFT2CHDJZEYYKcX93Ri6xm2T77H2G4G3ofMzZK+NoFoF/WIRp+LAkvpB/T50Kw8rv1Q/JUO3o7ehe7JzEHeFtuiHnskRM/Rt6A9Dhi41LFVqJ6aVvVxUYQho6ccx9DhuY47Rht7Tbn5m22VBqxLb29DXQmLovQPmTjtfoCe9ySVNxQsw8gysgPxwKebv+M+uDF1W/NAXlIJn6L6TOa7S/BQd1PHWGLoVhu/5ge3lGTH0zJbYhl4zdA9mU+oSjtymRbwdbOjEa3tuNkMgZhjqpZv+sG5yWXof+nZWXjKnE73FOW7f/GaNm8HGPWnXhl4us1Cs7Db09aaeTkGOnA19UAW+fwcF5Gzog3Edy0OK0W/MIyXb1sd+MqfQGty0tyCMm/mZsR/6kvyHE44/oBNDn1pyYwMpVRx33PmRyCoGzG2qKmOJ1Yp9TGPpI9GjaVlOVEog1Ct5ulinmRk6/w42dLsKFJ0z5sA+zRts6RN0xXPiy5Fen+viB5OLY5oG+Es7RcXRXu/OVsl4TiYXCX7oob2zGhiH7odegHXvpZIZeuwX5k5ocpTb/M/FD51k5BBdKOPYMRPbyutzQyOMbejj4P3LPVhXNKZ1+bLC53YDmKGrMp9TYYYewL8a2/cak4uIPFVErhOR60XkewZxvkpErhWRN4vIzx+umAsh2tBBHXDhAxd9YIZOFUG5B1G2V+9682lIyj+C47kx9IFTlmR+7gCR2V7IL3q58PRy9JUgSzcM7C0DuueDsSzxWmKYnkbTBy6SEKrOyxwdSNkji/UFFH0G3LtsZqeM2eSLNnQDj22T1VG83WYFzeaULnvzfW+0BjHyqOiAts3XhjtF54sH26TKA8HIynJKZbQoamNu5OXi2G4AT18uvadeLpa2MnRp3ssFJCenEW3oHdC3XC6Zy+/rWRl6ubFI6/wIEf3kWgQROQHgxQC+GMBNAF4vIi9rrV1LcR4F4HsBPKW19iER+bijEpiDByRADZvjjUXccZffQ5HMJ5ruWAGfE0OPjHkcFrxcCjlHNvT4bHSlY4ZhIFv3vTSsmwf0s2Fgu+ciQ08M08c3hu4l6QM1Kp3QCCJ+wCYFHtnhIkPvc8Ke1oh18dQ7mouq0N/lUuRrrDPvhIiKvmboSE/EL5P28gk9GGYzB7EQW9tzwPGYWDURbIbKxZ5jJTX8pmg/VrNGZt6+nW1jnmfom/6sl99MeV7uztBBM7LI0Hu7F4B+L2HonwXg+tbaDa21uwH8IoBnhjjfBODFrbUPAUBr7f2HK2YdjBURyoq4gRSfmGLRwIxT8N4ZM1I6t8WSofujA/AwqHf+wEUEQPEDKMo58nKZ0vDnlZcLA0CcrlseY4Z+7jZ0L1u2oZssMS1140uLpZS38DXx1ysZK/ZXmlzUNtssTuWRoffWbeiz9CQQz16czX7RD312W+z1lv33o4AMaOzBYe0oqUzThS2qUvlxIMBgVsugy+kMv1i0YIt3JheauXJpPKAXs/OABVyHLl+xVKKS6TSxGNsxvaMIuwD6wwHcSL9vmq9xeDSAR4vIH4rI60TkqVVCIvI8EXmDiLzh5ptvvmcS+xQ9Aolf1hkzdHSG7vnumKFPeQEYfE7LpTEfk9ti+L0TQ5dN6vCc2zJD98FPqKOXy3zWqm4a8w2AvrMN3egyg5WXVlx8rcPYlo6h83WJRxq4uKc2dH2+9V2AqigsvoAlYZPLaKYT8/WAqmmanGrC2M3LhfKmzOuNRZ7o9PvBFpEYethYVH08pAHjD1yE/qhh2+ovFkXl79MK6YQZmnq5cLxMhkJaXVmrXDxqp8aoPnDBypDDvYWhV6gTZToJ4FEAPh/AcwD8tIg8ID3U2ktaa1e31q6+9NJLz1XWgRCZoevv5UXReWBGABjm5hlYuSga0jq0D1ygYmIerExK/ywHP6CCl0swD+lxFzKRbehesZk8JmFm6FkJsEkjAboyZE4EeVCy0qsYemzx3RZFDSjcu1zSougsO2S1HvVdLlW+3eQCBWsGwihjcyCeFJ6OmgLQAUK8YqYVAb1FQNcj1bdzWwzlG+iuBYbujy4tQgNvutI1KB1FVO6o1MPv6GPOH7iY0tsmWRr85joO95aXc90E4HL6fRmAdxdx/mtr7Uxr7e0ArsME8Eca+hfFkw19vp/wnBm616O9+ge21W7KWdCyIw2v8b0JptbiKU1iZkHSMNyc+MUdL/OkBomhk1zMhHYyubSDcK9m6Hwx2dC1CV0+40Hc4Ssx9NB+Yj3C2dMHs4hlkwu5u4b4frbn+5af9dRBCfGiyUV0p2iWzXu5+B2M9ccs8jU3eohwRLOfJbENda/pcM8cuy3W/HjJht7c0T9tswDfzjZ+2Dy75LLcVTfVIf/mmQePmzlyWboqvaMIuwD66wE8SkQeISKnAHw1gJeFOL8K4AsAQEQuwWSCueEwBa2DdhbTnGxDHzF01dRqb+vPomJwlBe4UxUxQgfZBkSPgLoLQ4d+2EA7WbShpyT8/VJAaA3o4A0bJDqI7mhy2QaTS5KEs1dwMDn46Bn6gsmll70GLDtKGLBSxtOw/GV2BgNx8tmqjEU1hr7OyiaGHt0WvZSq4KJ93iRDlCL1u1WTi9CDoa6qt5cuMXQzgdZeLl57GxTdE4bOiXI9GnnjUWSzHn2C5R4p+czQgYjjbH6M4V7B0FtrZwE8H8CrALwFwC+11t4sIi8SkWfM0V4F4AMici2A3wHw3a21DxyV0F02/dtraAPTn8Wuv0YdNzCttUbtQ6U3ygjyNW7YKRqAZ0b0lRKiA0cFQdkKmAGRQ+XuRtLNcVhpwaNBzzcPbA3+XS6Rg7EGigPCDy6Nse2DKcrAJgi6HlmXA42V+0U+XraZAfdz/66Z7LY4n+/wgYu+U9QxdANr9advrWawnqEbY4xtaDIRoAuPix6B2tFk9C/Oigy9VpZseuKQe6/ms/zFoiokk0tg6Fp5MR6XL8qdbeh2f/JyyR+4MBqfoXUb0juKsOq2CACttVcCeGW49kI6bwC+Y/7/3y2wvgVgHXC+uvSBC/01mnZlLxdTBJSjjxLSim6LSZJdbOggW3HMt2DoSymyDprmNcbQO3FDXCCtEoq/axt6DLUNPTDMAMAjhq5lb/B1m1gXPNBEPhnbebf3oUvPf/EDF/qxcsigIn2+Xj4/ixGStfZD574fvJYozZqh27Fm6EpQmi/nkKGbImgikMav9SJZpP6xLWuBrpRmQI0trh6VrZsS5vaKcnv5I1inj0TTPW+orMM2aogjCMd6p2inLL2BBbxTdGSz837ogVUMmBswpztYsXfPzr8Pw4Y+mZA4P98R88Jj/M15eiCobeg8fWyDweOvua/fiHHTUtn0wWJy8DHg+aINXaBb4QsKygyty1bYTYOMtQ1dk7SJO88QNE6EIZ4p7mZDj26LVjfdFhzMYNlzpLkhkWaGJfAwQyclHxh6UvBt5Ieuskwpbno9RFnrcjiTSxozdRslt0VufwG1HFy8KU4mAZxPbUPPCpxlrMjavcWGfq8N5vsbGfqA1QWTC1D4os5RU3Nop1562yJ8B8mfoKPfZSZVotNXmGovl3WG7n4nG7oJx8BUvajLhwDowYYegcCyNwWavVw4jp2v2dATQw9K1dvQ86CN9bXm5aKAOeU/tqGn9/jswNBV3pgvxGYXbmYFrj+vnL0JzYKBFTN0GheOoftntpGEpDUW3+46I5Ph1v+ovud8Bgx9iQPnjUUBnDsM+3gcJyp5JjkA9Q1VEER4opQV4btX2NDv/YF7rMzvLZ/C2jdFK468ZEPnnaJVg9H4S/mzKQPQRl1HdGWYVEQn0Uh++10ABCIwRBu6RarZkA9xp2hlD+/PDRh6VRds0sh+6AMbOj2rR76WGbrPd32nqK29iIsfNhaBiAXinCYH80PP95h1mtnDy8ZKxzP0oPB6Bx68y6Un3BC1Y8w7+6GH45y/DPZuFL1jzofSLFkwUmDgdmNkXoMymGUm7x+OfSeCtd8pOt2JoG80fgHQs/iHFo41oLdpDmoXRKAv0QLyApcp2NyoeYAnZOzsDMg+tfwELyIthl1s6KI29CyXssSlJGuuo12bgIFQ3IHBDt2vbc1Gyu9yycrF588ylV4uWFgUncveAqKn6bPwNQabuu6XXp+rabSeblgUHayZNKzvFNVFUZ+vgbXMMsd3q2cvl1aYZSolVYUohK/L9F73kQ3dtSU5KUQIrwl6eM3uucFfr6vQjxrEtQ/3gB419J0Y7PW5krGHmH9INT3/0d4peq8N0eQy9x8D7CFDZ6aVgaT6rbbs0TbmKYrvEHGzjh/k1fygCOI/cFExIhd9YdDEWYVheME0ZvmX7JVFSpim1wagXhajoLssinbARm5LnhZXW9stHRq4kts729AXGLrEfkPyFXXrbejLYXp9rtl1OU1WILu9PpfZrG/DmqHzuKCUkw3d91kZ+aETOXJui4MPXEy5kdui83IBxYm8OJerIbezmuY4PY0HPoZMeXxMB8IZeIK3C0Pff4JuNcx8qVeiui1OYfSBi+lJ2/EHeiraYEd5lYuieiwYegSexpkvhOjl4gYUzTCK2z1OdTMtihadrWHU+fzVRgVdcltkGaz/e2A/J7fF0PxTnvno2rS4z6GeVRHDV0BPDN2bXCYXuTlN1GaCmC+bh6Y0OX/p+e1icmHG6AE9JU6ATvVB4M3jadHkUipyY8bpDYQjhj6ohWWTi0E2l8NMlp78eZdli8u/eaYKMEOfrzVvqvSxlxh6lv+wwrEG9Ob/YKLn7IceWJ1bFEUfmEAF7IFxiThzQtUmGRz8APcMfZZ3JcjGD5P1l3PFBGKees43GnXaMIDKwRPCdmRDp2cSdQ7AHhSqni8uirohqqlKOJIkBJgj99S1jUWzDulA4e2ivn/YTHG9nbvbomsvA2s1X2wHC5E2AvzLuWL7GZOtbOgMc1kxp7yHNnRry6ke5q3/URZXLfZjaEOvi+Se5raZrvM+jujlEuROY9+Ddd5Y5HfkusgLNvSjDMca0CNrls3MZBTQ886i+SmdOmdWsczQcW4Mfes7ox8MKBs9h02woYc8I+mJNnWXJTM7371VOC9zcAnsaQaG3tiGTq5sDM7hbGhyCTmpPLktYSYI9tiIg1T8gJXQwEkJDxY+ts3Uh7q7ilj8yNBbs3oa7x30+fJbAjXN6Wjsecov9wU2C1FzIm/9zzRxlaFTfx4RAY7HYKofV6+Cx3ODogPuLdW6RAmM3A6V26KNe4sdlP+IoTffB70JNIqkrV0AOo+tIwL3Yw3o2YauDH2+n/Ccm7FNzCmyCujvmFuttV2MwGiSV4tj6PXArNKc/K31OQn3aiktDucp7rwzx3LqiGT355RciK/PLZSiBKSNbMsAyTO+0TTbXlpWMzaTR1ybGthkGat8+vU5rnNbDO3iwZjU5Q4MvTUFVK90e9qz7LwG7P26rf82GGBEL6CqoJ6hU+5hTEyPcJ7BDz00vM4q1Msl+aEPCM12CEtxHkRpMaCLJ2qdm7ccz+TMYz/1UUe+ZZqhtDpObUOvzw8zHGtAnyp1Qh3+7uJGd+gtLor6QZgY+gAZuwtW0RdjWvlti4Ft7MLQ55FcLooWSWQzZR70mo7j4qFjxnOXZqjXllzgCnAOZ5mhS4g3na+9PnfKn65HBS1+wOb7vsJG02LzY7Z+wyahCDXM0A92GL3bGdFrBWysk2dWI0kZxKNSrtkyjQuH3p65ZrfF8DsC4yzrJtWOj+cygZ/RnLvbok9OF+K5/YCsgN0zWr8hv/g6bD7Ls4cC0AfnhxmONaBbN5k6nwDOxpw7EAO6LooGVtGBZQS2CjBjRI8avkvZ/O/dGDoxjPDM1FcD6wlpeoAI8mhcsu/H983s0vFa8JjYxYZeKaj4UF98QtGWc9kTcw95C1+THRg66mCA4F+fyzw3mweMDa4FmwEM7onOCNqw7tQs5F7fAJ0NqpR6o/Jy4f7UuNEoLS9ZteCa32Q5j5mFvsklH77LxXJFDHGnKKcq0Pr1JpeRcjei4BWRKQtT7cmGrseiIb3X29FA+vEGdKJo1kDWIZc/cLHM0LP6nqpK30tR29C9Msg7RVmUFnt0GSR84CIx9BQ/ykR5Joaeld/iC8V6mrFeRy/n4mcyOLgkSoa+8oEL5MGdbeg0tabBPmrnMUOP/UacfNnkYkmnD0MUQT8SzZUWF0WnGQHKvsB5TqxcmWMNuhxKCjRg6I5Q7PSBC7OhL7ktcroHqSZVpMCG3dO+Hdzrk0XrqoV4uc/xbyPdvg92gsV1mxj6+OVcvlSHG441oKN3FvIN7p2qDTf2RKYFVEx3/CxQN0gEk+S2mKZs64CuawKlAmHKOZB7tFPUwTItLC4pIQuBp8Wt/0GxOcEGDH1kQx9vLJrKnt0Z/ZGy3Imhj/oMM/TtDLCcPzPy6beBRzmbK/KNCppdOhV+2OxRKcXuh96v+XirfujMqgNAr7stzkceByLYjHaKVo2ETFpIojIdjmezGbtuimXcL5wI8zEqDnZbnKLR2lOSMoell/UdVjjWgK5aUm15zNAnppK7vD1pW7jtqTz96iEYbPXr4i5KOLbWsBE79wwdiAloRz5gty3xfujObRGR5QBLP0es2E0Y55ONqBKitKgju3TCBy5KF8Rw1iBzHh6cImeLG4s2YvfUBOHKW0yfnReD1PGsLD6fTb+tgOBfn8svY4r1Yl4u9SyC02+tOXu/1j8wHwXdxBSVYE9DAZ008dCGXlzL/cnXUWvNrx3Nfbq3SW8bD87s7bPx1V2Ggx22/sd0nB861aMfP6beFt0We/36GYFtLJLE0BsLx4nOYSO+HY7qBV3HGtABbci5ogW9IiuGbn7o6NOw3T9wMZtc6HNam8jqw8Pb5uNkrRzAZDbr8Cr/ZHKpJQsz9PnuGNEdU5s3YalgceFnIxksN1S3XnD7Pfr8VrSh9zy6bIUSEEkMfUPtxQw+FteORNc6z11n6JqPHg0GVJmLk0+HuQb1WpnSDP2EzjX9iaGbfJtup+2lmOPlfbEsoyCycv/L8h74oQsSKFnePgU1uWxCvGSbpg9c8HjwDL3+wEVpckHLY4+BOhA1g+mRySVggPGcnp+V37DDEaEkbwR02TP0taCV2hm644GFDZ2nlsS0pmuDRrUEp0Pjzhmj+A6ybdbxKvPFiDG714eKGCOgOD5HujLGcz+VFUE16B2gh7SH7KpFk4vlkSW1cjBotVB3GqIN3QaymSA4VNNoBpqodGN9xXwMLNm8Z0lsB4ysEXiwDX2SwSs1zdczdF83/HIuq0OfRlcqjWc2cZblZzzTUzwuQA/4MZG8XOa5hynZrLiiDX1T9gnLa8pntPXfTiKgcxyuY63TaHJh3TQic3HW6j8SjcDQQ+TE0KXAo8MPxxrQp5bSQaZ2TWMLuf64QaIfOuheCZXzX5u8jV6MxdaZfo6WBMoeHpt0nd3VrASWzxKAI8jY/A3LxzF0Szt5kGjdxnKQDf2EGOC44Rrom5qskslF/DOjmWwfqAMZWYbqAxcjb6Yqn0k+NrlIyp+BS9OpFgNZBpd+s/u97JpWf06cHTvOalRGdpD1/LwOeWNRZOhMSqgs8/vQ09hxs17vthjbl4TowW/Eauk0psNlYJdSlX0yzeldH8/L7eVnTyH+7fttc3FGbotxNrln6IPgGQVfr67Zvanj5wGdXa70GR019qKhxNBDxwawwtAjq8sml0yLIzjU8keZ5gzo+obyzxa9igGZKCH24Is0To7wW5mdAU/OryJhcXo/zK+IUIHJgOiVJhcJUsbzOOeJTG/Kz6+9eBOE3fMml1pOs6H7RmZWzh4vIBnr8RHp5jhvDiO2LPDt2gKz9lIPvimaHAkwr02Ffk5AHdPupC0AepY3Kkib5eSSzXn2Kgszn5D8qI4OOxxrQDdYnqFZBNJt3eMOayYXSVq5AmW+MLIHciQ/pVZZc8dIAK/T7wAVIn763e9IoXiSIsrpazxmFVG2yrwysqGnjzkUSjEy57goWtVdtReAF+CWfO6ZdVkOmU2OQlwUTX7o8P7OyeTSjBtnV9PcP+K9jZiUkXXG2Rr3Md3Jym8mdAqlAHQ/LnRMWf6uXImEELEJdRvdMOOiqFQNhrD13816DGBH/XwypVi+2v6VySXuXo59wxh6VnB9UZTzdWceWuN42i+KDkPrFStAuYNTgx/kAy+XGDk8rYxhaVGUr3qGnuwDoSTK0ANrAw2kAHi1SuEs6IrznokM3ctWM/RB5aYvnReAbhnPOWp69jvKv8zQx15G/Gz6HFmQbbT9vLahU7+RWNfB5ELyJKZND6ZFQrHrPHvh1zxkLxcvI5OH7OWSgwN3oYdzl0spWDtWdetJC8fNKRHwtxqWogmqKkPtnkg7RcXHy3IUijMO2/6X9mlole3I0PcmlyI0iL2asw9wre41hu5tcUYgfee0h7WVzad2BCgVcXNvwFP5o/apbOgSbOjObJKFWGboPmJlQx+lw2llG3o0uRR1GDSltlc0uQxIW5IrA6oHZ/Zm4YFrStfuVyH2Cza5dDAIutL1ucYgw2UKS4Ghr3Af4vUFln1kQ4eY2yKD35rJRcK9qF69G6IPpftfr2NO3ceNZY9MPsoLeCUVTVes7HhiwO/8YZMLSrk9xI92c/IXkKzGYtzlcXlEeH68AV21pHm5oIPioo2wT53Jdcl1wgLQgrkhrtj7NOz6ZqOdozC5xEbuJpfgtggC38DoMiCNO1IL/u3MJ2NtbSqbS78UYm8DQ69MLuGkQbDZsCkpy1uxZ5WrVGZZBEAsncjWY35VPhuyJ8QNadFLwylPeNbIQnKeXM9sxvF1I64cyeSysesqHzr4naPJRYQYem7H+E5zbce5aL4mmDRgct905fWITvFGW/8NRgWxvb2CcgpdPCMH4NxK05GU+BQ3mFww1YOUXi7bomx5PO23/heBXcm0w8fG4eCYGk2dp2s1sMen+5vjMHZb5IedH3qUPyD60OTi2FoEgCBDEpzyd8og+qEvm1wceyx4mv8VuVlmP5rHktti1YbO5BLuVewvxwvtPAL0ZHLRp2cLemCIE5Hw9l69vWxDrxV0MrnQU3HdIZlconmvMLl4KG39WiytypVTsKR5b4A7hoejycUFx9DrPuDAkxQcl6GFtlG2Hhm6xpviDMZ+BGsnqsAx9GRvD4CeFOHRhGMN6KZKmaHrgK+qzJtcOIkM7DVS8hfMhwzdAbqKWLwXJeUxtqH7EujNyAszCHqG7q97i68PWVkVdaJPR4ZeZC6hwm1RFP13lLdCdF6AS9UXlF1PLwxuTrxaeOV84qKonRd1HWq0NLlI3T9UIqF8zSTmyxFnNVlGzxzXGbrdE9UIKix8HS0tikYzlu9jOmZc0k4yDf7dN3UvreofmEgS37OZlDjpl9bPbCaU2y+Wizc7uciRoQdh9zb0IjRgtudWfuhjk4ttELGmHwE8P42en9fwPkbNTKsGrAbHdKRmkfiBC89est4ZA7yf+tOiaGlDj8qKZzPRdhRs6OLrNEtt9ZdMLgPZo1xTyxVaJ5xzPGa5aww9vdse3uSSFIqERdHmWaOJFW3o3Cbe64pnL1V5TQla3zAvF40TicSSycVaB/3KuI66bNE04xSBPbzluDEhx9Brk4sx5pZmSH5/CLUvbIYrIR5CH4iyJXNKz2tum5YZ+ugDF4kM7QG9CpPWtYrNAB1jWyxvcokgNOpw9sHbgsUGEADOzW2xYuhKzWq3xV28XDg//+yyl0tOt19KBdnByyUgqLK1yNA9q8+taAxvxculp+HBO06rR1iVGXroNxmag/KsPJ1Vhtw/VBZ2W3QmF5I9e7mYjHocfeCiLvc8emRgQ3cxl9ok5CH+ad67kdvWfh+EjViWdwBtpyh59pTXxkqTCyl6J78+k8woLNSswAMx72drDP2IEP1YA3r2Qwd1wmWGLrBBCsROWLGSOd02Nrn4mFNYcltMDH2OW9vQ8zNUXIofZaEBRedua3/phx4ZBg/CUI6BKakCWOOAfut/pYir2uWNRUvKy9iWn1rHwTuin6Ot/6LnEh4V7VFT0J2J+iyXqeofmoSZXCxmC+WwtzD6NFRGx9Cb1787mVwWGHptcpEyvgBu3YZdfXOtczwP4/2MGHPQFURN4Cp5GiPi2k/lDmJTPfj6rdwWtSekzUeNY1nYuy3uEpShsg3dN62P7gA9bizSODWHQQCzclG0UAY22DJoZp5UvZyjF7UNAAAgAElEQVRLqAMFtuVANsqfZfHPBj/0NUB3NRMiB7fFbArIAGpA4MsVLBApxJdzRRntHClenIpzvFE+GdDpbYvuYUkfuChNLhO1TPlEWbIfumebnG58l8tOH7gor6GPp1nYQrIxoNcMneK2vIBaJTvcWNSPLc1Oh+sbNH7ExctkDkG2+IELi9Yj0LgJijIx9FhvRxOONaBPJMi6rGfoOXADWiOH+AUoT5fneLT1fwSmDlis7VMjjkwu0b3Qm0dqAIj5VXG8DZ390KtOGy8MySxaNLmUbeDl1/YyFpSfqRYsGTSWXnPg4pGCiWAzKlOafve0mN0tS1tRCwc2SWZvj26hrow5+mOUkZXz6AMXFUQLGvxMI4Nv1YczkNs4iG6LmThp2Lh4UTYtC2AM3dUdA7qwDNbPVv3Qi7L1DCkI0D9+PXJbTL0/Kbe9yaUIasdin3JtyDFDBzOt3qgeUNI47/fp9bmbMkoJLGzX1JBNLks7RfMzlR05i20Rsg3d7qy6Lbq/oW5T58xAMGLoGZyyMqzkquzrFUhBxA3Y1XYO+UT2K0I29IDMflHU22tZsOpti10+uu7rRlxf4mMyuZBYDR6EV/3QJ+F7mVQuLieHJYaOoPSakHkmaT8C/sGiKJebFVxMLi5+q2LxaZ2LDT2LmkwuQcY9Q79HQaHu3L1cuj8xpQTQgC86LgDn5VKDXszTekdmNzWnW/JDD9iQmM4SwHuTC8FHIVtlTuppp0XR+uVc9YCzGl/7wEUV3AcukoySzl08yXHHW//90azncx+SxMES+NReLl5u/24Tu1cuitJvLpD/CEdQzgHRlwFd848MvSYF+ju5LVIbORt68+03CgeFvAACGx55uXjzlJapNLkEAM8zbJsRcOjEsbFMgaonQPdpfFRt6CLyVBG5TkSuF5HvWYj3lSLSROTqwxNxHJpOoZsNMs8l66BQVrlcFWN/vu8VxeK7XIpBOpmHKkm4POsfuHCbkST1m0WAX/JyibKdkw09mVw2Xb4kR2eT2U4c5a29XKyhUlmLc98nlj1jqnzixyNU1qRQIgFoHJ+jeanj+8HNy8W7dArlkb1c5t9z2v7r9N6DqerfVqVzyZYYegL0YmORUwQR2HI7TxdGH7ioQisU6gDQXX0HL5cI6OE48nLp45nuWIx5p+ig3CbJR8nkIiInALwYwNMAPAbAc0TkMUW8+wL4dgB/dNhCLgb2Q2eAXmHosUpH0y6LMN9X8Ko+Qdfz5kE6K49zsaEH4GXu1xIAlGKWv1u4wTbCqtPG33YtmI5G77xw5x5KdEAlk0uou5QmgUZuo3zO8XiaPmznmI8ObtCiaJsqIy7LxW3q/CIoTndoVhKfbwt1FUXtPNrp+ObexJBfObFicnGZZPCtZpm1qSVTqyUbOv8+GGz9n8rTyIae+4rOu3ltzDN0Lofvc54E0AwpMXR9qrKhh0Tqn0dmc9mFoX8WgOtbaze01u4G8IsAnlnE+z4APwjgrkOUbzHYot7s9Ztokw+xE5euS4MOpxE2C6/PjR1iOtdFzWynrqavQOGHXgBfv7UA4Lkcdr4JXi4xVGWrFikBUnIhnzhT4ZNsQ08ilk3pvFzKXPU8x+PuUS1gV/nEbfUqa+pqhbC8AMcycsxlGzrnxzZ03xdYRo0PetbLVIXA4Bd2ila1Htc1uKm9LNne3u+JjzcKqqBi+w9NLqJ3pYzHssS+MbKh83iMd3v6oYD3Jhv6wwHcSL9vmq/1ICJXAbi8tfaKpYRE5Hki8gYRecPNN998zsIWKYLZNnenqku4gQ0bKP5e3eHSlBrZLuaZScirZOgRfZfcFuvyLDGdQmyXrlOIayYXoQEQFdPQD92DFZ9Fk0vVbouAXtyvmK8DcQb3oMhH+eQPXOz4+lw2Y7NNmOqR0+/yCV8nZSIENIuA7onDeOs/X7PjlFS0oVNZynFQ9zkJjeTMM4jBrhy4q5EE2XzcKX8Cap+qzgSt/TReHr6+vKMPXJgNvRWg3yiOhXuTH3rV5Y1QTW95+hEA37mWUGvtJa21q1trV1966aW7SzlKT2aom9/WIzQidlkUXdLS+WFNd/ZyabWdeYrqelrvUGs7RVtpctk48D13hs75iYvoDQTr6fihyQnHj4ZlIMg7RbXuZfxMNewdOI+VFwM3s/FoHlhp7sLkwozZ16ev6xpkIpzl8lo9OJOLk8UfLQ3p5MHk8AC/7uUiiaH7EAG9GENU3xx/27heYwczKNrJ5BIUqp43qNK0hhb49rN4QZbQN87Jhh6RfaDkejmOiKPvAug3Abicfl8G4N30+74AHgvg1SLyDgBPAvCy/z4Lo8zQI9euAF2PBOiUkoubAM0DehNJnTKChZ4LZLBTtJZw6QMXHhyWeI49b/l5RXEuDH1STANlOfJDL9FSy5EX/qa7NdhFudYWOHmwOiUQZBsp8NLkIkhEgHOPDN164lgJLzF0Z3IhhTFm6JN88evynqH3O3SNchJ/T+XKT9nv5Q9cEKBDFhg6XLxRaGCTF48Fz7xZYdtOUS6rt7O7Y1CcsdACm6nkV+tufSJzuDcx9NcDeJSIPEJETgH4agAvM8Hara21S1prV7bWrgTwOgDPaK294UgkdsFqvmvchQ6ji1Ta4F5L69F3Tnp4OswtwS5YQZrMTEWZko+/sx+65IGk+SxtrmGZYn6y8Xwlvcsl+tg7QYNiSm9bzHUooXIaBJsNs6CsBKo2VLkqIPYDnM/tKCHu0Ia+8ccpricCgaDDtxJP752ULkeXvph8m00Gbp4t8LGnIerlwlIEkw9sDNg1O07F8Ax91W0xtIlrm2hy6bK6ZFwefmNRZOizshQJfYWAWrwsfax3dTCYWQjXhIF1nr1ONcU+/6tb/8N4OiI8Xwf01tpZAM8H8CoAbwHwS621N4vIi0TkGUck106BGyky9F02Fk2NH1iFxo3jvI8m6xBj26EHEx3ru7+ca/yBi8T2ilKOfnJ+TvZztKHnsMMHLtKz9aLoCAyiXKUyKx518ajChu0c8rF38UywwM85aJaNV57Ns0aWa8jQqT+6umniyhH7TdxYtHU2l6hOVkwuovA3XbG/cNd68gXrZtPjzgydTS5cX8mRwMhHpZQ6eydSoTOFZHIJz476RGLhc3rehu4RPfbNzNCPBtJP7hKptfZKAK8M1144iPv5H7lYOwaRrrLVp3zJbbE/tmByGU/F54HmbOgxRgGvoh2glsT/HH+CrrOG0I0TIx/jefCeid8UjelkZWVKL8QeMHR/xVesmhHO3W0xtpiXMZ7H9EyO/EyVD4Po9Dz3NZ953lik5wMZ4OuZFTTv5G3hGQZ6n4a60nk5XLn6cWRDR8HQfTk5aDvyrUiOOPLahi5gvPW/i6Y2dJcGM+9oZptS0vbjeCxLlDu5JAaZaoa+2+tz9y/nKkPh5TJiAOCOO4VGPyIADE0u5La427tEpn/VBy7y9HWXrf8+jwRq8TdPeeMn6PR3dlYevD7X1RwJXn/gova3NgBf+8BFNeb5Va0jpcvnafq91s4hn/LjESVz9SDpt/77MnmGHtKgfJMfeqrDKOMUh00u221EjhWTi3DKuY5Kk0uv32o82LWtixukEh9Pw0Yy8mk5qzIkG7oYSngzWFYacYa9/IGLaVTy+2VSJArVFx2PIhxrQC/90HsnHJtcPEOvQXkEFkJ2tZENnc87Q2+5Y2S3xem3M7lsNoAYGCe2V5hGRjKFTaaOT46m8Zxuv5RsR/VO0ao+jKEP/NAHske5pLhfK1QP3nnwFpmgMLkgeLlEhRJNLuA+yG0WbOhO6QkBet4pKqGu4qKoQhebXCKeVyYX8LgQLDP0FAqTi1h988PsGZbbjl/ONaavE/eYR67rzzYuk+KWgckl9IHkVjFg6NBytWIEtdzmwL1rUfTeG8SzJrZB1oCOfi+7LYZOmbLy6VY2dITByfk2FDgY8qgWRafnuStyHnmwLYGcf23AmpdLTpfrzws+Yuh87uVXhcgTfx8vKyeWK0+5lxVqOi8lzvksfuAitDGzSe86GNvMfi994IKfZ9mzlwsljuYZerKha9TK5KL5j23omaFz/jEPH5/jjk0uUni5eOA0MOb6Z+ZtvVWZPLefxmODKwDXTwAC9NDftVys+6yavTLUsP/AxQ6h8yV6l4tO3ar+4juuNTLgO2H9vHbuJT/0fN53irbciJmhexv6tllZIiub8li2I2ucOggJnM1BtQ19kFb0Qy9YWD9nxis28CozRpUbs78FfRpMXpZeXiupy5Rt6KpW641FTfxQGppcBvl0mUgux9Clclv0aRjI1Iplyn/J5FIzdC90APQmrk3yYxZ/6+KGQANvGz6eHt1Bbet/liqbp6wuPUPPXi6Wlq/fkQ3d1ItXOTGWysBhz9AHoX9TtKUJU45bmVxSo0aIh4vAXyzaDVBUeay7LWpzbJsCu6VRmSYk9mpkAHcMnZXBhtCjrb9tkVPOrmSRoc8ml2rEEYCXb1ss6rCSKwKql9CDS83QB8AS8ok2dEcEKkDZUv9wrFFl8IooM3S7zmY2bupscuFSR5NLZOj29Pjagg09AhOyXbz3Ey4Q9IV2Pq4JMepdQXEiKzh+ypi4JqtzDlPIMV2Oy6IM31Ek1hOSu2Inl76AmaEfTTjmgD43amvzRh9mcGsmFz/tcp0QRYeDT3fbqne51IACwcCGHn53pqX3NY2ByQW+s9dy1/lNtsVNv1Nvbw7pdtRas6FHSRnPrYzsF1Iz9FwYZ4MtZhH1udXjejv7vLOXDDN0zkQ/TtLn6UNq4QE9gr3l6+qG8ssmF67TaHKJ5dJjDWwikhi6r6MI6Fk5evMaKYOWzRyW6lwG19ezrOpcwAqO4xhDN5l0hsujq/RDhw+G0ZXZSiCl26JGGmNDleZhheMN6KJ8Sd/AZh2oGqeuE+smo96ooVOWefmOM/rARUxgiINhahk/Es2eH6XJJbC9KrgNG/Oz2xkg2OyXGHqxsYiGZijIOXwkmmq43jxTVBzLVYBzFZ3BxePRSjtrPmFjkVGA6alk8pnPeTPKyA+9Ko8mwQrH3BPh8ouAtyFkEmCRoW9oc53lyzNXld5icdxMSoqNRUUZAP9RmCWGnsHeGzRaFCqVxytu5eYbiSYXr7STkm/u4ETtDF3buA/QwU7Re8vGontz6K5kjcwnCwwdruNGP/T5GGynPcy/ux86drWhT2m11rtiStN++41F1bDK09Egw0JHZ5bvh+oOXyxyrCdpJqTIIXcJ90ZeLgOdmJNGUdbAdnsaNFCjHCMb+uo3RSXKp+CrnygcuMiJb7NYHgYVVuLedGbXOQ2V0e8rGpgNCpPL2Mtl3CrsHFDa0OlZHzdLhBC/yrH7ocPXY2TeLINQJ4imGS+vL+/iy7nE13W0oa9vLErFPJRwrAEds5YED7IdTS7AzJCl6ITIHa6n2wdsbrQKbJRZNawz9PxyLpMtMlm9vgRqUSbufKz8qt6VPUho+KSCxC8W+Tr15wp8s6LTJBafseBfn1uDsS8Hqy9ZbWd7Lg5uU6mVrNHkwoARTV0jkwvXMrv8mQ3d94Gh2yLZWbzJpbKb+7pY83KJjaL2bH+L644A/f9v79uDP63K+z7P97cXdlnYhWVZLgvCAoqsolDAS4wioIixYma0g9Ek09HKaMzN1EbHGcdmpp0mmSSdTp2mMbVJbVMTbZsyjqkasU1biwQiKAQvICoEBhBlue/td/rH+55zPs/lvN/3t+zv92PX92HY7/t733N5zu15nvM5zzknRWH7bwX+k55v6udcg6lvATM79ZBLZteWiJSs0SG2b8w/nCuAZUpQOw5tT5sgF0+5TbIfOmoHigaq9nJJatBZIeSFidXw4hY6orNEsiUXYuheawDwkAt3aSccQi5dkn1+LCB4sI1wW1TKY5yFbkUVf/OLol7Exhh6/daYRKln1ltKuDfbWecTL4pKLyi0cgVIoCduNaOEg3zKN8UXKRPxbZtT14uiaLotRkKcUxrjh+4X8vkKOhWt1FXhBbr9dCo6su7nbP/SBRdB/IQ8LqgPSjWeZiz4WXkG/FdhjYA6DN3CMu3DuXTsyUIPKeveg7tTNFwYaXS4km7KbouBH7oPXiyr8IKLJoZuIJdQ8Fkhq/MtfysLiQQ6pdkpxDmQC4I6KQkvmrBeEDgLHRpyififb6Fr0hZbDqdhNd++cZlaF1ywIaD5yxZ69nKpEJt2NdWKv4Whc4Gq3ztUem5RtJPGzY1FWgA2IBdVC1rgRcQwilXkYiqJx4xrW9Ht4RVHn1/Klr41oIzlbZR4rSuaQZkuYPuGh1NquDaGXjliejZdcPGsJY2hZ208JNDrb1YFTjsHwqj7W6eb0N62zekhT/lCC9122saiKHiKZwWAHYJtAcmfdNZjLHRSfnO8XKofejAoyQKzm2cMi6FAt94L6ptRdvlXW+j+e0TxxqK2H3rVjWyh17jMv5i/Fc/C72tdcX5DC8liDIfoLHRi1z/nzlr+0AGsoOV2nFe3UVjHheiyWb7JfDOx2fKGis0QiTq6Q+dcnqriHMbQedxYDH2y0A+GRKofulWzUfBsiYj2Rx1DVeC0MfQ4T5QO5TF0Y7EHh3PZ/J8JcXYKsgj80IfLNizQ7cCIvs3PIybttz2y/gNBPzdesSS1YKmGgI2Q3WEYQ28YFRS5dcYHKywruG2qBwO5cCr6OAA2H+ZXlvIWKcI6jscbi9oUiXqtoKqFHseKzhAqFjqXW3x4Jrf7k79B15Q30a1hZRXhhKEHVCvJ+gYPCWy7gAJQ52gNMGOhMx5Y0/XCirHQIf6ZiQq51IFsvUFK8DiJMAeeWHdKpjb/OAy9UY4RF1yIqegWhh7BJpovCjdQdqGXLGjmuqeWfPQvqF8VIWbgEoCUNNWnUsai83TH51I9VLfFvCiq00smjTxjHTrLpeYVQ5J6Rhco5gA6sLi4Fuw1vN5Y1BB4gdJqjp7gQ4XDajt3gtcKdIOzK76HqYxpdZbLMHOThT6CPORSB1nUKKpfmolbq3FtbA252E7p88oDMR8qpPi3eYjGzjmtaLI8zxfbMpX6uXudzZQvzmII3RZrSjoP1ztzXXmBl59y/Xm3RW9dKb6KH/Nw2XlwRm06H3IR9csYOorxwBl6DD10W4QWZu6CC9U0VDdUXruAPHjBRRND5+dU3omNZMJ6yMXj4mwcqVMUB9edfLqWv+59hqDsorQ20rjN2ZtK70Uxv4aVYnNbyKUX6AxvJRN4cls8GJIq6qq1nU/6iy2Q/Ou0srEcWn7o5cYiRDtF/R9V8PhJVmtRNLZa9bv8xvPZ/rPrfN2wVS5lKcLQbdnGY+iRqSO2wpEXRaHKNW9GrjF0q3TEh8sa1bJW0okzjC6J5n9NshUOeYYYuqj3WplY69Vj6FrIMD/d12E8vbPQyXwIx8KAQCcu6t+xYHPtPDBVHneWizYJ9KyMuUn1jCSTk+sTVlhTDnkBurbFMOTiF0UnyCUkuyhaGzKqMBboNHVW8fRvzagf4AVDn+M2R7/ZQp/bhmShL6aqdniVXiUhns+hRdFs6RUMmLb+O1aCstV38zD0wl4zPetpE/uhe2E7o4byZffPbMdZqy7iy75nmIP7DVxaRqCj9kGvhIPyZF5ZOJa8tbBvQy5ZYDHkMkagG0MnaaFkVTtT5g1cLqU0a3h9SbRKBmL80FuQS/YecjOk/D3pds7hGHIpaRuFJfp1IKz1d0GtKmuh2wK6/j9Z6BGx9atxzaixdX9LZqAZwW47HGn4LrYXOC0MXSCNs1zs4KgWOsv/TvD5OGphk8Jqnij9lEtg4qURO0VN+TTj4ZxUW5/QFTsKcgmyGvJDjyS6hTH8jCwuUmShd3UQ3ylaylWsutpSztWU/p4Znpkv7g+6vFoJ8vG5ArsoGpdPZ0uQi+TSgtqxhnUwIRhyMYLRRNZX0DU6quiyMX/9h7lui7adefzMsEiGUph1bTcrrCl8ghRDUofJdanLN+TifCjpsBboedpTNxZxp5oPubB1UQQAWh0uv6/H5zp5Iv45D8TQD93lUa2UBFH442g/dMcTp9GNBDuFB5bmtujddawfenDBRSCMohuLENSh5osU5UDZedpvrTX9PR5oc09bFFs+I9DR6oNaEbX90GsGdsHfrrvOVCdeuoVey2A2FoV1pOsrt6NOp9a32liU2qctCrK7ru/nbAplQyeeH/XxXDuTHzpYVujIVQn4ttTlyymnCssUBvu/TQGnRdFRVN0We1lVrJrRG4ustm50uILNE4YeCZWaV33IY2Sehc7Wa6LOraEJnYeHEMzfOsPCkMPQDW+xha4SIrJ+6Ko4mg+ywMKNRS3edfS5ZbcWWoljeWu03/BZLtZirgnpRbIAcombvPCv+TPCngQ8/7Ky9Ge5MIdj4JessmrCUTlL+vC4uFWaYVhoyuVt9XMuT0q94lH9ixWpkujKQs8bw5g//1v5zXkabj2GnhdDS3msQLd1sTwS/fAX6ECx0CO3NB26/vqdouLCqLj9ixn7oZtwrcOh8iq7M2wdgw3IhYbc0i10kx9b6NR1PWoSJNya/TQuidZyQNdshayscPJ1yDTeQs+/MYY+R56TlUn8QvcbfTJkVY6WB6e0KJ610NW/1B94RmAFOu8UFbRPW2yWlQydYn00YkTnoQ+eWsiQC19w4QwGKf2Ty8b8de9pvSwog3df7ouU64ohl4Zyt00ZY+iR8qT9LbZ8tt4mCz2gDLnkRlZ1NhJyKd/MQ0Mysh96Z1HZAWmSoc5hO4a7aksJdFEdL4RcggHnhVx94TB0Ys67Ldp0qHyuNzbuFI3qRlnobAV5JRAJoNZZIJS0fibBL+bZ8hjlYy+PsP2m5pfrcpGsNT9lt14uw2e59En2QrNa6Pp37AUXo7xcOOVRFvrABRcmvD7LRVPt43MEekY5GmPPY+gC3scxo9azQ73+qlpwooRj825S9mzyGLpOY5nk+eEt0NkPfbE05HzIJYtMbaHnMNraKHGNQC+bPVQY/6wxdMN/020x5+QFuuYptnTMi5ofMoZuPgS8DV4SbS0Wh6G7rBUs0KXQOD43EsoBX/PKriy0YNZmLfVWPg5ykX5SL4Y/Om2xODqQ1Vjz1fGa56GTJrIQgfNDp07cCfSavj7LZVi4l7oaxNA1RTBK3SSkC6tcfW03zX3clNkGrRi6bU+CXET3wayEAe3l0lTuWXE2MfTsKaYvuOjyji1074c+QS4hZXDCWp3tLsidYTyGnrH5eh5612uUAHK5kNUVYeiOyTpgWegqK9sKhziJ8M9soaPUVd2u7jutT4e50AVxeI3LXOw35EGcU4zaLVZinh/Pc2iBk1XXamcfP/NXqcB7pi2AXqDbd9BlbiktcfyRMqECD2PoWlikBuQSPY+x0L1nVmQUVW5U+BR2DeJcx67fdHkyhq7HHqs9XY9cl6IgFz2+rAzgPDWvfSBS3gXbb0IuJk0sDx3eAl1BBn0DGUtaBVe2r4ZpxmLo0TS6hhEfngXCXAtdD1S2JCLIBcpq1vlFfzOGnktDzDTLYkmcZmps/VeCTOeZYQQvnHwdmsTLxwEWtYU2pARa8UXzoxZFexMxttCHIZfufSxaPX+cd41lIRcr/HhJg5+bFrrQuOg0gkpX8WQtTRaeEI6mDCwgOxL4ds5huW83LXQ14/CtV9c3alxWLOzlYotklU1wigOFkyJDchjN88zEMfU2YegR5aUU7xs8T6DDNGzVznGHK0IqsduisdKUxVA5FEhvuc1pRYJcFIYOL+TzewcN2SR5kKQ8UcxWRvngOBs+y8VqphFX0HFCYAzdKK+BsjBfYdkD07ebfltrbaCdTT7ebZH6msq8D8cWOm1HZ7ZaFjoUf6C6svWvlWDhsUAuMYauVUADcul7GzM3tFOU869jjxUBCfQ0dNqihVy0klLhklbUHMZBLpIhz57XIcjFGBVDpy2Wfkv7Djq+Ct6myB/CNkEunqRi6AVNCHygS3D6zULS4mbNKaFkyKUOUp4G2zjcWXKH8l4uVmoaP3QSRBaa4LQ1n7H10cXtXmTe6+FcI7f+l4TmCHQz29F8VCEVbf1X9Rk04pK9XFhIUhnsbysfv7Go9hstmCMM3XOmTQDLM0OApIiNAml5ueQQbQw9fq7v5lvoEeTSOtPI9kW+tjHut37GlnMpT6k3xVz/ZOUpbhzXuiI/dNMLlmShZ9lDHPL5PbaA01kuS6IOoNaY5kjIpXzTnbc1nbcbi1QwhgvMcI790G3itTMHqJ2LY4WDDulYKpHzFJ577lwvFyVADXeNrf+ar0gQ8MD1giyaUi/Zy2Xe90Y7D1noEX/cQv5cD5OvgZWs8i8JykzHM1SsThJEHSTUwtDnPcd867zbbWJJTBlSarefmFybkAvoxiLx9R/CUNzuhKE7fk34UhtN6UuGUKozhy4tK9BtzOWhw1qgs5eLXxQdEuh9x2dNbn9th8sWW5/GIryVqCwgslKqH7rmqem2mAzkQoJvvoVuy6xFjbZG6jCY64eu0nKLAS6k48WMljo7yn97/mOhXNMeUl5s6SoZaWYPLQ+OGEPP/SanFWS+qL1cFs06iTUCollDfRYVygkaaB6z1TjGbTGCXwpvpjGk1clhMHRXt5oWOUzQb8dALsU9UGx96ZkzK0aPoaviOeVevIkGLPQEgZAhVOc0sYU+YehjqEx7GNdsmAvgjjbgh15b1eWV4wLo3RbHYOi99RHg1G762vJDBwt0m4cVGLYjUfp9gWM/dE2R22KV52MhF29BsQAPT1ts8G75cgLV5keDNX6OBYvNR7kVSipt0YK6uCZzHzMBndLyHhm6vpP5NgS5CJYOufC4MBLdcu/e5XZU6ShBWcOngeNzax+fI9BRR7sebyTQVZk8hu7VZQ3L/Je2bBg73bjOZdMY+tydoqvptigirxORb4rInSLygeD7+0Tkb0XkayLyRRF5zqFnNeSs73/ksTJkoQuLj8Zpi1Zr65yU26K30I9/bnkAACAASURBVHnwU7p9h/J+6JZBvVOU06rTPy205lnoPj+pkEuV0PPPcgF3fMv4iEVRM9oL5EL3nLo4gUDRC3Bt5aUFVlUwTui4HHQ+8aKoFsRden05jB+686hwvBnho5S4uegkUOrM41Is9HhRtBeHpQBeQUY7RVuLooDuoHMvuKA2bUIuuX7d2EOJFynJaqEvNi10O3aaO0XLv9bLJXKz6OhZA7mIyAKAjwK4CsB5AN4qIueZYF8FcFFK6XwAnwbwW4ea0TaxZmYXqnaVSfkurhNarV0j6XTzUaDigwR5IWxBd6doa2MRyCozQmRAfpcwJb+eyVQYy6M0wNBND1TKY6yFHgrn+jubBRuLoCI5ynzZRUkbnC1dNaVuWJOtfPJvVaR9v7Hqht0WqQUjFzmrCFqziRzVLsI6C31W/xbo5tFufq1nglxUZ43EUyDQZ3GdsiDtePFhOVWGXHSO1kLP4yoKo9smh6tjyS+Kzls/C7dZ9MqTz+4ZtNDNeFpNyOUSAHemlL6TUtoL4JMAruYAKaUvpZSe7P+8AcCOQ8tmg2QG9nLRFnoQnAYaYCAXYzl4DDlreMbMRA9ODq0ECnusVhq64CIhtlrnYd1DQq66LdounIJppf+7iTc33BbVoDQVndvL48Ex7xFfLaXbPfp+IPx3+d4ok0my1lyA01IE6+USrS74nlXLrmcOVFcUvrrMmToTgcgh2Prv3XSon1mBHo0dCmks9OYMWPTMdAhDR4KvfzbsjGLkcNFpi47/Ur9VWCteqSdUfg2aPmdcrubhXKcCuIf+vrd/16J3APiL6IOIvEtEbhKRmx566KHxXA6QxdCr22IAuSjbt15U0PGWw+jfEjdbbLnZ+gsuIiFu0xME51cFmYjxQ6/DOnbnsvnnsDrN+pzKi14RKQtd09CNRU5MNTYlhZALlUNv/Y/ieGE7vPXfk55+e3e2loWeA8SnLfr8JNh1G1voHkMnLUPCvbZPFVJVwPOvxtCfiR96dgdsW+gx5GLbjspAaXR+6L6dLReaUy+49Tmphj/kMVfHTlbCgF4UtXGtgG9CLpJTrozWnaI5jC6gWztYRQs96vIhOyLydgAXAfjt6HtK6Q9SShellC7atm3beC4HWMsWRUrSWyhtpllY8wYR/tqyIFA6RMbQswXiuFHPeVwuBnOsFoZeVU7lxWLNOY/I0vFcc360sYiGgb/gwqdb0j4YP3Tohkl9Hn6x1wuRiC8HeQBeUJpwaqA32zkrSlH5VUFR11707Kwvh9op6kvBPDj+BKb/1rrRolH3BcvjqEVRIyQLbwKy0CUIHylZ/aVtoQuabot5MIkuG/MHELRRmM3psYXuYSyNobPCoV9TwqI4nYWe/9EXXORZnOff19pyYehrRoS5F8Bp9PcOAPfZQCJyBYAPAXhVSmnPoWFvDvXWBB+pWS3uAEZQFrqdLuYwon5rVqLSiDB0JdxpAAgkvDmmDqM8gAzkQh02nIqykPUsKL5LKiJU7mqKzN9YxHViLJYxO0WNQMiW3YFRcTxf88oewhhKYNrhq9PJ4byFXrHqaDah9xs0zsgxZbSzOctEG0PXPAIa1+34GQ+5+JStwgqMEvCBW0Ywch9Dxph9O+dQ471c/NhrClLRKWgMHUFY3ZY5T8dsWNckY+z4CfryctAYC/2vAZwjImeKyDoA1wC4jgOIyAUA/i2AN6aUHjz0bMaUfUGX7odOXi6IOmHUAMFOUQxg6JReZ2E3LHQlFRqQi/ihlvNoKZ6IJ+3lwh8jwWNHHM0GXFnmuy3ab00/9Abvli8rUC3PkZBkITBsobPVbAV6CgUKz9OHvVw8VBBj6IpzNWuwyl37oQ9Z6MPwS6nTwEJ3FZdT4TPOTRDb/sqAgqauj9cvtp/X/DK0ISF7pW1IM2oLfcAP3ciCeVv/JbGF3mnympTui64uVgtySSntB/BeAJ8DcAeAP0sp3S4ivyEib+yD/TaATQA+JSK3iMh1jeQOLeWBlxdFIbCH4qjg6jneWNSMWzB02ikqps+rRtSdI4ZcEhRXJDw05NLG0O3IaFkdXdzuRSr8Ee7rLPR2uk5ZjrLQRX3zkMtQHM9XNEjaCrUqGCtQQqVBfKjzykH9Brrx2W2xTLig2yu/tLOQSIizcVIgl6wzTJ2NPw8djedEv4LYQo9i1nYsPJdy5DIQjJioHM7w6Pu86LIxf937WKFqP3RRPHA7zCpYyupS85/ruWQbYOiBFc9b/4V3+friBibUoaExkAtSSp8F8Fnz7sP0fMUh5mskSV+BiwdhodeBklMCfKNybMDsFIXtVP45C5Qm5FJNEzS9XGC7VOV5SIBbrryFzraIziE6n0MovPoW+nU16oYGbLyxqCU6NF+dQA2zNc8GT53bzjpcE3Kx2ZcBbN0WTdq2jGo2wEKx/psX72vta6af+Xno9Z0IRQpmPDZvtSgaKGWXgOi5B38eBbkknkD4vuK8XPpwBZ6iWVPolUPvq/VteC2lJd+WZCCXRhtzOZaDjoidonmrfG48IBbooIHGFxX0SfXfvGDpX6h081Gg0TRfh8/T4AbkwvkYP/TSdaR2cL+xyApeL4hLfsgYupFGIy10ofC6IC0LPaqbKj7C0xZbGtLw5QQqrDKQONy8du7fWQu9mgAGnjB8p8U5kIuYeOA+qw0BFm6cn1WCavOTaHhvKWe5sDit3NU6UQUlHpo3FgmcxZ3La4W+iH2gb5xfyrCKha60gtJKnPMPIJfyt8k7uy1afqSqdvaEUfNt08a+3paHDm+BTnoZgLHQ26GVNocO37bc9AUX4ZVpthFRB3CkkbOArZFaW//rUFuM9UyT7GAApMf6BNWqDGYzgaKor4yFbjD0CCqpHb2KDLUDFkF9RsI2gDl8JmawFktM3ICLrUk/yAvsAbbQo7bTbo0hhm6UFuelfKFJgFsBz78MZw1CLkH/5OfitrgEL5cK3/k66+pnphLIAtZWe53/9Omy4WIgF/TugbrtCHKhtrH1rbxcTNnsWFb4uOK1C5CNyS5MDpdlka47W97pxqIGdRuLMuTCA2Ie5FK3EAPUCYPGBeD90FGFdU3fC5scJrLQYS30WWvrP3cunUcMM8TvKoZuBFKK3BatICJO551hYOoy81pT6soR+6FHQsTzFU1jQ9lM4YTSt8rdpdOHi/3Qu9oI295ccOGtO9NPWKIzXwKAtv6zYGp6uUiXZ+uCC1bETT90FY75VIxRipEfOgU1iiCXI1LGKeDA8lotdFuPlR/ntkjpqgsuqC9Z/gUaH3flgmq2MnerxWUM3c9IJgs9orJT1GOw471cbBgvWPj9rD8PJl9woTp9NDD7/0LIxUTiBV1eIBL4QZzfz8Oc+bvdKcobVS13wxdc2II0IJcBgZCn6lG5XJyAL2+hxQqEw7Gl1N4RrMMNnuWi4mRFpTcW2VI4I0DxpHnlugqtvNInS2oQYMk7RR2MFFrorXbyvuV6lmuFZx4TNhU9HtxiMnObstLl+GRo0adcpmwIdeeh12/6V5d3yMslc9za+m+FgSvxhKHHlJu/TEtHQi5ZSDrLPNC+/EFj6F6omOBdYwriRdFBC52moErwaQUSW8EBH/TCTuHH+aFTl7RTUHtJdGih15S6cujTFosSCON4vqyFlnnUqelwbCm1xYUO17zgwvFKRx9T9TjrzvHMyodruYZLJpz3ciHBD92W/KwUUPhcVL37Ej1l3uzFz2p9wszMcrfzyjj396CfOws9uRma8kNXilErIuWHbqp6rIUOQXc7lNphnXewZuWoa8xb6BPk4ihfuVX80KklBy10IUurfNOKIOpwgHFbpPAcxqbXdY7IQh/C0Cs3QqVJtqOo8nlSkEuvQGpd0Y1Fpr68IuB3FnLRAp1nFo47Y3XaARwtbEZ8RYMkUgbW6nWKO6g0pQSyzoOGXDqBYiQA0MN/DLmYWhDTT4b4I5c/ttCbC8ky3kKP4Jfi5bIUP/RASc630GPFlvum5k73o4RULPSIvboupuuY3Rb9bD7uZ00MXWosxtCRKFfbxib9ycslpBkyemXdFuPJoe7EqjO631haHMwFF5CG26K10N2dojWt2ELXPSUUTsr+6npcsmFH7hQtmblFIm+HWn68hW4xdF+GYQs9mLZH8odqgAVJFULBYKbv9qxxZQgoXqtPf5l1BwLdRHP8KR6orjSGjvLe8/hMjs/NtBQLXVSbcIiujnTpCr4dDK8W5BK5LdoZmoJcnJLUGDrnGf126UlT6NZS6iO5MqDJdZHTchb6JNAD6uVZxi3VgI2D97/kh26sizhmbSB9OJe20mKBCmc1ZbIYuvVy0V0nsFxcp24wkPNjC12400WHc5lklPIattAjfNpaLgl5Y1FO0bdbLNDpm+XRKrs+wdACDpQOx82v9TkpbT/0OrW3Xi5B2kZp2QX0/JzXOPLiPc8Wag72PPRndsGFMNMS1acV6ANnuXD/tAIOmriPAwMCvbBn67FCLtw1cl45hRmS81DjsMxQE0PvG0p7ueSZg5/d2FlZLsdy0OEt0JHBiGpty6x92mLtCtn+rV0r1NKqDXK6+nAuq9VrXD1IYwudQR8ogc6/yr3PDFDF47A8L0cNFGXBJwRaC92eh86lG+uHzm9EfwPseeiRgPUF4vO03bQ9aDsdzivfSH1zvfJZ42yH2UGavaCe0QUXQms69KUKKV1XRUhViQ6RgznLhceFkug1jFMm9e96Rn0tR0nZWehacdX0tRGjvnF+vUdWe3as2yaHqwbDuAsuBLUaHByJCsFVgwSqtdnBIepjk9tiRFIx9CpycsNFkAv/WsglEEImL0Bb6JCW0NJ5CVoYuo7ECzidFcE86cGcM5wjz5XQqcPWDqhq90TxMpstC936oUfS0lpqGYf2kIsXIiFfxtJ14Tg8ZT208Yoj21lGFap8zATHycpxaRg6l0ML95pmWbwvQhXlPfOY8xy3U9S/L4os8nIJYxJvFFyVwbR7HaVe0SVgxNb/Gl6nwWWLYLY6flsYujUIIiPKhtN+6JUPu1/C9rPJQg+pb4oMufBADEOzJWLgi/wbTTNRG1Fv/RczmODCZ6trnB/6Qv86zztqWmwJcH5zBSBn14OP1W0xS4gRO0WFBpDzcomVQQxHVQE+F3LxxTE33FsezYg04bTA9MIwyrcFuUB0fedHtTUdAeSCqIy1UNHMIZl43sslJzaDoL0oqvnw72fSQy6hha4FM/PmjsTlHxEKWceoq3bJ5Zkj0BlDV/VfL+Tmb9VC78vIStYUycKXQxdcFGOyGHip9BFbT5ECmzD0iER6v/Bgs0BooWvIha0L08b+WfRpi/lwLsOOe85dNLrgIiFBX1pkzkMnwTjKbTEQgcqaKGnnuOTl4gS6Tksv7IyEXIL6YAs92liEKE7AV2htB896+h14ZPgsVLjWBRfiypfdFuf5oUcYeg7PEGDtm37NoypFzWMWbDX9cWe5aOtWaSS4R0N+YxGXwZUfvu5yHC3QW3nXCy5supH1ntdDeFHUqivTNcszb+tXeUnlmF0b+YIL2xl9X54gF0dsMRZXskGBXn/txqLWtMvGFr4kuhFG8dY35pizXAoOC22tVOuly5fz0ErHZaG7PWHoKmaKDucy6bDgcV4uS7jgggYsbyzy4WIFpS64GKVQo+k3KxiXhZqNDF5woZRrDrhI8FqModt+opUPB65eT4S4FPIWehYyLQzd8pGfrXBvY+hevMZ9pYS0Srfv1uH6R/Kzj5pLLg9b6FyP2qjTPFgMnRVO5dHWTwty4TjlU+armE3mtEUTfbLQA6oLLuxT7hsnUwS52JlkS6B4Lxc/ANsCJXaBSslGspBLFT61c+lBFk37VZkpQJ0U9h2e68/hhD61Wh/WQo9BRrEjhH7V7Ai6rCaZkK9IwEUKJJp+q+9hrXGcKmCUl4vjtQ+nFkUDyCXoM3Y2x/lXbrUCW0zs1ioU7mD80KHDRH7oJCyZNIaux54KWuokMoRQ6pX7R8R3Vje2/dWGIZOwUAqzIFzEr4go61slKbU/FFjG8kpabsLQR1Nu/Xp8Lrvi+dCM2A5fcKFeAsVaUme5KPsqtoCyRdJ0W+RY7oKLmlaxXJwA90qHSY2pYqEb6ylZ+zw6PrcbQZ0lZTH0+Rdc2CcHuUSHnbnS8PG5gVBgi42FJAt0+z2W5yWc9fHOW8d93v6gs9gP3S9kq1kDKRxeIORZQ87F+aH3Fvozg1yWaqGLahMOm7FmVXo1RvX7MZBLZ6Enp+BYeVrFXdMe9kO3vbSMigEMvRpadcNTCcP82HqbLPSAilW0SEIquxcGwem3tbEoCt99zx2iUx6xha7+oLwGLrgI4mQ/dO22WEwXFXyehc4veX6iIYPxx+f64QbYG4ti+EpXtIVceDC6OAFf3ScjLKJnGkwsBCSIo9ISnZ+2bbPF7JWpt9AjgRb/rTH0qiSiumHhN/4sFzSeGzMuBWn0n5yFPnzBRYYelIAOhHpdYvQtoxdFeyEqvgzsvWJnclWgM+Ti+eUCz8fQoaz47kiCXHerc8HF4S3Qi5Abd9qiFmkqhYYQinKsQrgOKZ2WSrcfsE0nF+64M+2Hzvnk6EMYeiSdlFWXLfSk048x9EgQiRuIAJZ2wQXV+LwLLiLiyxS8leyfVThSAvMt9Cwsq5IlkMNP+YO6lGDYCnQZeROThV8yVQWs3xUYwcwiuDn0voWWVW7DHKyF7sdQcm0kbtzkOB3kUus74jX1/wi0UuAep2ZifTiGRJzbYlDnqq6dhV65aR3O1fKWa6V5qOjwFui5ohZ7J0I1INqQi92MxElF57EAMMfn1kgtt0FrdTUXRVWkjKFXK72mJeUbMRh0alNmHlzIGLpOs1vRacfLIQVxvXovF30Gtno0MMKwhT5QHonK69vOzmCsYJqPoaPwq+E2w19ooc+/4KJ75w0EoQzK4r1qy2DdQTLkMh9DV89i3ocYOsJ34RhSQU35+/JGypgNnEHIJadhOGE1xDyxsA/vFC1/ayFs8XH+lk96rQaJVt6+31lul4cOb4Ge6aAgFz1tFRMGsH2XLrhoWeimEfM7kXinaBUNObDd+p/TargtuvyHRBxj6P1CLe8UNfEiDF2kHh+s87Bb/33eVu0kAJHboo7jy6MxdC8sbYYczlrDLk5A7BKoLjcRo/BLQlpgRF48TaXFM0yS/FkBawy91p09b2apkIviT3KOrVBeMFkMHaoMWsRkARv1VC5T20JPxT1Qjzd9iqKF2cpshiAXw64by4yPRzUgZAhVbD+Aq8SXd9opGlExnxbLdG3YbZEhF7O4JcI/fTjOKg+eKoTF9MxogFeB3rDQQ6Ew1stlQDgE73h+ojvZ+AsuZtFQHOHl4jH0GHIJrfqAL2+hxQJLCXHiI1LgughaWHb8pvJsBfMsK+NFfcGFT9f0E7ZwDV85XJQfp+780A/yggsAmKmdUXM6VB/b+6H78oDfSayMWdBqC50xJNC45Xrk8aJnDWwQdYvapHDUr+ZzyMslt07tv9Y8Y9HqZyTLRYe1QC++nhlDB2vmMQJdD3ZQfEB3OplxuqT9dQbBY28NtzB01Ys05KJFbve8KLoTt7xsOPeaSIf/1yl8Voi+07YuuJDAQneLolLrx/PGAjKyYONny1cWDJZHx4PADG79vTXS8lt7wUX37K2u6t5ozsg2ILIzAswz6XSl/Gx+rPDtTtGDPcul4yHG0IlL9VduR/6mqjaY6ZleWWImINz6r/PLWLUVwAby4F/qZxzO86DH/rzDuZQhZDF05bbo81ouDH3N8iS7MlTGCm39H1KFVlhoH1qoXxu+Qi6pBLKWhh7goDBjNxbl3YZ61xxbL2qRSwy/Qdn9K/JDL3lHlmTc3WdRWHseej7ILJLOCkbwCmv+jIPq3ikD3xZayS/dy0WI34qhi1coUd0jsO4M1+K+sTI0ytvUl9sg0wfkPFunLVo+mYdBC90Qt2OtWypDYInbfpvfa7fFhkBPndK0MzQLuXB/4xkur4HZMT/WQmf+fPtmo7Hddl28CXIJqAqk4lM+gKHnKXPX3sMXXNg/amfVGxP0mOZG1OnFfuhm6z9ZJ2y9s39Fa+HF8R6EyfqjLCoVC33cWS4Q/95zRQNc8aZFqLXQIy+XeW6Lwxa6D2efbRyVlsmPW6EaAqyMfV2Gfuhi+onlmfhK6nAu25YMudQExLQlC47Y80u/b3m5UEHVn2yhG53tYJH8VzDSUGERLyg9hp6FpE5XuS2aMaotdN3XorUaVgKhOW3qOqk5E1Q9RX118nKJSAzkoipuqMYIcrED23SS8twH6Cz0Gqdp0aswS7/ggruxstCV5p+PoXP6Ob8Eq25GLIrm/KIcWgdARbyR0ppJdaFMUZwgTesiNzc/o0q8q1os0UMM3UIuKj+64IJaMIKUYkWnhRSHS4rz/A4lhFoUFevlwnnNh1xqGYBGh9JBMfaCi/zSK6ccjCEXpSxZoGeIX2zd6cVorcQJQzfhot+S4oCFnnNnWEa7LeqQtiYngR5Qld3Vy2XYD93EY4Fe39SvgYSQchI64M/z8HnkEM0GVNYab/3Xtky44cJ06kgEKquuYOhwJo5bFDU9ozVV7pKyGHqGXLSwsk+zGS8qifkaFqfwFQoFo+xcOJKSkVujLoPOrxusuZwWECGh6ixkm25bCXftSe+LMvHlVV4uM46khXjLm2KMtR42gIMOqE1sEPFptAwD3cet4RLxGS001j7kxl/5e9H1tcp3PJZDEoGeOdjZs0krqLfloMMaQ6+V1InzruJakIu2SKTGUkm1LV5OtyXE/fs6ECPIxXCqLomm3FjwmjTmWej8qtiNKXtNtN0Wo518ghhDb53lEr4ii5ctpxBDDxWUF9r0wuUn6l+KIS5KmJQ+ywXEe6zw/Y1FkUBr5Cm0pkMh/Yyq7yOpxss8dBuLtEVryzT43PwjCt1ah6Iy2H7UMAzq5p+qxGqOWnByOhxGf7MKvdZg00J3pazWt6dc1z1fZet/LsW8w7kmDN1TbrTi5cLYmcF1A5ywc3XMSdkhY57LxiLyQ3edkuNqa2HMjUViz3IR7oTZ+uLwxtrzWRgLvXtRoKbyLTlNEe8U9e+7fGOBHgvnKqTiO0WHrSTlttiW55SGhtUGD5AKyqAhl0Xi1cyNyoL2mI1Fug2jMnC4LDS1hV77xKG6UxRAB5+VOJGF4AW6dVvUQWPDIFLWbT90CpPIDz1QLpxHjiuUrvZDZ+Vp+quAIJe28OW1LRVuOpzrYKivpbRYcTXlXuhClme7KFq+NQablA4Rnxnh8iBF0WHojSZUvYjPQ9eWhMWaazmGBSB/Z2y+KBoI4q3/nk2BNCz01saigDeCEaILLjTvnobdFn3bsd5Sz6QYIspv+SwX5eUiOn8Fuaia9uk2jQbhuqv/piAeWEhJfWeNhzE3FqnZK7stjrDQOX+/PuHTyIoqEv5sxCiBTq6ymTsxFeI2FiklXks4M+E0v3q8V+vbFRl5pygoDFvokSJTNGHoAalBVEUuEAjqEHIJposqDmfVcFtEHMFazouBie43FjUuiZbKvcbpbD6BUKRX6saiErerCe/l4jtkFycSUvHW/wCRKGWyFnota8y75SsrGM2Hf9bTb79m0qIcrrko6njtw809nEt3Gtt+pUzUuBHEwwrfn7YYW+iaj1i4d/J8QNoMWOiFdeq3rJQ4Lz+7kn6iqMN33/SiRCc47eqR9UPXCjtcFB0oWqcEhiCXnKeGt5p+6E6eT5BLQFmgB4dzGcHjBfoSL7iQGpftp5ZAtYty8caipE6vq4dz5Q7IA7h7VpCL7dSBlApEPPLaQVnWCdwWXVoSKLD8acThXLUCtZDyA97XYcRXtCgWtZ2afotuFxtHc6vDdXXGFrqpfTYuSnW0vFxE/c1JsGwUmrHZutd+6Mz1wRzOdfAWekqBY4Eqg1VoDWUsWvm1NxZ1/1kFx8ozUprstggOx7+mlIN+6OKdHbi1FYYejJtpY1FEZRDxWS7ccBTUPNut/9G0i2NVt8VFetdWADq9gcO5FJN6UVQdVZqLqmAFq1A8KavOYOi1o484bbH/N7IAnJfLPOWIDLn4rf9Ls9AtHzEPWsCY7w3BYS30ruwZQ+9jqbrPbbcIBrdcq7s+0xbupc3hFZj2Q6+dWDD2gguE75eOoXNda8Eo4sOXclhlDL0uoDF0bQX3E03T3mZ/CI1r9keZDXi5wLRL6Zuh9J259lWQi+obzzIMXUReJyLfFJE7ReQDwff1IvKn/feviMgZh5rRBmfdv6Efug2pqr5odOc/0BTQFXLhuz5b1hanIdJaFDWxyEJviSt1losJ18KDS37ZzkxSOn2ChBb6Ug7napn3Yd0whCGBlwsnE5RhqRdc8DMLgfkWus4v9EPXmXe/8yAXazIYPu3MYjHvGhZdn9xHxi+KMh8NPH2OhW7Lo/ZymDKxpw5nZusgx1mMwhteU6pl18aM8XIp70VZ6IN+6LZsQ1JXgA6q1HXd3vq/hLSfAc0V6NI5R38UwFUAzgPwVhE5zwR7B4AfpZTOBvB7AH7zUDPaYK5/qNa2vcy5Nlb392LqOn0+ZMs1quok/L52iCJKxQxCJVBI8KAOLA6f+hf1tvLqZM1T6u6dvl/SptUUTJxfsdC739rJ/C08vCiaB4gAamGw8O0WRWv9WB54wKqzXKJymHSYr+6dHTQUVb2vw9tkp8MFSqAsigq7bPaqPGhvGIs4WR5tn1E8k4HRh8ni1SqwBCmGBe8UBeqNRWxIsDLOY4DHRm1LLkMgXMX2y5YgD5imVx6KyYpLSvkyTzNKJrNX+mTQHwS6DwqsQDf90/CfnxlD9+Orh1wo3mLiflXXkUxX7cuxPBJ9DORyCYA7U0rfAQAR+SSAqwH8LYW5GsBH+udPA/jXIiJpuZwtC/WNdGAPynDoe/f71nwK71j4bAmZB+MiBOvkAIA6UIDgCND+3UwEB1LtBOtlHx7Zc6ByIIIFEexPSXeI8r37aPXfDgAADBpJREFUf8/+RZXPgZTwW//jG7hk/x6cjBlmOACZLZTY1lrJ+d9x/2OFJ6AuSM3ET+tsGT72v7+Dl6fHCmTQDXjB7v/7h/j1xU/h/Wtrc5325xvx+XVPlr+PuXstFmbAO9Penp9u8jpDwpq0F4upnkZYBXH3u8DKQ21nl3JhR9mMxAKQynCgKMQ6ZLSg1xKdfaF50NsFvBnxmNC1ixYINZ31so94N2O0D3fCF38NT11/FD6/bhGnyMO4N21TPIppE4jmj9kTCBYxK3XFZBfNMx2XduMzs18D1lHg/nmj7AHQjYEXyt343Nr3AwCOwZNYRDcD2fLJNwD7nlBl4npKmHVtmPIYEMxmtY44GgvZp/ctFl5zPajqA3AgAd984PFSvszTv1j7MTyR1gMA1nxqhj85sIjN31iLlID3rO3aZLs8gj1YS3lQPVI51ss+IGl+K//EjwBfuP0BvOZ3/xe+9/CTqg/mAGvlQKlDAFj78RneveZRVV/duPTlXU0M/VQA99Df9wJ4SStMSmm/iOwGsBXADziQiLwLwLsA4PTTTz9IlinTi/8+brrvJkjaj4e3vgmv3nk8TjxmHb560j/A9oXdeHz309h+7Ho8+vR+bFi3gJufOBez512Jzfd8EXv3JxzY8gbsOnUzAOC1552EPfsXsWl9rZJffc052LxhHW6/bzdOPvU5ePKCd+Jbd34b31l/Lt649RS8+twTceqWDUgAbr3nEbywTwsAfuYlp2PTUWvwU+efgh89sRcLM8H6NQt49bkn4ul9B3Db3+3GDx7fg+sf/TkcWLMBb97+AI4942LccMYv4KXPfSNu/vpzceGZ20t6l77qCnzhjtux8fhX4J+fezru/sGTeNlZW7Fp/Rq859KzcP6OLXjs6X2ujn76glPxnK0bcd8jT+P7P3wCX378GiRZwJW7TsK5Jx2Dzz35duzYcxcAYOum9Xj0qX2YiWD9ycdib9oNiGDzhrVYt24BCyJ46ul9wAkvx70nXor777sXi4/ej/WP3o37152BM0/YhP0//B7OftFP9nW6HU/u2Y/jN63DrlP6utl8Gp586fuwc98VePFpW3DGxVfhc99/AG86/1K8AQt47a5a5it3nYS7Hnocrzj7BPzN93+E449ej/N3bMa1r9qJl521FRvXLeBtLzkda2aCXadsxhknHF3ivmznVlz7qp147vZNOH3rRlz7yp3YdcqxSAm49pU7ccFpx3U87tqOvQcWceyGtdiyYS3+8o4HcMmZx+PS527DL152Ni44bQt+6fJzcNbaf4jvfWOGx/YmbDzhdTj7xE3Ys28Rb/57O3Dqlg04/bxtuPGG12PN/k4gzUSw+5hdeGLbK/AzOB3rFmZ4/snH4KxtmyACXHD6Fty/+2lcfu6JWL8ww/+58we49HknYu3CDB+86lxc/vzt2LltE/78r67FU8dejBft2Iyj1i7grZecho3r1uCup34FO098AX5pzxkdj5edjeN2/Czu3fcYHn/8aaxdmGHzhrX4weN7sGY2w9ZN6zATwa171mL/jpdA7vxLnHTsUXhy737cs2YXdp92BdZ/93o8b1snOHH0icCxp5b6/OXLz8GX73oYx73obZBdL8T/u/XrSI8/hEt3XYYXnroZ175yJy58zpYylp7edwDHrF+DHRe9ATfdewO+vX4X3rT1FLzsrK2YCXDy5g2qn77+hSfjxnvejr2yDm85bgcObHg3PnHP/Thvzy3YsXE/jgbw8ON7sb+/zOaErRuRAGzYewBP7d2Pp45ai/uOPR+/uvW5uPz5J2LjujV4/5XPw5W7TsLCTPDyV1yOG7/1VZy6cT/klNfg2tlOXHzm8QCAy849ET96Yh+OP7pqwX/0kztxw3ceBgCcs30TLjt3O7581w9w1rZNAIBtl7wFN3/huxAkbD92PR54dA+AhN0i2HTuC3DGqSfj3Zc+hhft2Iwn9x7AS3ZuxZtefArOPGETvvXAYzj9+I1urB4KknlGtIi8BcCVKaV39n//LIBLUkq/SGFu78Pc2/99Vx/m4Va6F110UbrpppsOQREmmmiiiX58SERuTildFH0bsyh6L4DT6O8dAO5rhRGRNQA2A/jh0lmdaKKJJproYGmMQP9rAOeIyJkisg7ANQCuM2GuA/Dz/fObAVy//Pj5RBNNNNFETHMx9B4Tfy+AzwFYAPDxlNLtIvIbAG5KKV0H4N8B+ISI3InOMr9mOZmeaKKJJprI06iNRSmlzwL4rHn3YXp+GsBbDi1rE0000UQTLYUO863/E0000UQTZZoE+kQTTTTREUKTQJ9oookmOkJoEugTTTTRREcIzd1YtGwZizwE4HsHGf0EmF2ozxKa+FoaTXwtjSa+lkZHKl/PSYnOlCBaNYH+TEhEbmrtlFpNmvhaGk18LY0mvpZGP458TZDLRBNNNNERQpNAn2iiiSY6QuhwFeh/sNoMNGjia2k08bU0mvhaGv3Y8XVYYugTTTTRRBN5Olwt9IkmmmiiiQxNAn2iiSaa6Aihw06gz7uweoV5+a6IfF1EbhGRm/p3x4vIF0Tk2/3vcSvAx8dF5EERuY3ehXxIR/+qr7+viciFK8zXR0Tk7/o6u0VEXk/fPtjz9U0RuXKZeDpNRL4kIneIyO0i8sv9+1WtrwG+Vru+jhKRG0Xk1p6vf9q/P1O6C+G/Ld0F8ev69ytyYfwAX38kIndTfb24f79i/b7Pb0FEvioin+n/Xpn6SikdNv+jO773LgA70d2UeCuA81aRn+8COMG8+y0AH+ifPwDgN1eAj1cCuBDAbfP4APB6AH+B7grFlwL4ygrz9REA/zgIe17fnusBnNm388Iy8HQygAv752MAfKvPe1Xra4Cv1a4vAbCpf14L4Ct9PfwZgGv6978P4N3983sA/H7/fA2AP12m+mrx9UcA3hyEX7F+3+f3PgB/AuAz/d8rUl+Hm4VeLqxOKe0FkC+sfjbR1QD+uH/+YwBvWu4MU0p/BX9DVIuPqwH8h9TRDQC2iMjJK8hXi64G8MmU0p6U0t0A7kTX3oeap/tTSn/TPz8G4A50d+Kuan0N8NWilaqvlFJ6vP9zbf9/AnAZugvhAV9fuR4/DeBykej68mXjq0Ur1u9FZAeAnwLwh/3fghWqr8NNoEcXVg91+uWmBODzInKzdBdgA8D2lNL9QDdIAZy4Sry1+Hg21OF7+2nvxwmSWnG++untBeisu2dNfRm+gFWurx4+uAXAgwC+gG428EhKaX+Qt7owHkC+MH7Z+Uop5fr6Z319/Z6IrLd8BTwfavqXAP4JgMX+761Yofo63AR6pLlW0+/yJ1JKFwK4CsAviMgrV5GXsbTadfhvAJwF4MUA7gfwO/37FeVLRDYB+C8AfiWl9OhQ0ODdSvK16vWVUjqQUnoxuvuELwHw/IG8V40vEXkBgA8COBfAxQCOB/DrK8mXiLwBwIMppZv59UDeh5Svw02gj7mwesUopXRf//sggP+GrrM/kKdy/e+Dq8Rei49VrcOU0gP9QFwE8DFUmGDF+BKRteiE5n9KKf3X/vWq11fE17OhvjKllB4B8D/RYdBbpLsQ3ua94hfGE1+v66GrlFLaA+DfY+Xr6ycAvFFEvosOEr4MncW+IvV1uAn0MRdWrwiJyNEickx+BvBaALdBX5j98wD++2rwN8DHdQB+rl/1fymA3RlqWAkyuOVPo6uzzNc1/ar/mQDOAXDjMuQv6O7AvSOl9Lv0aVXrq8XXs6C+tonIlv55A4Ar0OH7X0J3ITzg62vZL4xv8PUNUsqCDqfm+lr2dkwpfTCltCOldAY6+XR9SultWKn6OtSru8v9P7rV6m+hw/E+tIp87ETnZXArgNszL+jwry8C+Hb/e/wK8PKf0U3H96HT+O9o8YFuivfRvv6+DuCiFebrE32+X+s788kU/kM9X98EcNUy8fQKdFParwG4pf//9atdXwN8rXZ9nQ/gq33+twH4MPX/G9Etxn4KwPr+/VH933f233euMF/X9/V1G4D/iOoJs2L9nni8FNXLZUXqa9r6P9FEE010hNDhBrlMNNFEE03UoEmgTzTRRBMdITQJ9IkmmmiiI4QmgT7RRBNNdITQJNAnmmiiiY4QmgT6RBNNNNERQpNAn2iiiSY6Quj/A6aLKcLVuMWJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(actuals)\n",
    "plt.plot(change_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 同參數去跑個幾次，把好的結果記錄下來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\n",
    "optimizers = adam\n",
    "kernel_init = 'glorot_uniform'\n",
    "recurrent_init = 'glorot_uniform'\n",
    "bias_init ='zero'\n",
    "epochs = 400\n",
    "batches = 80\n",
    "\n",
    "r_count = 1\n",
    "result = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    model_LSTM = create_LSTM_model(optimizer=optimizers, batch_size=batches, kernel_init=kernel_init, \n",
    "                 recurrent_init=recurrent_init, bias_init=bias_init)\n",
    "\n",
    "    history = model_LSTM.fit(_X_train,_y_train,\n",
    "                             epochs=epochs,\n",
    "                             batch_size=batches)\n",
    "\n",
    "\n",
    "    preds = model_LSTM.predict(X_test_std)\n",
    "    actuals = y_test\n",
    "\n",
    "    #格式轉換\n",
    "    change_pred = []\n",
    "    for i in range(len(preds)):\n",
    "        if(preds[i][0]>0.5):\n",
    "            change_pred.append(1)\n",
    "        else:\n",
    "            change_pred.append(0)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(actuals,change_pred)\n",
    "    print(\"準確率 : \" + str(accuracy))\n",
    "\n",
    "    #如果準確率>70，則將model及loss圖保存下來\n",
    "    if (accuracy > 0.65):\n",
    "        result.append(accuracy)\n",
    "        model_LSTM.save('KLSTM'+str(r_count)+'.h5')\n",
    "        \n",
    "\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.title('model train loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train'], loc='upper right')\n",
    "        plt.savefig('plot'+str(r_count)+'.png')   \n",
    "        plt.show()\n",
    "        \n",
    "        r_count+=1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7562189054726368,\n",
       " 0.746268656716418,\n",
       " 0.6691542288557214,\n",
       " 0.681592039800995,\n",
       " 0.6716417910447762]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
