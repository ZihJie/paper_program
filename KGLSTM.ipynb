{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/fchollet/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.compat.v1.set_random_seed(1234)\n",
    "\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os, json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取KG資料並轉呈DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_from_file(dict,filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as dict_file:\n",
    "            for line in dict_file:\n",
    "                (key, value) = line.strip().split('\\t')\n",
    "                value = value[1:-1].split(', ')\n",
    "                #print部分為檢查用\n",
    "                #print(key)\n",
    "                #print(type(value))\n",
    "                #print(\"-\"*50)\n",
    "                dict[key] = value\n",
    "    except IOError as ioerr:\n",
    "        print(\"檔案 %s 不存在\" % (filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = {}\n",
    "relation = {}\n",
    "load_dict_from_file (entity,'entityVector(20d).txt')\n",
    "load_dict_from_file (relation,'relationVector(20d).txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將每日相對應的tuple依日期做成DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取資料\n",
    "t = open('Workday_tuple_ex.txt','r')\n",
    "\n",
    "#建立之後要存每日tuple embedding 的df\n",
    "\n",
    "col = []\n",
    "\n",
    "col.append('Date')\n",
    "\n",
    "for i in range(20):\n",
    "    col.append('h'+str(i))\n",
    "for i in range(20):\n",
    "    col.append('r'+str(i))\n",
    "for i in range(20):\n",
    "    col.append('t'+str(i))\n",
    "    \n",
    "t_df = pd.DataFrame(columns=col)\n",
    "\n",
    "\n",
    "for lines in t :\n",
    "    dict = {}\n",
    "    triple = lines[15:].replace('\\n','').lower().split(\"-----\")\n",
    "    date = lines[:10].replace('/','-')\n",
    "    \n",
    "    dict['Date'] = date\n",
    "    \n",
    "    \n",
    "    for i in range(20):\n",
    "        dict['h'+str(i)] = float(entity[triple[0]][i][:11])\n",
    "    for i in range(0,20):\n",
    "        dict['r'+str(i)] = float(relation[triple[1]][i][:11])\n",
    "    for i in range(0,20):\n",
    "        dict['t'+str(i)] = float(entity[triple[2]][i][:11])\n",
    "        \n",
    "    #print(dict)\n",
    "    \n",
    "    new = pd.DataFrame.from_dict(dict,orient='index').T\n",
    "    t_df = t_df.append(new,ignore_index = True)\n",
    "    #print(date + 'is success')\n",
    "    #print('-'*50)\n",
    "\n",
    "\n",
    "t.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取股票基本資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Financedata_2010_2017.csv').drop(index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整理之後要跟股票資料concate的DF(日期比照所有股票資料，無tuple的zero padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero padding\n",
    "f_col = col.copy()\n",
    "\n",
    "f_df =  pd.DataFrame(index = range(0,2014),columns = f_col)\n",
    "for i in range(1,2014):\n",
    "    if df['Date'][i] in t_df.index :\n",
    "        for j in range(20):\n",
    "            f_df['h'+str(j)][i] = t_df.loc[df['Date'][i]]['h'+str(j)]\n",
    "            f_df['r'+str(j)][i] = t_df.loc[df['Date'][i]]['r'+str(j)]\n",
    "            f_df['t'+str(j)][i] = t_df.loc[df['Date'][i]]['t'+str(j)]\n",
    "    else:\n",
    "        for j in range(20):\n",
    "            f_df['h'+str(j)][i] = float(0)\n",
    "            f_df['r'+str(j)][i] = float(0)\n",
    "            f_df['t'+str(j)][i] = float(0)\n",
    "            \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_df = f_df.drop(index = 0)\n",
    "d_df = d_df.drop(columns = 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將df轉成array\n",
    "t_array = d_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_df.to_csv(\"f_df_notech.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 後續在colab中，加上所需的技術指標，之後再轉成csv，在進行讀取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_csv('f_df_withtech.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage change of adj price 取代 adj close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df = pd.DataFrame()\n",
    "\n",
    "#基本資料\n",
    "tech_df['Open'] = total_df['Open']\n",
    "tech_df['High'] = total_df['High']\n",
    "tech_df['Low'] = total_df['Low']\n",
    "tech_df['Close'] = total_df['Close']\n",
    "tech_df['Adj Close'] = total_df['Adj Close']\n",
    "tech_df['Volume'] = total_df['Volume']\n",
    "#技術指標\n",
    "tech_df['Adx'] = total_df['Adx']\n",
    "tech_df['Rsi'] = total_df['Rsi']\n",
    "tech_df['Sar'] = total_df['Sar']\n",
    "tech_df['Adj-1'] = total_df['Adj Close'].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAP = []\n",
    "\n",
    "for index, row in tech_df.iterrows():\n",
    "    if (index == 0):\n",
    "        PCAP.append(0)\n",
    "    else:\n",
    "        PCAP.append((row['Adj Close']-row['Adj-1'])/row['Adj-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df['PCAP'] = PCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df = tech_df.drop(columns=['Adj-1','Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adx</th>\n",
       "      <th>Rsi</th>\n",
       "      <th>Sar</th>\n",
       "      <th>PCAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.622500</td>\n",
       "      <td>7.660714</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>7.643214</td>\n",
       "      <td>493729600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.664286</td>\n",
       "      <td>7.699643</td>\n",
       "      <td>7.616071</td>\n",
       "      <td>7.656429</td>\n",
       "      <td>601904800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.656429</td>\n",
       "      <td>7.686786</td>\n",
       "      <td>7.526786</td>\n",
       "      <td>7.534643</td>\n",
       "      <td>552160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.699643</td>\n",
       "      <td>-0.015906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.562500</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.466071</td>\n",
       "      <td>7.520714</td>\n",
       "      <td>477131200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.699643</td>\n",
       "      <td>-0.001849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.510714</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.466429</td>\n",
       "      <td>7.570714</td>\n",
       "      <td>447610800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.690300</td>\n",
       "      <td>0.006648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>43.669998</td>\n",
       "      <td>43.855000</td>\n",
       "      <td>43.625000</td>\n",
       "      <td>43.752499</td>\n",
       "      <td>65397600</td>\n",
       "      <td>15.311032</td>\n",
       "      <td>60.293137</td>\n",
       "      <td>42.316421</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>42.700001</td>\n",
       "      <td>42.867500</td>\n",
       "      <td>42.419998</td>\n",
       "      <td>42.642502</td>\n",
       "      <td>132742000</td>\n",
       "      <td>15.205238</td>\n",
       "      <td>46.549483</td>\n",
       "      <td>44.299999</td>\n",
       "      <td>-0.025370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>42.525002</td>\n",
       "      <td>42.695000</td>\n",
       "      <td>42.427502</td>\n",
       "      <td>42.650002</td>\n",
       "      <td>85992800</td>\n",
       "      <td>15.107000</td>\n",
       "      <td>46.637989</td>\n",
       "      <td>44.262399</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>42.750000</td>\n",
       "      <td>42.962502</td>\n",
       "      <td>42.619999</td>\n",
       "      <td>42.770000</td>\n",
       "      <td>65920800</td>\n",
       "      <td>14.517060</td>\n",
       "      <td>48.118303</td>\n",
       "      <td>44.225551</td>\n",
       "      <td>0.002813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>42.630001</td>\n",
       "      <td>42.647499</td>\n",
       "      <td>42.305000</td>\n",
       "      <td>42.307499</td>\n",
       "      <td>103999600</td>\n",
       "      <td>14.449465</td>\n",
       "      <td>43.149848</td>\n",
       "      <td>44.189440</td>\n",
       "      <td>-0.010814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open       High        Low      Close     Volume        Adx  \\\n",
       "0      7.622500   7.660714   7.585000   7.643214  493729600   0.000000   \n",
       "1      7.664286   7.699643   7.616071   7.656429  601904800   0.000000   \n",
       "2      7.656429   7.686786   7.526786   7.534643  552160000   0.000000   \n",
       "3      7.562500   7.571429   7.466071   7.520714  477131200   0.000000   \n",
       "4      7.510714   7.571429   7.466429   7.570714  447610800   0.000000   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2008  43.669998  43.855000  43.625000  43.752499   65397600  15.311032   \n",
       "2009  42.700001  42.867500  42.419998  42.642502  132742000  15.205238   \n",
       "2010  42.525002  42.695000  42.427502  42.650002   85992800  15.107000   \n",
       "2011  42.750000  42.962502  42.619999  42.770000   65920800  14.517060   \n",
       "2012  42.630001  42.647499  42.305000  42.307499  103999600  14.449465   \n",
       "\n",
       "            Rsi        Sar      PCAP  \n",
       "0      0.000000   0.000000  0.000000  \n",
       "1      0.000000   7.585000  0.001729  \n",
       "2      0.000000   7.699643 -0.015906  \n",
       "3      0.000000   7.699643 -0.001849  \n",
       "4      0.000000   7.690300  0.006648  \n",
       "...         ...        ...       ...  \n",
       "2008  60.293137  42.316421  0.000000  \n",
       "2009  46.549483  44.299999 -0.025370  \n",
       "2010  46.637989  44.262399  0.000176  \n",
       "2011  48.118303  44.225551  0.002813  \n",
       "2012  43.149848  44.189440 -0.010814  \n",
       "\n",
       "[2013 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.95924134, -0.96457297, -0.95718584, ..., -1.        ,\n",
       "        -1.        ,  0.16399997],\n",
       "       [-0.95697694, -0.96248562, -0.95550269, ..., -1.        ,\n",
       "        -0.65756207,  0.18028724],\n",
       "       [-0.95740273, -0.963175  , -0.96033934, ..., -1.        ,\n",
       "        -0.65238631,  0.01415333],\n",
       "       ...,\n",
       "       [ 0.93212703,  0.91394104,  0.93025536, ...,  0.03178927,\n",
       "         0.99830248,  0.16565603],\n",
       "       [ 0.94431971,  0.9282843 ,  0.94068306, ...,  0.06453879,\n",
       "         0.99663891,  0.19050441],\n",
       "       [ 0.93781697,  0.91139409,  0.92361938, ..., -0.04538015,\n",
       "         0.99500862,  0.06212937]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將股票基本資料及技術指標進行標準化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mmc = MinMaxScaler(feature_range=(-1,1)) # default (0, 1) for sigmoid function\n",
    "mmc.fit(tech_df)\n",
    "tech_array = mmc.transform(tech_df)\n",
    "tech_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將 標準化完的array 跟 每日tuple的array 合在一起"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將整理好的 array 再轉乘df 再進行合併"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tea_df  = pd.DataFrame(tech_array)\n",
    "ta_df  = pd.DataFrame(t_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "taa_df = pd.concat([tea_df, ta_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_array = taa_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 69)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9604606151299209, -0.967445418907735, -0.9647890678825901,\n",
       "       -0.9653654748343927, -0.5462620342582922, -1.0, -1.0,\n",
       "       -0.6532130373914652, 0.08089304561755996, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_array[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y的製作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = total_df\n",
    "total_df['T+1'] = tmp['Adj Close'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [0], [0], [1], [0], [0], [1], [0], [0], [1]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the trend on T+1 and T+30\n",
    "\n",
    "\n",
    "y = []\n",
    "\n",
    "for index, row in total_df.iterrows():\n",
    "    _tmp = []\n",
    "    if (row['T+1']-row['Adj Close'] > 0):\n",
    "        _tmp.append(1)\n",
    "    else:\n",
    "        _tmp.append(0)\n",
    "        \n",
    "    y.append(_tmp)\n",
    "    \n",
    "#djia.head(5)\n",
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.asarray(y)\n",
    "y.reshape(2013,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windows size 設定5天"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 69)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5天做一個 window\n",
    "def train_windows(df, df1, ref_day=5, predict_day=1):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for i in range(df.shape[0]-ref_day):\n",
    "        X_train.append(np.array(df.iloc[i:i+ref_day,:]))\n",
    "        Y_train.append(df1.iloc[i])\n",
    "    return np.array(X_train), np.array(Y_train)\n",
    "X, Y=train_windows(pd.DataFrame(final_array),pd.DataFrame(y),5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K #转换为张量\n",
    "\n",
    "X = K.cast_to_floatx(X)\n",
    "#\n",
    "Y = K.cast_to_floatx(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 切割成train,test,valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#分割資料\n",
    "_X_train, X_test_std, _y_train, y_test = train_test_split(X, Y, train_size = 0.8, shuffle = False, stratify = None)\n",
    "\n",
    "#X_train_std, X_validate_std, y_train, y_validate = train_test_split(_X_train, _y_train, train_size = 0.8, shuffle = False, stratify = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 5, 69)\n",
      "(402, 5, 69)\n"
     ]
    }
   ],
   "source": [
    "print(_X_train.shape)\n",
    "print(X_test_std.shape)\n",
    "#print(X_validate_std.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model - stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "config.gpu_options.allow_growth = True \n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, TimeDistributed, LSTM, GRU\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "    \n",
    "def create_LSTM_model(optimizer='adam', kernel_init='normal', recurrent_init='normal', bias_init='zero', batch_size=1):\n",
    "    model = Sequential()\n",
    "    #input method: batch_input_shape=(batch, timesteps/lags, features)\n",
    "    #  or input_shape=(timesteps/lags, features) , model.fit(X, y, epochs=n, batch_size=b, verbose=2)\n",
    "    model.add(LSTM(64, input_shape = (_X_train.shape[1], _X_train.shape[2]), return_sequences=True, activation='sigmoid', \n",
    "                   recurrent_activation='hard_sigmoid', use_bias=True, \n",
    "                   kernel_initializer=kernel_init, recurrent_initializer=recurrent_init, bias_initializer=bias_init,\n",
    "                   unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, \n",
    "                   activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
    "                   dropout=0.0, recurrent_dropout=0.0, implementation=1, return_state=False, \n",
    "                   go_backwards=False, stateful=False, unroll=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=True, activation='sigmoid', recurrent_activation='hard_sigmoid', use_bias=True, \n",
    "                   kernel_initializer=kernel_init, recurrent_initializer=recurrent_init, bias_initializer=bias_init, unit_forget_bias=True, \n",
    "                   kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
    "                   kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, \n",
    "                   implementation=1, return_state=False, go_backwards=False, stateful=False, unroll=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    \n",
    "    # The last layer of LSTM, return_sequences = False\n",
    "    model.add(LSTM(256, return_state=False, activation='sigmoid', recurrent_activation='hard_sigmoid', use_bias=True, \n",
    "                    kernel_initializer=kernel_init, recurrent_initializer=recurrent_init, bias_initializer=bias_init, unit_forget_bias=True, \n",
    "                    kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
    "                    kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, \n",
    "                    implementation=1, return_sequences=False, go_backwards=False, stateful=False, unroll=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=kernel_init))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.8731 - accuracy: 0.5062\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.8666 - accuracy: 0.4981\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.8239 - accuracy: 0.5093\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.8300 - accuracy: 0.5342\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7931 - accuracy: 0.5218\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7875 - accuracy: 0.5324\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7822 - accuracy: 0.5162\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7526 - accuracy: 0.5672\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.7464 - accuracy: 0.5579\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7556 - accuracy: 0.5374\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7321 - accuracy: 0.5685\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.7438 - accuracy: 0.5417\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7618 - accuracy: 0.5249\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7482 - accuracy: 0.5318\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7363 - accuracy: 0.5542\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7305 - accuracy: 0.5498\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7446 - accuracy: 0.5442\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.7287 - accuracy: 0.5573\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7199 - accuracy: 0.5685\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.7319 - accuracy: 0.5492\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.7194 - accuracy: 0.5548\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7260 - accuracy: 0.5542\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6996 - accuracy: 0.5822\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7098 - accuracy: 0.5853\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7139 - accuracy: 0.5735\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7089 - accuracy: 0.5579\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7029 - accuracy: 0.5778\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7012 - accuracy: 0.5766\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6951 - accuracy: 0.5822\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7061 - accuracy: 0.5654\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.7003 - accuracy: 0.5741\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7104 - accuracy: 0.5672\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7068 - accuracy: 0.5685\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6973 - accuracy: 0.5716\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6957 - accuracy: 0.5729\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7023 - accuracy: 0.5778\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.7000 - accuracy: 0.5648\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6900 - accuracy: 0.5897\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7061 - accuracy: 0.5722\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6970 - accuracy: 0.5872\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7044 - accuracy: 0.5797\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6931 - accuracy: 0.5803\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6989 - accuracy: 0.5747\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6914 - accuracy: 0.5809\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6938 - accuracy: 0.5803\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6960 - accuracy: 0.5772\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6872 - accuracy: 0.5791\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.7178 - accuracy: 0.5610\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7025 - accuracy: 0.5785\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 1s 336us/step - loss: 0.6968 - accuracy: 0.5791\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.7067 - accuracy: 0.5560\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6831 - accuracy: 0.5797\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6921 - accuracy: 0.5834\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6871 - accuracy: 0.5853\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6972 - accuracy: 0.5766\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6918 - accuracy: 0.5859\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6907 - accuracy: 0.5716\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6860 - accuracy: 0.5922\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6802 - accuracy: 0.5866\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6886 - accuracy: 0.5822\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6869 - accuracy: 0.5841\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6889 - accuracy: 0.5772\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6917 - accuracy: 0.5978\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6782 - accuracy: 0.5834\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6665 - accuracy: 0.6046\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6946 - accuracy: 0.5722\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6773 - accuracy: 0.6034\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6705 - accuracy: 0.6083\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6861 - accuracy: 0.5884\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6843 - accuracy: 0.5965\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6952 - accuracy: 0.5760\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6850 - accuracy: 0.5841\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6751 - accuracy: 0.5946\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6798 - accuracy: 0.6059\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6806 - accuracy: 0.5953\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6749 - accuracy: 0.5915\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.6945 - accuracy: 0.5803\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6797 - accuracy: 0.5903\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.6786 - accuracy: 0.6021\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 1s 350us/step - loss: 0.6708 - accuracy: 0.6052\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6773 - accuracy: 0.5909\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6850 - accuracy: 0.5853\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6944 - accuracy: 0.5785\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6745 - accuracy: 0.6034\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 1s 367us/step - loss: 0.6845 - accuracy: 0.5884\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 1s 367us/step - loss: 0.6772 - accuracy: 0.5971\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6751 - accuracy: 0.5959\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6861 - accuracy: 0.6009\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6875 - accuracy: 0.5872\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 1s 369us/step - loss: 0.6750 - accuracy: 0.6102\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 1s 365us/step - loss: 0.6587 - accuracy: 0.6227\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6657 - accuracy: 0.6059\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6913 - accuracy: 0.5797\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6754 - accuracy: 0.5822\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6754 - accuracy: 0.5990\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6697 - accuracy: 0.6040\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6768 - accuracy: 0.5965\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6823 - accuracy: 0.5772\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6800 - accuracy: 0.5959\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6722 - accuracy: 0.6083\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6846 - accuracy: 0.5959\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6574 - accuracy: 0.6245\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6679 - accuracy: 0.6052\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 1s 369us/step - loss: 0.6719 - accuracy: 0.6177\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6825 - accuracy: 0.6002\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6696 - accuracy: 0.6046\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6601 - accuracy: 0.6096\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6683 - accuracy: 0.6090\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6761 - accuracy: 0.6015\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 1s 365us/step - loss: 0.6747 - accuracy: 0.6071\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6740 - accuracy: 0.5872\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6700 - accuracy: 0.5866\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6837 - accuracy: 0.6002\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6533 - accuracy: 0.6220\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6813 - accuracy: 0.5990\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6781 - accuracy: 0.5946\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6703 - accuracy: 0.6083\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 1s 369us/step - loss: 0.6723 - accuracy: 0.5897\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6655 - accuracy: 0.6183\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6717 - accuracy: 0.6083\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6648 - accuracy: 0.6046\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6668 - accuracy: 0.6139\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6723 - accuracy: 0.6133\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6594 - accuracy: 0.6108\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6684 - accuracy: 0.6046\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6661 - accuracy: 0.6189\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6702 - accuracy: 0.6127\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 1s 367us/step - loss: 0.6728 - accuracy: 0.5971\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 1s 367us/step - loss: 0.6657 - accuracy: 0.6139\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6656 - accuracy: 0.5996\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6704 - accuracy: 0.6102\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6635 - accuracy: 0.6108\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6500 - accuracy: 0.6276\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6645 - accuracy: 0.6158\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6659 - accuracy: 0.6202\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6625 - accuracy: 0.6083\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6559 - accuracy: 0.6370\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6609 - accuracy: 0.6102\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6543 - accuracy: 0.6258\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6571 - accuracy: 0.6214\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6595 - accuracy: 0.6189\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6598 - accuracy: 0.6133\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6566 - accuracy: 0.6158\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6718 - accuracy: 0.6127\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6568 - accuracy: 0.6252\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6738 - accuracy: 0.6214\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6553 - accuracy: 0.6177\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6585 - accuracy: 0.6059\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6657 - accuracy: 0.6320\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6733 - accuracy: 0.6015\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6854 - accuracy: 0.5959\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6603 - accuracy: 0.6189\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6669 - accuracy: 0.5978\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6586 - accuracy: 0.6252\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6575 - accuracy: 0.6220\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6628 - accuracy: 0.6121\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6558 - accuracy: 0.6146\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6643 - accuracy: 0.6102\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6663 - accuracy: 0.6065\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6677 - accuracy: 0.6096\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6562 - accuracy: 0.6220\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6601 - accuracy: 0.6046\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6617 - accuracy: 0.6152\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6574 - accuracy: 0.6164\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6556 - accuracy: 0.6239\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6588 - accuracy: 0.6314\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6643 - accuracy: 0.6046\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6671 - accuracy: 0.6208\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6521 - accuracy: 0.6245\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6568 - accuracy: 0.6258\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6628 - accuracy: 0.6177\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 1s 365us/step - loss: 0.6502 - accuracy: 0.6196\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 1s 368us/step - loss: 0.6540 - accuracy: 0.6333\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6402 - accuracy: 0.6326\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 1s 365us/step - loss: 0.6594 - accuracy: 0.6220\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6432 - accuracy: 0.6314\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6493 - accuracy: 0.6308\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6518 - accuracy: 0.6295\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6555 - accuracy: 0.6245\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6461 - accuracy: 0.6270\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 1s 367us/step - loss: 0.6457 - accuracy: 0.6146\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6551 - accuracy: 0.6220\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6513 - accuracy: 0.6127\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6559 - accuracy: 0.6227\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6513 - accuracy: 0.6245\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6448 - accuracy: 0.6314\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6493 - accuracy: 0.6270\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6579 - accuracy: 0.6252\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6417 - accuracy: 0.6382\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 1s 367us/step - loss: 0.6421 - accuracy: 0.6413\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6560 - accuracy: 0.6258\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6545 - accuracy: 0.6158\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6545 - accuracy: 0.6183\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6606 - accuracy: 0.6046\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6449 - accuracy: 0.6283\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 1s 365us/step - loss: 0.6397 - accuracy: 0.6389\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6522 - accuracy: 0.6208\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6462 - accuracy: 0.6264\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6560 - accuracy: 0.6308\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6472 - accuracy: 0.6326\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6403 - accuracy: 0.6283\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 1s 369us/step - loss: 0.6485 - accuracy: 0.6283\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 1s 365us/step - loss: 0.6419 - accuracy: 0.6276\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 1s 369us/step - loss: 0.6489 - accuracy: 0.6233\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6421 - accuracy: 0.6177\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6495 - accuracy: 0.6389\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 1s 369us/step - loss: 0.6359 - accuracy: 0.6407\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 1s 365us/step - loss: 0.6440 - accuracy: 0.6382\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6470 - accuracy: 0.6227\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6575 - accuracy: 0.6220\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6465 - accuracy: 0.6202\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6444 - accuracy: 0.6432\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 1s 369us/step - loss: 0.6367 - accuracy: 0.6357\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 1s 367us/step - loss: 0.6502 - accuracy: 0.6208\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6382 - accuracy: 0.6333\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6360 - accuracy: 0.6519\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 1s 368us/step - loss: 0.6342 - accuracy: 0.6389\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6415 - accuracy: 0.6245\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 1s 365us/step - loss: 0.6380 - accuracy: 0.6482\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6439 - accuracy: 0.6289\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6429 - accuracy: 0.6320\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6337 - accuracy: 0.6326\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 1s 371us/step - loss: 0.6351 - accuracy: 0.6451\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6515 - accuracy: 0.6283\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6376 - accuracy: 0.6476\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6412 - accuracy: 0.6438\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6379 - accuracy: 0.6351\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6263 - accuracy: 0.6619\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6349 - accuracy: 0.6613\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6407 - accuracy: 0.6333\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6364 - accuracy: 0.6351\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6376 - accuracy: 0.6457\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6400 - accuracy: 0.6339\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6387 - accuracy: 0.6432\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6297 - accuracy: 0.6389\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6374 - accuracy: 0.6364\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6340 - accuracy: 0.6526\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6275 - accuracy: 0.6420\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6190 - accuracy: 0.6563\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6341 - accuracy: 0.6376\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6329 - accuracy: 0.6345\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6303 - accuracy: 0.6550\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6318 - accuracy: 0.6426\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6319 - accuracy: 0.6457\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6205 - accuracy: 0.6550\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6314 - accuracy: 0.6469\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6311 - accuracy: 0.6445\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6343 - accuracy: 0.6476\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6263 - accuracy: 0.6563\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6245 - accuracy: 0.6631\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6160 - accuracy: 0.6700\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 1s 369us/step - loss: 0.6223 - accuracy: 0.6588\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6358 - accuracy: 0.6339\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 1s 370us/step - loss: 0.6315 - accuracy: 0.6526\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 1s 365us/step - loss: 0.6207 - accuracy: 0.6563\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6155 - accuracy: 0.6638\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6234 - accuracy: 0.6588\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6197 - accuracy: 0.6575\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 1s 370us/step - loss: 0.6221 - accuracy: 0.6557\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6192 - accuracy: 0.6563\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 1s 368us/step - loss: 0.6221 - accuracy: 0.6650\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6192 - accuracy: 0.6476\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6266 - accuracy: 0.6638\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6219 - accuracy: 0.6519\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6211 - accuracy: 0.6588\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6210 - accuracy: 0.6519\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6233 - accuracy: 0.6507\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6253 - accuracy: 0.6544\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6163 - accuracy: 0.6606\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6032 - accuracy: 0.6750\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6041 - accuracy: 0.6687\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6157 - accuracy: 0.6631\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6102 - accuracy: 0.6644\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6150 - accuracy: 0.6625\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 1s 368us/step - loss: 0.6175 - accuracy: 0.6650\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 1s 368us/step - loss: 0.6131 - accuracy: 0.6687\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6100 - accuracy: 0.6650\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6246 - accuracy: 0.6494\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6170 - accuracy: 0.6719\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6065 - accuracy: 0.6656\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6254 - accuracy: 0.6476\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6228 - accuracy: 0.6681\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6213 - accuracy: 0.6557\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6053 - accuracy: 0.6687\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6119 - accuracy: 0.6750\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6197 - accuracy: 0.6638\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 1s 367us/step - loss: 0.6132 - accuracy: 0.6663\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 1s 367us/step - loss: 0.6092 - accuracy: 0.6762\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6092 - accuracy: 0.6656\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6168 - accuracy: 0.6681\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6113 - accuracy: 0.6743\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6066 - accuracy: 0.6687\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6302 - accuracy: 0.6413\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 1s 366us/step - loss: 0.6035 - accuracy: 0.6905\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6047 - accuracy: 0.6712\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6032 - accuracy: 0.6743\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6074 - accuracy: 0.6750\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6136 - accuracy: 0.6706\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6153 - accuracy: 0.6619\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6092 - accuracy: 0.6793\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3hc5ZX48e+Zohn1LkuWXORu44qNsTE9BIwhIQGWQEI2pJFkl01IhxRCyC8b0hOypABhk7ChhZ4E0yE0A5a73LslS1bvZWY0en9/3DtXo2q5jNXO53n8eHTnXs17NfYcve0cMcaglFJK9eQa6gYopZQanjRAKKWU6pMGCKWUUn3SAKGUUqpPGiCUUkr1SQOEUkqpPmmAUGOeiPxJRP7fIM89ICIXxbAtHxORF47z2ttF5P9OdpvU2KUBQqmT5FgCTX+MMX81xlx8stqk1InQAKHUKSIinqFug1LHQgOEGhHsoZ2vi8hmEWkRkT+KyDgRWS0iTSLykoikR53/QRHZKiL1IvKaiMyOem6RiKy3r3sE8Pd4rctFZKN97dsiMn8Q7bsR+BjwDRFpFpG/R7X7myKyGWgREY+I3CIie+3X3yYiH476PjeIyJtRXxsR+byI7BaROhG5W0RkkD+zgX4G3xSRw3YbdorI++zjS0WkSEQaRaRCRH4xmNdSo5MGCDWSXAW8H5gBfABYDXwLyML6t/xFABGZATwE3AxkA88CfxeROBGJA54CHgAygL/Z3xf72tOB+4HPAZnAH4BnRMQ3UMOMMfcAfwV+YoxJMsZ8IOrp64DLgDRjTAewFzgHSAW+D/yfiOQN8O0vB84AFgDXAJcM1JZB/AxmAjcBZxhjku3vd8C+9NfAr40xKcBU4NGjvZYavTRAqJHkN8aYCmPMYeAN4F1jzAZjTAB4Elhkn/cR4J/GmBeNMSHgZ0A8cBawDPACvzLGhIwxjwFro17js8AfjDHvGmPCxpg/AwH7uuN1lzGmxBjTBmCM+ZsxpswY02mMeQTYDSwd4Po7jTH1xphDwKvAwkG85kA/gzDgA+aIiNcYc8AYs9e+LgRME5EsY0yzMead47pjNSpogFAjSUXU47Y+vk6yH48HDkaeMMZ0AiVAvv3cYdM9S+XBqMeTgK/awzL1IlIPTLCvO14l0V+IyL9HDWHVA3OxekH9ORL1uJWu+xxIvz8DY8werJ7F7UCliDwsIpH7+zRWD22HiKwVkcsH8VpqlNIAoUajMqwPegDsMfsJwGGgHMjvMY4/MepxCfBDY0xa1J8EY8xDg3jd/lIjO8dFZBJwL9YQT6YxJg0oBgY1r3AMBvoZYIx50Bhztn2OAX5sH99tjLkOyLGPPSYiiSe5bWqE0AChRqNHgctE5H0i4gW+ijVM9DawBugAvmhPGF9J9+Gde4HPi8iZYkkUkctEJHkQr1sBTDnKOYlYH8hVACLySawexMnW789ARGaKyIX2vEo7Vu8rbLfnehHJtnsc9fb3CsegfWoE0AChRh1jzE7geuA3QDXWhPYHjDFBY0wQuBK4AajDGqt/IuraIqx5iP+xn99jnzsYf8Qa168Xkaf6ads24OdYgaoCmAe8dWx3eHQD/Qyw5h/utI8fweotfMu+dCWwVUSasSasrzXGtJ/s9qmRQbRgkFJKqb5oD0IppVSfNEAopZTqkwYIpZRSfdIAoZRSqk+jJnlYVlaWmTx58lA3QymlRpR169ZVG2Oy+3pu1ASIyZMnU1RUNNTNUEqpEUVEDvb3nA4xKaWU6pMGCKWUUn3SAKGUUqpPo2YOQimljkcoFKK0tJT29tGdUcTv91NQUIDX6x30NRoglFJjWmlpKcnJyUyePJlBFusbcYwx1NTUUFpaSmFh4aCv0yEmpdSY1t7eTmZm5qgNDgAiQmZm5jH3kjRAKKXGvNEcHCKO5x7HfICobw3y65d2s6W0YaibopRSw8qYDxBul/Crl3fxyo7KoW6KUmoMqq+v57e//e0xX7dq1Srq6+uPfuIJGPMBItnvZVp2EptKY/uDVkqpvvQXIMLhgQv5Pfvss6SlpcWqWYCuYgJgwYQ0XtlRiTFmTIxFKqWGj1tuuYW9e/eycOFCvF4vSUlJ5OXlsXHjRrZt28aHPvQhSkpKaG9v50tf+hI33ngj0JVeqLm5mUsvvZSzzz6bt99+m/z8fJ5++mni4+NPuG0aIICFE9J4bF0pJbVtTMxMGOrmKKWGyPf/vpVtZY0n9XvOGZ/C9z5wWr/P33nnnRQXF7Nx40Zee+01LrvsMoqLi53lqPfffz8ZGRm0tbVxxhlncNVVV5GZmdnte+zevZuHHnqIe++9l2uuuYbHH3+c66+//oTbPuaHmMAKEAAbSuqGuCVKqbFu6dKl3fYq3HXXXSxYsIBly5ZRUlLC7t27e11TWFjIwoULAVi8eDEHDhw4KW3RHgQwOSsRgIrG0b2TUik1sIF+0z9VEhMTncevvfYaL730EmvWrCEhIYHzzz+/z70MPp/Peex2u2lrazspbdEeBODzWD+GQKhziFuilBprkpOTaWpq6vO5hoYG0tPTSUhIYMeOHbzzzjuntG3agwA8LsEl0N4x8KoBpZQ62TIzM1mxYgVz584lPj6ecePGOc+tXLmS3//+98yfP5+ZM2eybNmyU9o2DRBYOwz9Xrf2IJRSQ+LBBx/s87jP52P16tV9PheZZ8jKyqK4uNg5/rWvfe2ktUuHmGw+j4tAhwYIpZSK0ABh83vdtId0iEkppSI0QNi0B6HU2GWMGeomxNzx3KMGCJvP4yagk9RKjTl+v5+amppRHSQi9SD8fv8xXaeT1Da/10W7TlIrNeYUFBRQWlpKVVXVUDclpiIV5Y5FTAOEiKwEfg24gfuMMXf2eH4i8GcgzT7nFmPMsyIyGdgO7LRPfccY8/lYtlV7EEqNTV6v95iqrI0lMQsQIuIG7gbeD5QCa0XkGWPMtqjTvgM8aoz5nYjMAZ4FJtvP7TXGLIxV+3ryeV00BzpO1csppdSwF8s5iKXAHmPMPmNMEHgYuKLHOQZIsR+nAmUxbM+AfB63DjEppVSUWAaIfKAk6utS+1i024HrRaQUq/fwX1HPFYrIBhH5l4ic09cLiMiNIlIkIkUnOn7o87p0iEkppaLEMkD0VVih5zKB64A/GWMKgFXAAyLiAsqBicaYRcBXgAdFJKXHtRhj7jHGLDHGLMnOzj6hxvo8Lt1JrZRSUWIZIEqBCVFfF9B7COnTwKMAxpg1gB/IMsYEjDE19vF1wF5gRgzbaqXa0B6EUko5Yhkg1gLTRaRQROKAa4FnepxzCHgfgIjMxgoQVSKSbU9yIyJTgOnAvhi2VXsQSinVQ8xWMRljOkTkJuB5rCWs9xtjtorIHUCRMeYZ4KvAvSLyZazhpxuMMUZEzgXuEJEOIAx83hhTG6u2QmSZqwYIpZSKiOk+CGPMs1iTz9HHbot6vA1Y0cd1jwOPx7JtPfm9LoLhTsKdBrdL61IrpZSm2rD5PG4AgtqLUEopQAOEw6kqpxPVSikFaIBw+L1WD0I3yymllEUDhE17EEop1Z0GCJvPGwkQ2oNQSinQAOHw25PUuhdCKaUsGiBskR5Euw4xKaUUoAHC4dMehFJKdaMBwua3exDX//FdXth6ZIhbo5RSQ08DhC3SgwD42Qs7BzhTKaXGBg0QtsgyV4DTxqcOYUuUUmp40ABhi2yUA0jxxzRFlVJKjQgaIGxxUT2ItpCuZFJKKQ0QtmS/h7QEL6DpNpRSCjRAOLxuFxtvu5hZucnag1BKKTRA9BIf56ZdA4RSSmmA6Mnv0QChlFKgAaKX+Di3DjEppRQaIHqJ97p1kloppdAA0YvP66ItqD0IpZTSANGD1YPQAKGUUhogetAAoZRSFg0QPfi91iS1MWaom6KUUkNKA0QP8XFuOg0EwzpRrZQa2zRA9BBJ2qcrmZRSY50GiB4ihYN0HkIpNdZpgOgh3u5B6FJXpdRYpwGih0iAaO/QAKGUGttiGiBEZKWI7BSRPSJySx/PTxSRV0Vkg4hsFpFVUc/dal+3U0QuiWU7o/m1B6GUUgDErHSaiLiBu4H3A6XAWhF5xhizLeq07wCPGmN+JyJzgGeByfbja4HTgPHASyIywxgT809tJ0DoHIRSaoyLZQ9iKbDHGLPPGBMEHgau6HGOAVLsx6lAmf34CuBhY0zAGLMf2GN/v5iLTFIHdBWTUmqMi2WAyAdKor4utY9Fux24XkRKsXoP/3UM1yIiN4pIkYgUVVVVnZRGx8dpD0IppSC2AUL6ONZze/J1wJ+MMQXAKuABEXEN8lqMMfcYY5YYY5ZkZ2efcIMhapJaA4RSaoyL2RwE1m/9E6K+LqBrCCni08BKAGPMGhHxA1mDvDYmdA5CKaUssexBrAWmi0ihiMRhTTo/0+OcQ8D7AERkNuAHquzzrhURn4gUAtOB92LYVoeuYlJKKUvMehDGmA4RuQl4HnAD9xtjtorIHUCRMeYZ4KvAvSLyZawhpBuMlSVvq4g8CmwDOoD/PBUrmKBriKlVA4RSaoyL5RATxphnsSafo4/dFvV4G7Cin2t/CPwwlu3rS5zHRUF6PMWHG071Syul1LCiO6n7cNbUTN7dX0u4U1N+K6XGLg0QfVg+NZOGthDbyxuHuilKKTVkNED0YfmULADW7K0Z4pYopdTQ0QDRh9xUP1OyE3l7b/VQN0UppYaMBoh+LJ+SyXv7awlpZTml1BilAaIfZ03NoiUYZouuZlJKjVEaIPqxbEoGAO/uqx3iliil1NDQANGPzCQfyT4P1c2BoW6KUkoNCQ0QA0jwuWkNdgx1M5RSakhogBhAYpyHloCm3FBKjU0aIAYQH6c9CKXU2KUBYgDag1BKjWUaIAagcxBKqbFMA8QAEuM8tGjab6XUGKUBYgAJcW5aA9qDUEqNTRogBpDo0x6EUmrs0gAxgARdxaSUGsM0QAwg0echFDYEOzRhn1Jq7NEAMYCEOKs+dYvOQyilxiANEANIjLNKdrfoMJNSagzSADGABJ/Vg2jViWql1BikAWIATg+ixxDTjX8p4rev7RmKJiml1CmjAWIAkTmInj2Id/fX8t5+rROhlBrdNEAMINHXuwfREe6koS1ERaPWiVBKjW4aIAbQVw+ioS0EQEVj+5C0SSmlThUNEANwehDBDtYdrKW8oY261iAAtS1BAh06ea2UGr00QAwg0oNobu/gqt+t4crfvk1tS8h5vqpJh5mUUqNXTAOEiKwUkZ0iskdEbunj+V+KyEb7zy4RqY96Lhz13DOxbGd/EuxVTPuqWgAob2intiXoPK/zEEqp0cwTq28sIm7gbuD9QCmwVkSeMcZsi5xjjPly1Pn/BSyK+hZtxpiFsWrfYLhdQmKcm6KD1ooln8flDDEBVOo8hFJqFItlD2IpsMcYs88YEwQeBq4Y4PzrgIdi2J7jclp+KnvtHkR2sq9bgNCJaqXUaBbLAJEPlER9XWof60VEJgGFwCtRh/0iUiQi74jIh/q57kb7nKKqqqqT1e5uTp+Y7jyO97qpawni97rwuoUKnYNQSo1iMRtiAqSPY6afc68FHjPGRC8LmmiMKRORKcArIrLFGLO32zcz5h7gHoAlS5b0971PyOJJXQGiOdBBbUuIzEQfABUN2oNQSo1esexBlAITor4uAMr6OfdaegwvGWPK7L/3Aa/RfX7ilFk0Mc153NTeQV1rkLQEL3mpfsoa2oaiSUopdUoMKkCIyJdEJEUsfxSR9SJy8VEuWwtMF5FCEYnDCgK9ViOJyEwgHVgTdSxdRHz24yxgBbCt57WnQlaSjxvPncLpE9NoDnRQ3RwgIzGO8WnxlNVbPYg9lU0cqmkdiuYppVTMDLYH8SljTCNwMZANfBK4c6ALjDEdwE3A88B24FFjzFYRuUNEPhh16nXAw8aY6CGi2UCRiGwCXgXujF79dKp9a9VsVs3LA6CktpW0BCtAlDe00dlp+PIjm/j+37cOVfOUUiomBjsHEZlPWAX8rzFmk4j0NcfQjTHmWeDZHsdu6/H17X1c9zYwb5BtOyVS/F4A6lpD5CT7yE/zEwobqpsDHK5vI9wZkykQpZQaMoMNEOtE5AWslUa3ikgyMKbqcCb7u35U+WnxjE+LB+BATSu1LUG87qPGS6WUGlEGGyA+DSwE9hljWkUkA2uYacxIifc6j8dHBYjNpdbm75rmIJ2dBpdLA4VSanQY7BzEcmCnMaZeRK4HvgM0xK5Zw09/PYgNJVaA6Og0NLaH+rxWKaVGosEGiN8BrSKyAPgGcBD4S8xaNQwl+7t6EPnp8aT4PST5PGw85KSPoro52NelSik1Ig02QHTYq4yuAH5tjPk1kBy7Zg0/kR6E3+siPcGLiFCQHs/h+q69ENXNurNaKTV6DDZANInIrcDHgX/aifi8R7lmVIkEiPy0eCILuBZFpeEAax5CKaVGi8EGiI8AAaz9EEewcir9NGatGoZ8HjdxHpcz9wCwtLB7gKhuDhDuNLrkVSk1KgwqQNhB4a9AqohcDrQbY8bUHARYvYfpOV0ja2dMznAei0BNc4AvP7KRLz60YSiap5RSJ9WglrmKyDVYPYbXsDbN/UZEvm6MeSyGbRt2HvncMpJ8XT+ygvQE53FGQhzVLUGKDzcQNtqDUEqNfIPdB/Ft4AxjTCWAiGQDLwFjKkDkJPt7HfvHf51Nos/D5x4ooqrJ2lVtAGMMg9hsrpRSw9ZgA4QrEhxsNWg9awDm5qcC1ua5LaUNBDqsDea1LUEyk3xD2TSllDohg/2Qf05EnheRG0TkBuCf9MixNNZNy07iSFSFubtf3csDaw4MWXuUUupEDaoHYYz5uohchZV2W4B7jDFPxrRlI8zUnKRuX9//1n4APr588hC0RimlTtygK8oZYx4HHo9hW0a0aT0ChFJKjXQDBggRaaLvMqECGGNMSkxaNQJNzbYChM/jItxp6NC9EEqpEW7AAGGMGVPpNE5ERmIcGYlxpMZ7CXZ0Oik4dDWTUmqkGvQQkzq6RRPSiPO4nCJCAIGOTvxe9xC3TCmljp0uVT2J/uejp/PLjyzkmytncencXACaAx0xfc2m9hBffXQTDa2aalwpdXJpgDiJ4uPc+L1ulkzO4KLZ4wBoiXGA2FTSwOPrS3l3f01MX0cpNfZogIiRJDv7a1N7bANEa9D6/lqLQil1smmAiJFIzqaWQAd3v7qHLz+yMSav0xoMA1DVpLUolFInlwaIGEm0A0RDW4j739zPUxsPU9ty8n/Lb3F6EBoglFInlwaIGIn0IF7ZUUlNSxBj4I3dVb3Oa2gNUXz4+Mt7t9k9CA0QSqmTTQNEjEQCxN/WlZIQ5yY13svru6p7nff1xzZx+W/epLKpvddzg9ES0AChlIoNDRAxEpmkDnca5hekcs70LN7cU4XpUStiT2UzAE9tOHxcrxOZpNY5CKXUyaYBIkYSojbHTcpIZGlhBhWNAUrrrA107aEw1c0BPG5rl/Xfikp7fY/OTnPUeYtWZ4gpSKAjzI9Wb6e+VVc0KaVOnAaIGHG5BJedYWNiZgKLJ1n1q9cdrAPgf17Zw8pfvc6h2lYAdlc299rstrr4CGfd+fKAQSIySd0c6OChdw/xh3/t47ev7T3Zt6OUGoM0QMRQJF/fxIwEZuWmkBjnpuhgLQA7jjRR3RykPdTJOdOzANhf09Lt+r1VzbSHOvlbUQmX3fUGTe29d0u32nMQAMVljQB43Zr7SSl14mIaIERkpYjsFJE9InJLH8//UkQ22n92iUh91HOfEJHd9p9PxLKdsTYpMwG3S1g0MZ03d1cT6AhTWtfqPH/+zBwA9lc309AW4q091mR2jT3xfO8b+9la1siuiuZe37s11BUgdlU0AV1LbJVS6kTELECIiBu4G7gUmANcJyJzos8xxnzZGLPQGLMQ+A3whH1tBvA94ExgKfA9EUmPVVtjbVJGIgDXL5vEgZpWfvCPbc5cBMA507NwCeyvbuXnL+zkY/e9y+u7qqi2h5YiK5Sig0pEa6CDnGSrtOn28kb7WLjXeUopdaxi2YNYCuwxxuwzxgSBh4ErBjj/OuAh+/ElwIvGmFpjTB3wIrAyhm2NqdQELwAr5+Zy3dIJPPReCc2BDlwCbpdQmJVIfno8B6pb2HnE6gXc9nQxVY3dVyZFB5WIlmCY+QWpZCTGEQpbY1p9DUUppdSximWAyAdKor4utY/1IiKTgELglWO5VkRuFJEiESmqquq9CW2oLZuSQbK/+3DPBTNzCNuTE99cOYu7rl2E1+1icmYi+6qb2WEHiAM1rWzpsYHupe0VXPrrN7pNWrcFO0iI83DG5K4OVqzzPymlxoZYBoi+Zkr7K7N2LfCYMSYyNjKoa40x9xhjlhhjlmRnZx9nM2Pn4RuXs+m2i7sdO31S1wf5imlZXDY/D4ApWYkUH26koS3EladbsbAtan7B7RI2HKpne3kjRQdqneMtwTCJPjdnFmY6xxrtANER7uQH/9hGSW3voSmllDqaWAaIUmBC1NcFQFk/515L1/DSsV47rLlc3WNdVpKPyZkJAExIT3COXzRnnPP4ioVdnaWzp2UxKzeZs6Z2BYBt5Y3sq2rmU39aS1VTgHivh/NmZhPnduH3upwhpl0Vzfzxzf089N6h425/XUsw5jUtlFLDUywDxFpguogUikgcVhB4pudJIjITSAfWRB1+HrhYRNLtyemL7WOjwtLCDKs8qT03AXDO9Gx+ctV8zp6WxYqpmcTbG+0uOW0cz918LrNyu6q/bi9v5NtPFvPKjkoAEn1upmYnsfWOSzh7WpbTgzhUay2bfXvv4GpF/PT5Hbyyo6LbsU/+aS23PVXc69yXtlXw9029Y/a6g3U8tq73pj+l1MgTs/WQxpgOEbkJ64PdDdxvjNkqIncARcaYSLC4DnjYROWgMMbUisgPsIIMwB3GmFpGiVsunc2nzi7sdfyaMyZwzRlWx2lSZgI7jjSRmWStUMpPiwcgxe/h5e2VdHR2jbglxFlvo9ftItnvpam9ax4DYHNpPY3tIVL8XQGpL39++yDlDe1cOMvqzRhj2HmkifZQ71VR976xj/rWEB9YML778df38d6BWq5eXHD0H4RSaliL6T4IY8yzxpgZxpipxpgf2sduiwoOGGNuN8b02iNhjLnfGDPN/vO/sWznqZaRGMes3JQBz5mYYQ0/ZSbGAXDujGwunJXDR8+cREenYV5+KnFu6+1LiOtK65Hs93C4vo3Lf/MGq7eUA9aGvWc3l/d6DWMMv3ttL8WHGzDG0BLs6DYBXt0cpC0U5lBta68cUvWtIar6SBC4v7qFhrZQr/N7agl08N7+URPzlRqVdCf1MDXJnqeI9CCmZCdx/w1n8P4540iMc/ODD81lfJof6B4gUvxejIHiw41sKm3gtPEpzC9I5ZYntvQaPnp7bw0/fm4Htz1dTGswjDHWnENEib3vojUY7hUM6tuC1LYECYU7nWOdnYb9NS2EO81R5y2eWF/Ktfes6fZ6SqnhRQPEMLV4Ujqp8V7yUv29jm+5/RIWTkgjL9UadooMMQG9ltVOy0ni0c8tJyvJxxPrrYyx7+yrob41yC9f3AVAarzXyelUE/WBHb3v4lBN95VQ9XbeqJqoUqdlDW0EOzq7Pd+fmpYgnQYqNQutUsOW5mQYpi45LZf3z8nF7eq94jeyMirP7kFEb4xL7jHPMCkjAb/XzYWzsnmu+Ai1LUGuveedbufUtYacuhLRQ0zRy2MP1LSyZHIGYGWiDdiBoKopQK4dxPZXd+WSamgLdVuGtuNII+sP1vPRMycC0GxPpFvpRJJRSg0/2oMYpkSkz+AQ7QPzrQniaTlJzrHoHoTXLZyWnwrAhbNyaGzv4OG1XUtez5qayZWL8qlsbKfFHhJqDYZpD4V5ZlMZT6wvJTXei0vgUFQiwejeQVVzV6Gj6AARfc62skZW/uoNvvXkFqcCXmQIqlqHmJQatjRAjGAXzMph0/cudn6zh64AMTkzgTW3vo+L7f0VZ0/Pxu0S/vL2QQB++ZEF/P7ji8lN9VPZFOi2+7q2JcgXH9rA3qoWjDGMT4vnYFRvoi6q3kR0oaJ9VV0BYl91M1vLrJ3gjxZ1bYovb7CGrZoiAaKfIaZQuJMnN5TS2TnwZPdI8Pbealbc+YoThJUaKTRAjHCp8d2HlDwu6y3NSfaTleRDxOqFJPk8nDY+hSON7fi9Lj64IJ8Uv5fcVD8dncaZkIbu8wpnT89icmais2QWuvcOKqPyRe2ubCI3xRpu+tGzO7j2nncId5puSQaPNFg9DmeIqaXvAPE/r+zhy49s4vmtRwb1c+gId/Klhzc4QWk4KTpQx+H6No40Hl9ZWaWGigaIUWZChjVxfd2ZE3o9d4bd05ianeQMX+UkWx/oe6u6Uonvq7Ye/+cFU/nJ1QuYmJnQbYipoS2qB2GvbjLGsL28iWVTrNdoC4Vpau/gQE0LJbVtTLeHwcoiASIQmYPo+l4Ha1r44kMbaGgNscduT2Suo7KxnZW/ep2DPWpmROysaOLpjWV89dFNR/sRnXKRXlOz5shSI4wGiFFmUmYi2+9YyYcX9d6oFgkQ06PmLMalWMto90cND+22607MGJdMks/D5MwE6lpD1LcG+fumMl7Yai2XTfJ5nCGmqqYAtS1BFkxIc3aBAxQfbqC0rmuC+4j9YRkZbqmOWj775IbDPLOpjB8/v8MZ8vLaez3WH6pnx5EmpyJfT41t1vl+r5sl/+9F/vCv4VNV73B996Co1Eihq5hGofiofRHRlhZmWBPX41OdY5EVSPuiJph32oWHsu09GBPtehYfu+9dttpV68CaHN9W3khdS5Dtdhba2XkppMZ7nUSDb+2ppiUYZlpOEhmJcU4PIhIAqqN6EO/ss1KCPPTeIWeDYGT5bWRFVX/DNNVRPZnq5iA/Wr2Dz5wz5agT/adCeb0976I9CDXCaA9iDMlIjGP1l87l48snOceseYquISaXwG47QGTZhYgmZ1mb9qKDA8Dnz5tKeX07Nz203ilWNCs3mbSoHFPP272NCenx5KX6nQ9LZ4jJnoNoD4VZf6ies6ZmYkxX4Ij0NCJzJJE5jJ4qIoFDugLCy9sr+jz3VDLGUOYECK3ToQV/cDYAACAASURBVEYWDRBjzLScJPxRQ0Bet4vsJB/GgM/jIiMxzpmQznJ6EF1ZZ79+yUzn8cq5uXx8+SSKDtRRfLiBvFQ/aQlxzsT5zHHJNLRZH4oF6QlWgGhox5iundbVTVYg2HConmBHJx9fNqnbb/2RAHGotneAOFjT4qxyigx1RTbqAU7p1qHU2N5BS4+lvUqNFBogFPnp1sR2ks/DjHHWpjW3S0izP+gT4jxkJ/tI9nn45IrJ3a6dnZdCoKOTl7dXMs/ecxHpQXz38q4KswUZ8eSlxlPe0E57qJNwpyEtwRqKuuXxzU6Ni7OmZlGYlehc12xv4IsMMUV6CodqWjnvp6/x7/e/R0e40zkevew2UnxpKEV6D6CT1Grk0QChGG9nik30eZhXYH3IJ/s93WpZXDgzh2vOmEBCnIfMxDhntVQkDXlbKMzCiWmAlT8qNd7LimmZfOX9M1gyKd1ZUtvQFnLmCy6dm8us3GQeXlvCQ+8dYmJGAqkJ3m6pzVsCHXR2GkrstB/ldg+i2F7O+uaeat73i385Kc0jQ1azcpPZcaTpqEkDT7bKxnYnSaLV3qgAoT0INcJogFBOKvGEODfz860P+Z65lH589XynR/DWLRfy0lfOA6whq0gcWVhgXXvTBdO4/4YzEBG++L7pPPaFswDISrImng/aQ1hnFmby4GeXAdby17n5Vobb2XldmW5bAh1UNQcIdnSSkRhHVXOAULiTHUeacAn8z0cXUdUUcHI6ReLB6ZPSaWgL8WhRCZVN3ectNpXUd/vgBvjFi7tOqLBSxIPvHeILf13v7BiP5LNyu8TZHKjUSKEBQjkBoj0UZn5B6lHOtpaS+jxu53FhViIiOL2P8WnxLI4qrRqRmWjNaRyw9zIk+TxkJMYx0x7WmmsPUZ0xOQOPS0iMc9Mc6GCnPVS0dHIGxljDSLuONDE5M5HL54/notnjer3W4onW63/z8S384B/b+dDdb/HAmgOEwp1ccfdbXP27rvpUGw7VcdfLu7n1iS1H/2H148F3D3H+T191hrgiu823lzeRGu9lQnq8DjGpEUcDhHKGmOrbQhTY8xHZ9gqmwVhamMGCgrReiQJ7ynB6EHaAsNOCnGlvrptrL79dWpjB5tsvZlZeCi3BDlYXl5MQ53aKEx1pbGdXRRMz7aGo6HKtEdEB6q091WwsqefF7ZVsLrWGpg5HzQ38/IVdzuP2UJibHlzPzQ9vGPT9A2w53MCBmlYn+EWSHm4rb2ROXgrJfq8OMakRR/dBKKcHUd8aQkT45xfPdn7bH4zvf3Au4UHkTMpyehDWEFOSz/rn98EF43lvf60zhwHWxHiiz0N1U4CtZUd4/5xxTM2xJq/3VjZzoKbFCRgrT8vlY2dOZE9lM+/aRYjy0vzcdd0i/rm5zFlqW3y4gTV7rZVN6Qle/rG5DGPgrb3VzMlLYVt5I+sP1vHC1goSfG6MMU6qkqOJzKtEejv1rSE6wp3sKG/k+mWT2FbWeNRlrh3hTjxu/Z1NDR/6r1E5ASLitPGpzga6wYjzuPrdnBcts0cPIpJYcMnkDJ67+dxeJVGTfG62lTdS3xrisnl5TLI37L20vYJO0zVBHudx8cMPz3OGxzwuIc7t4oMLxrNqXp7z/Wpbgjxu18RoD3Vy04Mb+K+HNmAMfPPSWQD8/vV9BMOd1LeGutXDOJpIgIjs36hrDXKgpoVARydz8lJI8nuoaAzwt6KSPifOH1hzgGnfXt1vLqmOcCc/f2FntxTsSsWaBghFSrz1QX3G5N7zBidTQpwbv9flTFIn+gbuwCZGFUKaMz6F+Dg3eal+/rWrCoAZud3rSMTb5yf6PM5v/pGltxn2zuz91S14XOLs9AZrUvzc6Vmkxnt53f7eYA0bATzwzkHue2PfgG2t6pGVtq416GwsnDM+hWSfh0O1rXz9sc29Nhy+vquK7z69FbBSo/flobUl/OaVPdx7lHYodTJpgFCICG/dciF/+uTSmL9OZqKPQEcncR5Xr0y0PUUCiMclTvW8wqxE2kPW9ZMzE7ufb/dikqICz+TMRAqzErnx3CnOsTuumOs8vnJRPt//4GmICP+2uIDsZB83nDUZr1vYXNrAn98+wHefKuZHq3d07dbuwUrv0SNAtITYVtZInNvFtJwkZ74FYFdF1/6MxvYQ33hsM5PtErPRcyMR4U7D/W/uB3DqkCt1KugchAJ6DzPFSlZSHIfr25idm+wk4utP5IN+fFq8s7t6clYib++tYXpOUq88Swn2+dE1ul0u4dWvnQ9YuaVm5SXTGuzqPXzpoulMsgPNdy6fw3fspbxFB2vZWtbAhkN15KfFc7i+jUfWlvDF903v1c7mQAftoc5ux+pag+ytamZGbhJet6tbIaddFc0EOsKs3nIEr9vFkcZ2Hvzsmdz88EYO9zGstbm03inGFCkJ+8qOChZOSHd6RkrFgv46ok6pdPsDLbKkdSCRHkT0iqop9i7ryNLYaAl2CpH+hq6uWlxgza/YNSvi3C4K0hP6PHdSZiKH69qoagqwcEIaK6Zl8tSGw3SEOwl0hLudG51wMKKuNci2MmsFE0D0HP7uiiae3lDGzY9s5IF3DiACiyakk59uBaK6liA/Wr3d6ZWssZMYTsxIoKopwJGGdj71pyL+752DfbZdqZNFA4Q6pSK5leYNIkAk+awP/OjfkiNpOGbm9g4Qib7eQ0x9GWcHiMKsxH6zvY5L9lPR2E5VU4DsZB8rpmWxr7qFrz+2mSt/+zZgDS3trWrm7b29cz7tPNJETUvQCRCHogou7aps4k07T9Q7+2qZkJ5AfJyb/LR4DlS38Kk/r+UP/9rnBIA1do9pVm4yVU0Big5aK7XK+hiOOhkeXVvC9/++NSbfW40sGiDUKVVm10YYTA8iIjMqQMwvSGNiRgJnT8/qdV6CM0k98IqqOI+LnGSfs2y2L7mpPlqCYZoCHeSk+Fg4wVqC++SGw2wta6S2JciPn9vJ+37+L779ZDEA4+2VX7kpficP1Bx7b8dNF05j6eQMPnfuFEpq23gpKtNspD5Hfno8ZQ3tbDhUT3qCl+eKjxAKd1J0oI7lUzPJTvZR1Ryg6IBVE6M8KnHhh3/7Fo+sPfGd4ADfeHwz//vWgZPyvdTIpgFCnVLfWDmTZJ+H6eOSjnpuZLw9ugeRnezj9W9c0K2mRURk7iF69VN/fnXtQr568cx+n4/0MsCau5iXnxqdSZxHi0q45/W9nBMVqCIpQiKBx+MSZuclO889+vnlnD8zB4DWYJg4j/Xfb5r9syiw54FcAv95wTR2HGnintf30RYKc/7MbLKSfNS1Bp26GZF0IcGOTjYcqmfDofqj3ne3n8FLu/jxczu6HWuPWt0V/fhYNLSF+O1rewa1N0YNbxog1Cl1xcJ8tnz/EidVx0Aun5+H2yVcvbh3dby+JEQtcz2as6ZmMTW7/yAVHSByUvwk+71Mizr/J8/tIDXey2+uW+QcO218Cl63ONdeOi+v1+7y5VMz+dm/LWBBQSofXToRgOk5VhBJS7AC4ekT07lsfh4+j4ufPr+TiRkJnDcjh+xkKy17JA9VpAdRb5eAjZ4LCXZ09tpvsaW0gT2VXSuontlYxkvbrJ7M9vJG3thdxaaSriAT2Q0OVjbd54q7khAO5Lnicn7y3E42lx5bwFLDjwYINWxNy0lm73+vYsoAH+TRIkNLgwkQR9OzBwFw4awclkxKZ1pOEp0Gbjx3KmkJcbz45XP5ydXz+fTZU3j4xuVgfy7fcNakvr41Vy8u4OmbzuYDC8bjcYkzfHXW1EzOLMzgp/+2gLzUeH505TwAPnNOIW6XdJusv2BmDk3tHTQHOmiwEytGMtmGOw0zvrOabz9lDX19/+9buff1fdz4QJFTszvY0cnB2lanl/a1v23i4398j5+9sNN5jeilu/e9sY//+Ov6QfUqIrU7jmWjoRqeYrrMVURWAr8G3MB9xpg7+zjnGuB2rP9Wm4wxH7WPh4FI9rRDxpgPxrKtauSLd4aYjt47OZpIrW6AHPvxratmA/CtJ7dQ2xJ0KvNNH5fMdHtV1eJJ6UxIj+e8mdksnpQx4GssnpTOpu9d7AS0zCQfj3xuufP8lacXcMbkDCc/VqSAE8CqeXm8vKOSud973ulh1dg9iEihpAffPcQPPzS323xCeUM7FY3tNLSFCHca6lqDhDsNAbvQ0toDdYhgV/XrChD7a1rpNNZGw+hsu305VGsFhkgVQDVyxSxAiIgbuBt4P1AKrBWRZ4wx26LOmQ7cCqwwxtSJSE7Ut2gzxiyMVfvU6JMWH8es3GTmDiIj7dEkxHlI9ntoDYbJSOi+1+Dbq2Zz8/um97taKifFzxUL8wf1Okfr7UyIquaXHRUgIkED4LF1pQDU2B/ojxaVAFa+qZqW3ktwX95e6RR1MsZaktvQFuIjSybwrVWzqWsNcv7PXqO6Och7+2spOljrpEfZU9k8iABx/D2I6uYAGQlx3WqRqKETyx7EUmCPMWYfgIg8DFwBbIs657PA3caYOgBjTGUM26NGuTiPi+duPvekfb9xKX6a2kO9PqwSfZ6TMox1rMan+Vk1L5fPnjOlz2SKLcEw28oaea74CAB1rSGKD3fldlo0MY2a5iCv7Kjstsy4orGd6uYA41J8pCZ48Xqs+61uDvDuvloeX1/q1PyI1C4fSCRfVHTeqMP1bUfdjNnYHuLsH7/CnVfO50OLBhdgVWzFcg4iHyiJ+rrUPhZtBjBDRN4SkXfsIakIv4gU2cc/FMN2KtWniRkJ/W6kGwoet4vffmwxiyamMy6172y7tz6xGZ/HxQ+uOA2AV3dYv3Pddd0ifnr1ApYWZrCxpI49UR/0uyqaMMbq+YDVe0qIc1PdFHRWSkUWJO2p7LquPRSm+HAD+6tb+N7TxYQ7rVrjkcntyK7wjSX1rLjzlW7Bqi9H7HK00a+hhlYsA0RffcSe6948wHTgfOA64D4RieR8nmiMWQJ8FPiViEzt9QIiN9pBpKiqqqrn00qdkB9+eC6/+sjwHOX0edy8+c0L+NDC8d2Obypt4KNnTuSMQmv+4+UdlXjdwqq5uUzLSWLBhDSqm4O8tqOSqdnWctxIgsDoifmsJB81Ldau7Yi0BC97q1p4ZlMZF/3iX/zxzf1ccfdb3PP6Pv685iCHaludXsOEjHhK69ro7DTOB/7RPvgjcyj95bxSp14sA0QpMCHq6wKgrI9znjbGhIwx+4GdWAEDY0yZ/fc+4DVgUY9rMcbcY4xZYoxZkp2dffLvQI1peanx3eYAhpuC9ASn2FO0s6ZlMTnTqvJXWtfGxIwEp85EpCxsU6CDj5xh/ffcVm4FiJyoVVJZSXFUNwcoiyrNesHMHPZVNfPajkr2VDbz8NpDhDsNz2y0UqhXNLazr8qaq1g+JZNguJPKpoDzgd9XIsJokVVYlT0y46qhE8sAsRaYLiKFIhIHXAs80+Ocp4ALAEQkC2vIaZ+IpIuIL+r4CrrPXSil6PqtP97btXLr9InpVilYOwlhJD0JWClK4jwuXGKtknK7hO3lTd2+F1grqvZUNtMe6iQrKY5xKT7OmZ5FoKPT2QVeYq9WarGTH1Y0tvPQe4fISfbxkTOsPR5/evuAEyCOlhpEexDDT8xm2owxHSJyE/A81jLX+40xW0XkDqDIGPOM/dzFIrINCANfN8bUiMhZwB9EpBMriN0ZvfpJKWWJLMedkp3o1JmIpFF/6MZlvLitgiVRdT7iPC6WTEpHxBpGykiMo6opYH/dtVprfKqfF7dZv8l/9/I5nD8jh6pm64O7sZ/a2q/sqOTNPdXccuksFk9K5yNLJnDvG/ucxIo9A0Swo5NfvrSLi+eMY9HEdGcVlvYgho+YLsUwxjwLPNvj2G1Rjw3wFftP9DlvA/Ni2TalRoPsZOu3/rzUeLaWNTIlu6u3MC7Fz/XLem/W+931i520IRkJVoDITPR1K3e6tDCTP6+xkgVOzEggNcFLkt+avG4NhnGJNXEdSYUO8OwWa6f1NUusoasbVkzmkaISZwgrOncUwDv7avjda3v53Wt7eeI/znKW5Na2BAnaNUPU0NJ3QKkRLNKDSE/w8tJXzuWp/1xx1GtS471OedfI7uxIwaKIs6ZmOo8jxZrcLuG08dYeiItmjyPO7eLGc6eQ5POQleQjFDbkpvid3FlTs5PwurvWqkQCSU1zgCvufou/vtuVrnzN3hpniAnglic2szuqsNKB6hbagseXG0odPy0YpNQIFvmAT0vwMi2ndwr0o/nO5bPZXt7I+TNyuh1P75EgMWJefhprD9Tx31fOo6EtxJSsRK5eXMCn/7yW6uZAtzKwcR4X03KS2V7eiN/roqm9g8b2EO/ur2VTST2bgLn5KVQ3BdlX1UJNS8DZxf3E+sM0tnVw3yeW0B4Ks+quN7j2jIl89/LZfO+ZrczMTeZjZ/adykSdPBoglBrBfB43P/u3BSyedHz1xGflpjArt++d0T+44jTeO1DXrWbG58+bwrIpGWQl+ZzUH4k+jzPBPatHnY7ZuVaAmJ+fxnsHaimrb2NrWdd+iCWTMth5pIl91c00tIUozExkn1097+UdFZTUtnK4vo3WYJh/biljXkEKf7GHvjwucSbDVWxogFBqhBtstttj9fHlk/n48sndjuWk+Ln4tNxe50aq9M3oUelvdl4KbDjMeTOzee9ALY8VlbK7spnUeC9N7SHOmZ5FMNzJs1vKMQbOmW4VZrKW2Qb5x+ZyQmErT1RFY4AvP7KJufkptATCvLitgqIDdczMTeYz50zp1SZ14jRAKKVOWGQXds9SsGdOybA26s3L43B9G/e/tZ9OA1edXsA3V84kO9nH/uoW6u2MtNNzkrnv3/NZOiWDC376GodqWymta2VSZgIH7ap8v7xmIb94cRebSxuoaGwnye/h+mWT8HuPL0njuoO1vLe/ji+c32sv7pinAUIpdcJWzs2lsrHdKZAUMb8gjWK7/sctl87iifWltIc6mZmb5ASV6JVXeal+LpozDrAq7JXWtbLuYB1XLy7guqUTyUn2kZnkY2p2EqvtnFP1rSH+ubmcqxYX8M6+GjwuYcnkvjPpvr2nmsqmQLdcT5/9yzpqW4J8YEHesEqtMhzoKial1AnLT4vn1lWzuy2VjYgUh0rxe3ns82cxY1wSF8zsmhSPFEzKS/XzgQVdqUPGp8az/mAdrcEwp41PYXZeCplJXfs+IhLi3PzTXmL7qT+t5erfr+Fpe3d3tI5wJx+9711ufmRjt2JKKX7r9+RIkkPVRXsQSqlTZm5+Ki98+bxuxyZkJPC3zy9nXn5qt2Gi/PR4Z5f2tJzuRaMi1QDj3C4uOS2X13dVYYyhw84q+J2niik+3MAbu6u5dG4eF582zkmDDlDVFHB6MJHXXF18ROcyetAehFJqyJ0xOaPXHEJ0nqlp2d2HriI9iGk5SSyelE5NS5ADNa2Ewp2smpdLS6CDe9/YT2ldG09uKOVHq3d0K5y040jXHotIao+NJfV02BPiw83TGw/zrl2L/FTSAKGUGpYi9SOyk606FdGS/V4mZiSwYEKaU7L15e0VGAPLp2bxjZWzuPmi6XzszImU1bdzsKaF0yem8cpXrd7LLnsTXnsoTF1riAkZ8YQ7Ta/d3sPFT5/fyf1v7T/lr6tDTEqpYSkSIKb1U5P80c8tJ9Hnxu914/O4nCSC2Uk+Pm6nGPnLmgMEw50crGll5dxcpmQnkZXkY6fdg6iy8z4tmZRBSe1hSmpbh2UG38a2EC2BU7+TXHsQSqlhKd8uq9pz/iEiN9VPst+L1+1idl4KRQfqAMhO7toFHl2aNbJCaVZuMlsON2CM4Yg9vBRJaDhQHe2391Sz4s5XnIJIEdET3oMV7hz8NcZYhZiaA30nSYwlDRBKqWEpPcHLJ1dM5srTj15+dMa4JGeCOjupK215flpXb2CCHSxWzs1lx5Em7ntjvzP/sHBCGm6XOCnM+/KvXVUcrm/jlR1dlZFf3VnJoh+82K28al+MMTy2rpTG9hDtoTDTvv0sP39h51HvC6x06p0GWjRAKKWURUT43gdOY9HEo6cRmR6VhyorqgeRH9WDiAwdfezMiZw3I5vf/WuvUzEvPy2e8Wl+Supa2VXRxN2v7unVM4hkpY2UcW1qD3Hr41uobw2xqbR+wPYdqm3la3/bxKNrS6hqCmAM/OaVPdS3Bge8LvI6gPYglFLqeEwbZw1DJca5SYjrmlpN8nmc+hiROQ0R4bwZ2dS2BNlW1kicx0VqvJcJ6QmU1Lby13cO8tPnd/J/7xzku08Vs7Wsge88tYWNJVYQeH1XFdXNAe5cvYPKJivA7K1sGbB9FY3WXMe2skZn1zjA1x/bfNSVU012/Y2hCBA6Sa2UGvGm2/MU0ZlnI/LT4vF5XN2W0U63A8qL2yqYlp2EiDAhPcGu4W393vzdp7cCVp2LSK2Ky+bn8XzxEZb/6GVCYcNnzi7kua1H2Fc9cL3tSCDZVt5Ind1ruHx+Hv/YXM7Da0v6rNsREelBtAQ6MMYgIv2ee7JpD0IpNeKNT40nIc7tZJiNtnxqZrf6FtA1JNUU6OD0SdYy2Rm5yVQ3B5yeAkCyz+MEB4B/XzaJ524+l0+dXcgXL5zGVy+eyZTsJPZWDRwgIqul9lY1OxXzbr5oOglxbg5Ut2CM4fMPrGO1vSM8WqSCX6eB9tCp3aehPQil1IjncgnLpmQysY8lqt+9fE6vY+NSfCT7PDQFOlg0wZrjWDHNCiKBjk4+uWIyEzMSKEhP4K6Xd/OZcwr57at7mZufSqLPw62Xzna+19TsRIoO1Pb67d4Yw7qDdSyckOYEhVDYsO5gLQBpCXFkJfmobg5Q1RTgua1HCBvDpfPyurW1KarEa1MgRHzc8SUlPB4aIJRSo8L9N5wx6HNFhOnjklh/qJ7T7VoaM8clOx/Yl5yWy7IpVsB4v5088IqFfa+mmpKdRGswzJHGdqf6Hli5nb7w1/X8+Kp5VDUFnDKta/ZaO6JT471kJsVR0xJku70vY2NJvRNo7ly9gwUFqc4QE2DthTj2ulDHTYeYlFJj0rz8VMal+JxyqyLC2XYvomfho4EUZlppPw5Ut1JW38bZP36F4sMN3PncDsDK8VTVFGDGuGRcAgdqWkn2efC6XWQm+qhuDrLziLVCqqopQHlDO+2hMPe+sY/739rfrQfRc6nro2tLeGJ96fH/EI5CexBKqTHpGytn8YXzp3UbFvr8+VOZm59KWkLcAFd2l5tq7buoaGynoS1EaV0btz1dzMGaVmblJvPWnmpyU/3MyEmmqb2Dw/VtpCVaK6uykuLYXFrPjvImp4exsaSeCekJhDsNG0vqmZef5rxW9Eqm54rL+cbjmwG48vTYFI3SHoRSakxK9HmcD/eIWbkpx5zRNfI9jjS2c7je2mi3/lA98V43t10+h1DYUFLbRnayjwkZ1hBUuh2AIkNM28obWTYlkziPi/f217Ld3nMRChv+tatrY15zVG/iVy/tdh6X1fe/we9EaIBQSqkTkOTzkOTzcKShncN1XR/UZ03NZPnUTKZkWUNQ2ck+ZxI90kPJTPQR7jTsONLEvPxUzp2ezericraWNeD3unC7hL1VXXssWoJWgGhqD7GzoomLZlvzI0UH62JybxoglFLqBI1L8XGkob3bb/Lnz8xGRLh6iTX8E+40TLDzQaXZm/eyovZtzC9I44MLx1PRGOBv60qZlZvCIjtTbVaSFVAiQ0zWZDZ8bNlEEuLcrDtQG5P70jkIpZQ6Qbmpfo40thPuNKyYlskFM3OceYFPrSikvjXEx5dP4r391gd5up2+PCuxa65j4cQ00hO8JPk8NAc6WFCQyrhUP0UH65x5ksgk9bqDdYjAkknpLJyQFrMehAYIpZQ6QeNS/KzZW0Ogo5O5+bnd5jH8XjffWmXtm5jQc4gpamPf+FQ/IsKT/3EWFY0BFk1Mo6SulZ88t5OqpgAiXXMQ6w7WMSMnmWS/l29fNpvEuNh8lGuAUEqpE5Sb4neKDUWnGO+pMDOROLfLSSKYmdTVg4j0EqaPS2b6OGuZ7Uz773NnZLP+YB3NgTANbSHe2VfDDWdNBuC08akn/X4iNEAopdQJykuNTjHef4BIT4zjxa+c65RTjaxm+tx5fa+cEhE2334xPo+Lebe/wP1v7eetPdWEwoZVPXZcx0JMJ6lFZKWI7BSRPSJySz/nXCMi20Rkq4g8GHX8EyKy2/7ziVi2UymlTsS4lK4AMb9g4N/oJ2UmOgkB3S5h73+v4paVs/o9P8XvxedxO+nHd1Y0kZ8W75RajaWY9SBExA3cDbwfKAXWisgzxphtUedMB24FVhhj6kQkxz6eAXwPWAIYYJ19bWxmYpRS6gSsmJbFZ88p5KrFBUzpp0Rqf9yuwWVn/etnlpEQ52Z7eSNZSb5TktU1lkNMS4E9xph9ACLyMHAFsC3qnM8Cd0c++I0xkR0hlwAvGmNq7WtfBFYCD8WwvUopdVwSfR6+fVnvpIAn09LCDADm5sduzqGnWA4x5QMlUV+X2seizQBmiMhbIvKOiKw8hmsRkRtFpEhEiqqqqk5i05VSSsUyQPTV/+lZqdsDTAfOB64D7hORtEFeizHmHmPMEmPMkuzs7BNsrlJKqWixDBClwISorwuAsj7OedoYEzLG7Ad2YgWMwVyrlFIqhmIZINYC00WkUETigGuBZ3qc8xRwAYCIZGENOe0DngcuFpF0EUkHLraPKaWUOkViNkltjOkQkZuwPtjdwP3GmK0icgdQZIx5hq5AsA0IA183xtQAiMgPsIIMwB2RCWullFKnhkTW1o50S5YsMUVFRUPdDKWUGlFEZJ0xZklfz2k2V6WUUn3SAKGUUqpPo2aISUSqgIMn8C2ygOqT1JyhNlruZbTcB+i9DFd6LzDJGNPnPoFREyBOlIgU9TcON9KMlnsZLfcBei/Dld7LwHSISSmlVJ80QCilIlGzNQAABfNJREFUlOqTBogu9wx1A06i0XIvo+U+QO9luNJ7GYDOQSillOqT9iCUUkr1SQOEUkqpPo35ADGYsqjDmYgcEJEtIrJRRIrsYxki8qJdrvVFO+HhsCMi94tIpYgURx3rs+1iuct+nzaLyOlD1/Le+rmX20XksP3ebBSRVVHP3Wrfy04RuWRoWt03EZkgIq+KyHa7FPCX7OMj6r0Z4D5G3PsiIn4ReU9ENtn38n37eKGIvGu/J4/YiVEREZ/99R77+cnH9cLGmDH7ByuJ4F5gChAHbALmDHW7jvEeDgBZPY79BLjFfnwL8OOhbmc/bT8XOB0oPlrbgVXAaqxaIcuAd4e6/YO4l9uBr/Vx7hz735oPKLT/DbqH+h6i2pcHnG4/TgZ22W0eUe/NAPcx4t4X+2ebZD/2Au/aP+tHgWvt478HvmA//g/g9/bja4FHjud1x3oPwimLaowJApGyqCPdFcCf7cd/Bj40hG3plzHmdaBnlt7+2n4F8BdjeQdIE5G8U9PSo+vnXvpzBfCwMSZgrDooe7D+LQ4LxphyY8x6+3ETsB2rouOIem8GuI/+DNv3xf7ZNttfeu0/BrgQeMw+3vM9ibxXjwHvk+MoYj3WA8SgSpsOcwZ4QUTWiciN9rFxxphysP6TADlD1rpj11/bR+p7dZM97HJ/1FDfiLkXe2hiEdZvrCP2velxHzAC3xcRcYvIRqASeBGrh1NvjOmwT4lur3Mv9vMNQOaxvuZYDxCDKm06zK0wxpwOXAr8p4icO9QNipGR+F79DpgKLATKgZ/bx0fEvYhIEvA4cLMxpnGgU/s4Nmzup4/7GJHvizEmbIxZiFVhcykwu6/T7L9Pyr2M9QAx4kubGmPK7L8rgSex/uFURLr49t+VQ9fCY9Zf20fce2WMqbD/U3cC99I1XDHs70VEvFgfqn81xjxhHx5x701f9zGS3xcAY0w98BrWHESaiEQKv0W317kX+/lUBj8E6hjrAWIwZVGHLRFJFJHkyGOs0qzFWPfwCfu0TwBPD00Lj0t/bX8G+Hd7xcwyoCEy3DFc9RiH/zDWewPWvVxrrzQpxKrD/t6pbl9/7LHqPwLbjTG/iHpqRL03/d3HSHxfRCRbRNLsx/HARVhzKq8CV9un9XxPIu/V1cArxp6xPiZDPTs/1H+wVmDswhrP+/ZQt+cY2z4Fa9XFJmBrpP1YY40vA7vtvzOGuq39tP8hrC5+COs3nk/313asLvPd9vu0BVgy1O0fxL08YLd1s/0fNi/q/G/b97ITuHSo29/jXs7GGo7YDGy0/6waae/NAPcx4t4XYP7/b+9+XnSK4jiOvz9S41exYWNBw0aKKTtSyj9gQVOYZG1jJ+VH2VsqlmQWIjaWZjE1C5ExC8lispq9FMWCr8U9NHSNB/NDeb9Wz3Oec89zz+L2vffU/RzgeTvnF8Cl1j5MV8RmgbvAUGtf077Ptt+H/+R/jdqQJPX635eYJEk/YYGQJPWyQEiSelkgJEm9LBCSpF4WCOkfkORQkocrfR7SfBYISVIvC4T0G5KcbLn8M0lutAC1d0muJplOMpFkc+s7kuRxC4V7MG//hJ1JHrVs/+kkO9rwG5LcS/IqyfifpG9Ki8kCIQ0oyS5glC4gcQT4BJwA1gPT1YUmTgKX2yG3gHNVtYfuzd2v7ePAtaraC+ynewMburTRs3T7EgwDB5Z8UtICVv+6i6TmMLAPeNpu7tfSBdZ9Bu60PreB+0k2ApuqarK13wTutuysrVX1AKCqPgC08Z5U1Vz7PgNsB6aWflpSPwuENLgAN6vq/HeNycUf+i2UX7PQstHHeZ8/4fWpFeYSkzS4CeBoki3wbY/mbXTX0ddEzePAVFW9Bd4kOdjax4DJ6vYjmEtypI0xlGTdss5CGpB3KNKAquplkgt0O/itoktuPQO8B3YneUa3c9doO+QUcL0VgNfA6dY+BtxIcqWNcWwZpyENzDRX6S8leVdVG1b6PKTF5hKTJKmXTxCSpF4+QUiSelkgJEm9LBCSpF4WCElSLwuEJKnXF1g1kUFgXMiGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "準確率 : 0.6517412935323383\n"
     ]
    }
   ],
   "source": [
    "# 無valid\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\n",
    "optimizers = adam\n",
    "kernel_init = 'glorot_uniform'\n",
    "recurrent_init = 'glorot_uniform'\n",
    "bias_init ='zero'\n",
    "epochs = 300\n",
    "batches = 80\n",
    "\n",
    "model_LSTM = create_LSTM_model(optimizer=optimizers, batch_size=batches, kernel_init=kernel_init, \n",
    "                 recurrent_init=recurrent_init, bias_init=bias_init)\n",
    "\n",
    "history = model_LSTM.fit(_X_train,_y_train,\n",
    "           epochs=epochs,\n",
    "           batch_size=batches)\n",
    "\n",
    "#畫出LOSS圖\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model train loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper right')\n",
    "#plt.savefig('plot.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "preds = model_LSTM.predict(X_test_std)\n",
    "actuals = y_test\n",
    "\n",
    "#格式轉換\n",
    "change_pred = []\n",
    "for i in range(len(preds)):\n",
    "    if(preds[i][0]>0.5):\n",
    "        change_pred.append(1)\n",
    "    else:\n",
    "        change_pred.append(0)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(actuals,change_pred)\n",
    "print(\"準確率 : \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T+1 report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64       185\n",
      "           1       0.69      0.70      0.69       217\n",
      "\n",
      "    accuracy                           0.67       402\n",
      "   macro avg       0.66      0.66      0.66       402\n",
      "weighted avg       0.67      0.67      0.67       402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "threshold = 0.5\n",
    "preds = np.where(preds >= threshold, 1, 0)\n",
    "\n",
    "t1r = list(map(int,preds[:,0]))\n",
    "t1t = list(map(int,y_test[:,0]))\n",
    "\n",
    "print('T+1 report\\n %s'%(metrics.classification_report(t1r, t1t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 5, 64)             34304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5, 128)            98816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 529,409\n",
      "Trainable params: 528,513\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將參數儲存至 HDF5 檔案\n",
    "model_LSTM.save('KLSTM0(6716).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "準確率 : 0.7562189054726368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = loaded_model.predict(X_test_std)\n",
    "actuals = y_test\n",
    "\n",
    "#格式轉換\n",
    "change_pred = []\n",
    "for i in range(len(preds)):\n",
    "    if(preds[i][0]>0.5):\n",
    "        change_pred.append(1)\n",
    "    else:\n",
    "        change_pred.append(0)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(actuals,change_pred)\n",
    "print(\"準確率 : \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他的準確率判斷\n",
    "from sklearn import metrics\n",
    "print(\"準確率 : \" + str(accuracy))\n",
    "print('T+1 report\\n %s'%(metrics.classification_report(actuals, change_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 5, 256)            333824    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 5, 256)            1024      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 5, 256)            525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 5, 256)            1024      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,387,777\n",
      "Trainable params: 1,386,241\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將參數儲存至 HDF5 檔案\n",
    "model_LSTM.save('KLSTM(7114).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "# 從 HDF5 檔案中載入模型\n",
    "loaded_model = keras.models.load_model('KLSTM1.h5',custom_objects={'root_mean_squared_error': root_mean_squared_error})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = loaded_model.evaluate(X_test_std, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41312772035598755, 0.7562189102172852]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(actuals)\n",
    "plt.plot(change_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 同參數去跑個幾次，把好的結果記錄下來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.8147 - accuracy: 0.4994\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7995 - accuracy: 0.5374\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.7992 - accuracy: 0.5224\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7939 - accuracy: 0.5149\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7758 - accuracy: 0.5349\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7664 - accuracy: 0.5455\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7486 - accuracy: 0.5411\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.7327 - accuracy: 0.5592\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.7261 - accuracy: 0.5679\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 1s 349us/step - loss: 0.7373 - accuracy: 0.5585\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.7234 - accuracy: 0.5610\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.7228 - accuracy: 0.5623\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.7243 - accuracy: 0.5654\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7197 - accuracy: 0.5523\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7195 - accuracy: 0.5623\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.7102 - accuracy: 0.5785\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7144 - accuracy: 0.5747\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6978 - accuracy: 0.5878\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6987 - accuracy: 0.5884\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7163 - accuracy: 0.5604\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6937 - accuracy: 0.5834\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7236 - accuracy: 0.5560\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6963 - accuracy: 0.5984\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7025 - accuracy: 0.5778\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6954 - accuracy: 0.5778\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6968 - accuracy: 0.5778\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6866 - accuracy: 0.5922\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.7011 - accuracy: 0.5791\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6904 - accuracy: 0.6027\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6968 - accuracy: 0.5897\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6946 - accuracy: 0.5778\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 1s 349us/step - loss: 0.6772 - accuracy: 0.6027\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6887 - accuracy: 0.5897\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7008 - accuracy: 0.5729\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6900 - accuracy: 0.5803\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6724 - accuracy: 0.5984\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6840 - accuracy: 0.5903\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7062 - accuracy: 0.5841\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6961 - accuracy: 0.5922\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6889 - accuracy: 0.5834\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6822 - accuracy: 0.5953\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6795 - accuracy: 0.5878\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6755 - accuracy: 0.5909\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6740 - accuracy: 0.5984\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6837 - accuracy: 0.6065\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6852 - accuracy: 0.5959\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6871 - accuracy: 0.5853\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6763 - accuracy: 0.6077\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.6781 - accuracy: 0.5990\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6807 - accuracy: 0.5971\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6724 - accuracy: 0.6021\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6741 - accuracy: 0.5971\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6692 - accuracy: 0.6133\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6802 - accuracy: 0.6027\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6799 - accuracy: 0.6040\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6779 - accuracy: 0.5996\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6676 - accuracy: 0.6121\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6666 - accuracy: 0.6102\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6857 - accuracy: 0.5946\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6692 - accuracy: 0.6021\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6739 - accuracy: 0.5971\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6764 - accuracy: 0.6077\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6647 - accuracy: 0.6158\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6754 - accuracy: 0.6196\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6683 - accuracy: 0.6021\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6706 - accuracy: 0.6021\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6674 - accuracy: 0.5971\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6680 - accuracy: 0.6034\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6606 - accuracy: 0.6189\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6709 - accuracy: 0.6027\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6823 - accuracy: 0.6009\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6789 - accuracy: 0.6065\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6641 - accuracy: 0.6059\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6619 - accuracy: 0.6164\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.6699 - accuracy: 0.6152\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6652 - accuracy: 0.6183\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6701 - accuracy: 0.6164\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6728 - accuracy: 0.5959\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6713 - accuracy: 0.6077\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6820 - accuracy: 0.5996\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6841 - accuracy: 0.6059\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.6725 - accuracy: 0.6183\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6547 - accuracy: 0.6102\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6461 - accuracy: 0.6189\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6574 - accuracy: 0.6139\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6557 - accuracy: 0.6301\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6512 - accuracy: 0.6214\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6654 - accuracy: 0.6183\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6657 - accuracy: 0.6127\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6596 - accuracy: 0.6152\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6536 - accuracy: 0.6289\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6542 - accuracy: 0.6276\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6651 - accuracy: 0.6133\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6555 - accuracy: 0.6177\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6579 - accuracy: 0.6326\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6629 - accuracy: 0.6289\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6550 - accuracy: 0.6301\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6488 - accuracy: 0.6270\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6577 - accuracy: 0.6133\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6581 - accuracy: 0.6208\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6463 - accuracy: 0.6276\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6541 - accuracy: 0.6096\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6577 - accuracy: 0.6139\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 1s 350us/step - loss: 0.6541 - accuracy: 0.6189\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 1s 350us/step - loss: 0.6529 - accuracy: 0.6196\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.6516 - accuracy: 0.6276\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6529 - accuracy: 0.6333\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6512 - accuracy: 0.6252\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6432 - accuracy: 0.6407\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6427 - accuracy: 0.6494\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6646 - accuracy: 0.6183\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6482 - accuracy: 0.6252\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6437 - accuracy: 0.6301\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6447 - accuracy: 0.6420\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6744 - accuracy: 0.6015\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6475 - accuracy: 0.6208\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6366 - accuracy: 0.6488\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6568 - accuracy: 0.6345\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6475 - accuracy: 0.6301\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6419 - accuracy: 0.6432\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6493 - accuracy: 0.6333\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6487 - accuracy: 0.6426\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6449 - accuracy: 0.6364\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6539 - accuracy: 0.6233\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6482 - accuracy: 0.6357\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6408 - accuracy: 0.6513\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6324 - accuracy: 0.6494\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6466 - accuracy: 0.6357\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6361 - accuracy: 0.6432\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6378 - accuracy: 0.6588\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6528 - accuracy: 0.6333\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6475 - accuracy: 0.6376\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6362 - accuracy: 0.6445\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6419 - accuracy: 0.6308\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6421 - accuracy: 0.6488\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6303 - accuracy: 0.6426\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6267 - accuracy: 0.6532\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6359 - accuracy: 0.6451\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6360 - accuracy: 0.6619\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6395 - accuracy: 0.6432\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6445 - accuracy: 0.6357\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6400 - accuracy: 0.6326\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6353 - accuracy: 0.6357\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6437 - accuracy: 0.6426\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6290 - accuracy: 0.6526\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6396 - accuracy: 0.6457\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6369 - accuracy: 0.6413\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6395 - accuracy: 0.6364\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6353 - accuracy: 0.6538\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6250 - accuracy: 0.6594\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6331 - accuracy: 0.6451\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6342 - accuracy: 0.6407\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6340 - accuracy: 0.6463\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6305 - accuracy: 0.6457\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6294 - accuracy: 0.6613\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6288 - accuracy: 0.6420\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6284 - accuracy: 0.6476\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6259 - accuracy: 0.6544\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6364 - accuracy: 0.6370\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6267 - accuracy: 0.6550\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6205 - accuracy: 0.6569\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6270 - accuracy: 0.6389\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6298 - accuracy: 0.6426\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6221 - accuracy: 0.6613\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6250 - accuracy: 0.6669\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6326 - accuracy: 0.6600\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6412 - accuracy: 0.6445\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6311 - accuracy: 0.6638\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6147 - accuracy: 0.6501\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6224 - accuracy: 0.6469\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6199 - accuracy: 0.6625\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6274 - accuracy: 0.6538\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6181 - accuracy: 0.6619\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6140 - accuracy: 0.6812\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6251 - accuracy: 0.6432\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6195 - accuracy: 0.6557\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6185 - accuracy: 0.6706\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6317 - accuracy: 0.6544\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6295 - accuracy: 0.6563\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6219 - accuracy: 0.6569\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6143 - accuracy: 0.6694\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6176 - accuracy: 0.6550\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6151 - accuracy: 0.6538\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6071 - accuracy: 0.6793\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6208 - accuracy: 0.6613\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6275 - accuracy: 0.6451\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6167 - accuracy: 0.6451\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6128 - accuracy: 0.6775\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6195 - accuracy: 0.6650\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6148 - accuracy: 0.6793\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6115 - accuracy: 0.6737\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6158 - accuracy: 0.6669\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6167 - accuracy: 0.6600\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6063 - accuracy: 0.6737\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6065 - accuracy: 0.6725\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6047 - accuracy: 0.6806\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6245 - accuracy: 0.6675\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6173 - accuracy: 0.6631\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5913 - accuracy: 0.6806\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6183 - accuracy: 0.6563\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6105 - accuracy: 0.6700\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6092 - accuracy: 0.6731\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6092 - accuracy: 0.6700\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6058 - accuracy: 0.6656\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6042 - accuracy: 0.6650\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6018 - accuracy: 0.6880\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6048 - accuracy: 0.6700\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6127 - accuracy: 0.6712\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6235 - accuracy: 0.6631\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6003 - accuracy: 0.6681\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6026 - accuracy: 0.6818\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6017 - accuracy: 0.6787\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.6013 - accuracy: 0.6824\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.5919 - accuracy: 0.6843\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6141 - accuracy: 0.6600\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6010 - accuracy: 0.6756\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6054 - accuracy: 0.6706\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5949 - accuracy: 0.6756\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6010 - accuracy: 0.6856\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5920 - accuracy: 0.6862\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5969 - accuracy: 0.6737\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5852 - accuracy: 0.7017\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5984 - accuracy: 0.6812\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5811 - accuracy: 0.6893\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5829 - accuracy: 0.6837\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6016 - accuracy: 0.6756\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5956 - accuracy: 0.6843\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5832 - accuracy: 0.6936\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5911 - accuracy: 0.6974\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5839 - accuracy: 0.6849\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5775 - accuracy: 0.6955\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5938 - accuracy: 0.6862\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5761 - accuracy: 0.6887\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5865 - accuracy: 0.6800\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5787 - accuracy: 0.6936\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5870 - accuracy: 0.6993\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5896 - accuracy: 0.6856\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5875 - accuracy: 0.6843\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5809 - accuracy: 0.6930\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5827 - accuracy: 0.6862\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5826 - accuracy: 0.7005\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5956 - accuracy: 0.6812\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5836 - accuracy: 0.6856\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5954 - accuracy: 0.6824\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5701 - accuracy: 0.6980\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5911 - accuracy: 0.6905\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5911 - accuracy: 0.6899\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 1s 350us/step - loss: 0.5739 - accuracy: 0.7024\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5823 - accuracy: 0.7067\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5766 - accuracy: 0.7055\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5712 - accuracy: 0.7092\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5739 - accuracy: 0.7092\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5713 - accuracy: 0.7080\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5811 - accuracy: 0.6874\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5799 - accuracy: 0.6862\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5850 - accuracy: 0.6968\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5825 - accuracy: 0.6986\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5603 - accuracy: 0.7186\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5794 - accuracy: 0.7017\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5763 - accuracy: 0.7067\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5721 - accuracy: 0.7067\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5613 - accuracy: 0.7148\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5711 - accuracy: 0.7179\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5703 - accuracy: 0.7017\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5641 - accuracy: 0.7161\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5647 - accuracy: 0.7067\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5663 - accuracy: 0.7080\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5793 - accuracy: 0.6924\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5549 - accuracy: 0.7210\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5711 - accuracy: 0.7042\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5563 - accuracy: 0.7161\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5725 - accuracy: 0.7005\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5757 - accuracy: 0.7055\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5722 - accuracy: 0.7105\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5622 - accuracy: 0.7179\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5693 - accuracy: 0.7024\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5636 - accuracy: 0.7117\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5651 - accuracy: 0.7030\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5699 - accuracy: 0.7036\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5560 - accuracy: 0.7154\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5618 - accuracy: 0.7105\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5554 - accuracy: 0.7123\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5774 - accuracy: 0.7024\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5590 - accuracy: 0.7067\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5608 - accuracy: 0.7254\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5614 - accuracy: 0.7036\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5437 - accuracy: 0.7267\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5505 - accuracy: 0.7123\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5620 - accuracy: 0.7130\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5437 - accuracy: 0.7210\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5677 - accuracy: 0.7024\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5580 - accuracy: 0.7117\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5533 - accuracy: 0.7186\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5571 - accuracy: 0.7179\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5603 - accuracy: 0.7198\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5492 - accuracy: 0.7130\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5493 - accuracy: 0.7210\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5396 - accuracy: 0.7354\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5476 - accuracy: 0.7260\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5488 - accuracy: 0.7167\n",
      "準確率 : 0.6492537313432836\n",
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.7898 - accuracy: 0.5262\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7559 - accuracy: 0.5274\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.7496 - accuracy: 0.5492\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.7156 - accuracy: 0.5847\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.7303 - accuracy: 0.5648\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 1s 334us/step - loss: 0.7062 - accuracy: 0.5772\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.7129 - accuracy: 0.5741\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.7126 - accuracy: 0.5710\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.7238 - accuracy: 0.5554\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 1s 336us/step - loss: 0.6950 - accuracy: 0.5897\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.6803 - accuracy: 0.6027\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.7048 - accuracy: 0.5841\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6818 - accuracy: 0.5859\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6957 - accuracy: 0.5890\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6858 - accuracy: 0.5915\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6842 - accuracy: 0.5909\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6904 - accuracy: 0.5890\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6887 - accuracy: 0.6002\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6816 - accuracy: 0.5940\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6898 - accuracy: 0.5660\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6930 - accuracy: 0.5847\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6837 - accuracy: 0.5866\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6842 - accuracy: 0.5778\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6942 - accuracy: 0.5890\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6772 - accuracy: 0.6077\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6732 - accuracy: 0.5866\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6697 - accuracy: 0.5996\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6887 - accuracy: 0.6021\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6842 - accuracy: 0.6021\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6831 - accuracy: 0.6096\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6780 - accuracy: 0.6183\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6688 - accuracy: 0.6127\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6908 - accuracy: 0.5922\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6738 - accuracy: 0.5915\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6813 - accuracy: 0.5922\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6743 - accuracy: 0.6052\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6715 - accuracy: 0.6059\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6810 - accuracy: 0.5953\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6744 - accuracy: 0.6090\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.6813 - accuracy: 0.5922\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6643 - accuracy: 0.6164\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6883 - accuracy: 0.5934\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.6739 - accuracy: 0.6046\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6564 - accuracy: 0.6196\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6657 - accuracy: 0.6152\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6718 - accuracy: 0.6127\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6588 - accuracy: 0.6083\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6576 - accuracy: 0.6239\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6645 - accuracy: 0.6252\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6745 - accuracy: 0.6027\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6788 - accuracy: 0.6115\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6500 - accuracy: 0.6276\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6735 - accuracy: 0.5940\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6565 - accuracy: 0.6295\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6743 - accuracy: 0.6189\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6632 - accuracy: 0.6133\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6552 - accuracy: 0.6239\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6620 - accuracy: 0.6270\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6557 - accuracy: 0.6220\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6598 - accuracy: 0.6152\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6573 - accuracy: 0.6083\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6671 - accuracy: 0.6189\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6782 - accuracy: 0.5959\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6522 - accuracy: 0.6158\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6548 - accuracy: 0.6196\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6614 - accuracy: 0.6027\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6569 - accuracy: 0.6108\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6705 - accuracy: 0.6127\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6631 - accuracy: 0.6202\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6615 - accuracy: 0.6208\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6576 - accuracy: 0.6146\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6467 - accuracy: 0.6289\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6486 - accuracy: 0.6301\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6459 - accuracy: 0.6289\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6398 - accuracy: 0.6413\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6550 - accuracy: 0.6301\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.6461 - accuracy: 0.6345\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6485 - accuracy: 0.6189\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6502 - accuracy: 0.6252\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6454 - accuracy: 0.6227\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6515 - accuracy: 0.6233\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6483 - accuracy: 0.6333\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6506 - accuracy: 0.6233\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.6485 - accuracy: 0.6389\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6500 - accuracy: 0.6407\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6454 - accuracy: 0.6333\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6416 - accuracy: 0.6389\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6432 - accuracy: 0.6345\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6398 - accuracy: 0.6276\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6522 - accuracy: 0.6220\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6330 - accuracy: 0.6370\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6254 - accuracy: 0.6563\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6532 - accuracy: 0.6333\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6439 - accuracy: 0.6301\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6442 - accuracy: 0.6389\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6527 - accuracy: 0.6320\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6322 - accuracy: 0.6451\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6438 - accuracy: 0.6252\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6416 - accuracy: 0.6351\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6479 - accuracy: 0.6301\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6288 - accuracy: 0.6445\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6426 - accuracy: 0.6401\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6457 - accuracy: 0.6326\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6412 - accuracy: 0.6413\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6351 - accuracy: 0.6526\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6376 - accuracy: 0.6413\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6422 - accuracy: 0.6357\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6296 - accuracy: 0.6519\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6414 - accuracy: 0.6413\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6277 - accuracy: 0.6550\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6413 - accuracy: 0.6351\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6398 - accuracy: 0.6432\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 1s 336us/step - loss: 0.6309 - accuracy: 0.6563\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6360 - accuracy: 0.6445\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6331 - accuracy: 0.6501\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6412 - accuracy: 0.6326\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6295 - accuracy: 0.6519\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6463 - accuracy: 0.6488\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6336 - accuracy: 0.6451\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6402 - accuracy: 0.6407\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6405 - accuracy: 0.6376\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6313 - accuracy: 0.6507\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6211 - accuracy: 0.6600\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6178 - accuracy: 0.6582\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6178 - accuracy: 0.6544\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6151 - accuracy: 0.6526\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6228 - accuracy: 0.6507\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6157 - accuracy: 0.6526\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6262 - accuracy: 0.6526\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6133 - accuracy: 0.6706\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6227 - accuracy: 0.6663\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6134 - accuracy: 0.6625\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6157 - accuracy: 0.6613\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6263 - accuracy: 0.6494\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6165 - accuracy: 0.6750\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6078 - accuracy: 0.6613\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6081 - accuracy: 0.6588\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6158 - accuracy: 0.6675\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6283 - accuracy: 0.6532\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6243 - accuracy: 0.6519\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.6127 - accuracy: 0.6719\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6199 - accuracy: 0.6613\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6101 - accuracy: 0.6725\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6149 - accuracy: 0.6644\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6188 - accuracy: 0.6588\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6067 - accuracy: 0.6800\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6083 - accuracy: 0.6737\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6208 - accuracy: 0.6606\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6210 - accuracy: 0.6519\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6114 - accuracy: 0.6694\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6046 - accuracy: 0.6762\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6152 - accuracy: 0.6513\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6012 - accuracy: 0.6725\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6104 - accuracy: 0.6625\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6185 - accuracy: 0.6619\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6122 - accuracy: 0.6812\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 1s 336us/step - loss: 0.6072 - accuracy: 0.6756\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6116 - accuracy: 0.6687\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6032 - accuracy: 0.6874\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5941 - accuracy: 0.6712\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6040 - accuracy: 0.6656\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5971 - accuracy: 0.6750\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6172 - accuracy: 0.6625\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5936 - accuracy: 0.6862\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5890 - accuracy: 0.6812\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5987 - accuracy: 0.6887\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6084 - accuracy: 0.6750\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6007 - accuracy: 0.6793\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5991 - accuracy: 0.6793\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6078 - accuracy: 0.6831\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5866 - accuracy: 0.6949\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5939 - accuracy: 0.6719\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5979 - accuracy: 0.6899\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.5921 - accuracy: 0.6806\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6014 - accuracy: 0.6793\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.6028 - accuracy: 0.6787\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5902 - accuracy: 0.6899\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5960 - accuracy: 0.6756\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5925 - accuracy: 0.6961\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5926 - accuracy: 0.6818\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6001 - accuracy: 0.6731\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5888 - accuracy: 0.6824\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5930 - accuracy: 0.6806\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5881 - accuracy: 0.6961\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5893 - accuracy: 0.6843\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6030 - accuracy: 0.6737\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5858 - accuracy: 0.6824\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5849 - accuracy: 0.7036\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5903 - accuracy: 0.6831\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5744 - accuracy: 0.7117\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5838 - accuracy: 0.6887\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5831 - accuracy: 0.6905\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5903 - accuracy: 0.6849\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5871 - accuracy: 0.6880\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5827 - accuracy: 0.6999\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5903 - accuracy: 0.6961\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5672 - accuracy: 0.7055\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5671 - accuracy: 0.7111\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5695 - accuracy: 0.6986\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5709 - accuracy: 0.7024\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5872 - accuracy: 0.6843\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5810 - accuracy: 0.6862\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5901 - accuracy: 0.6912\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5671 - accuracy: 0.7117\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5721 - accuracy: 0.7042\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5832 - accuracy: 0.6999\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5709 - accuracy: 0.7223\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.5819 - accuracy: 0.6980\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5647 - accuracy: 0.7186\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5767 - accuracy: 0.7005\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5722 - accuracy: 0.7067\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5741 - accuracy: 0.7005\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5714 - accuracy: 0.7036\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5672 - accuracy: 0.7036\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5683 - accuracy: 0.6955\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5709 - accuracy: 0.6961\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5560 - accuracy: 0.6955\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5763 - accuracy: 0.6974\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5698 - accuracy: 0.6980\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5651 - accuracy: 0.7117\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.5684 - accuracy: 0.7092\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5593 - accuracy: 0.7167\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5651 - accuracy: 0.7024\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5656 - accuracy: 0.7173\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5588 - accuracy: 0.7186\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5587 - accuracy: 0.7186\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5575 - accuracy: 0.7111\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5568 - accuracy: 0.6924\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5630 - accuracy: 0.7105\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5465 - accuracy: 0.7173\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5532 - accuracy: 0.7167\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5708 - accuracy: 0.7080\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5612 - accuracy: 0.7105\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5571 - accuracy: 0.7186\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5674 - accuracy: 0.7055\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5430 - accuracy: 0.7242\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5556 - accuracy: 0.7285\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5518 - accuracy: 0.7148\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5465 - accuracy: 0.7397\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5481 - accuracy: 0.7298\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5596 - accuracy: 0.7186\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5632 - accuracy: 0.7111\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5467 - accuracy: 0.7086\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5576 - accuracy: 0.7235\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 1s 336us/step - loss: 0.5545 - accuracy: 0.7223\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5356 - accuracy: 0.7285\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5461 - accuracy: 0.7223\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5319 - accuracy: 0.7304\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5360 - accuracy: 0.7335\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5324 - accuracy: 0.7291\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5512 - accuracy: 0.7179\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5436 - accuracy: 0.7347\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5347 - accuracy: 0.7291\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5355 - accuracy: 0.7379\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5521 - accuracy: 0.7235\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5419 - accuracy: 0.7310\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5347 - accuracy: 0.7260\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5319 - accuracy: 0.7329\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.5326 - accuracy: 0.7335\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5287 - accuracy: 0.7422\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5288 - accuracy: 0.7403\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.5317 - accuracy: 0.7372\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5338 - accuracy: 0.7453\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5282 - accuracy: 0.7248\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5324 - accuracy: 0.7323\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5195 - accuracy: 0.7503\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5342 - accuracy: 0.7410\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5327 - accuracy: 0.7291\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5290 - accuracy: 0.7291\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5132 - accuracy: 0.7509\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5276 - accuracy: 0.7403\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5250 - accuracy: 0.7428\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5107 - accuracy: 0.7516\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5095 - accuracy: 0.7572\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5255 - accuracy: 0.7416\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5174 - accuracy: 0.7484\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5093 - accuracy: 0.7472\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5249 - accuracy: 0.7453\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5103 - accuracy: 0.7466\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5109 - accuracy: 0.7410\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5097 - accuracy: 0.7478\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5054 - accuracy: 0.7572\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5069 - accuracy: 0.7509\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.5100 - accuracy: 0.7478\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5044 - accuracy: 0.7553\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 1s 337us/step - loss: 0.5118 - accuracy: 0.7516\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5099 - accuracy: 0.7547\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.4986 - accuracy: 0.7503\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.4994 - accuracy: 0.7553\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5006 - accuracy: 0.7634\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 1s 336us/step - loss: 0.5003 - accuracy: 0.7553\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.4830 - accuracy: 0.7659\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5070 - accuracy: 0.7460\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.4903 - accuracy: 0.7590\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.4931 - accuracy: 0.7727\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.4828 - accuracy: 0.7721\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5050 - accuracy: 0.7534\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.4946 - accuracy: 0.7565\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.4871 - accuracy: 0.7609\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 1s 338us/step - loss: 0.4871 - accuracy: 0.7765\n",
      "準確率 : 0.7039800995024875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.8445 - accuracy: 0.4981\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7830 - accuracy: 0.5405\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7543 - accuracy: 0.5311\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7292 - accuracy: 0.5585\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7357 - accuracy: 0.5511\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7168 - accuracy: 0.5629\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.7152 - accuracy: 0.5604\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6999 - accuracy: 0.5778\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7132 - accuracy: 0.5641\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7083 - accuracy: 0.5772\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7195 - accuracy: 0.5349\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7020 - accuracy: 0.5616\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7019 - accuracy: 0.5760\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6958 - accuracy: 0.5809\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6946 - accuracy: 0.5766\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6937 - accuracy: 0.5760\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6816 - accuracy: 0.5903\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7069 - accuracy: 0.5542\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6941 - accuracy: 0.5629\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6758 - accuracy: 0.5953\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6890 - accuracy: 0.5934\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6883 - accuracy: 0.5741\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6817 - accuracy: 0.5903\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6794 - accuracy: 0.5897\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6822 - accuracy: 0.5922\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7030 - accuracy: 0.5710\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6875 - accuracy: 0.5847\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6916 - accuracy: 0.5934\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6866 - accuracy: 0.5971\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6843 - accuracy: 0.5915\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6903 - accuracy: 0.5729\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6789 - accuracy: 0.5922\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6775 - accuracy: 0.6021\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6928 - accuracy: 0.5797\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6747 - accuracy: 0.6015\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6754 - accuracy: 0.5853\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6803 - accuracy: 0.6059\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6832 - accuracy: 0.5897\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6783 - accuracy: 0.6009\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6797 - accuracy: 0.6115\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6705 - accuracy: 0.6158\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6660 - accuracy: 0.6158\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6793 - accuracy: 0.5922\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6731 - accuracy: 0.6009\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6719 - accuracy: 0.5859\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6791 - accuracy: 0.6065\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6720 - accuracy: 0.5953\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.6726 - accuracy: 0.5959\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6678 - accuracy: 0.6034\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6694 - accuracy: 0.6164\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6672 - accuracy: 0.6021\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6615 - accuracy: 0.6214\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6610 - accuracy: 0.6177\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6628 - accuracy: 0.6233\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6617 - accuracy: 0.6152\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6561 - accuracy: 0.6264\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6691 - accuracy: 0.6220\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6661 - accuracy: 0.6096\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6534 - accuracy: 0.6077\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6647 - accuracy: 0.6090\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6628 - accuracy: 0.6270\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6525 - accuracy: 0.6301\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6657 - accuracy: 0.6202\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6556 - accuracy: 0.6158\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6443 - accuracy: 0.6276\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6592 - accuracy: 0.6245\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6560 - accuracy: 0.6121\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6522 - accuracy: 0.6401\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6515 - accuracy: 0.6202\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6561 - accuracy: 0.6189\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6587 - accuracy: 0.6301\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6452 - accuracy: 0.6320\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6618 - accuracy: 0.6258\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6544 - accuracy: 0.6364\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6625 - accuracy: 0.6102\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6496 - accuracy: 0.6301\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6531 - accuracy: 0.6233\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6481 - accuracy: 0.6326\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6560 - accuracy: 0.6227\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6487 - accuracy: 0.6283\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6603 - accuracy: 0.6289\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6421 - accuracy: 0.6320\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6503 - accuracy: 0.6308\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6444 - accuracy: 0.6326\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6449 - accuracy: 0.6283\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6434 - accuracy: 0.6289\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6652 - accuracy: 0.6276\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6484 - accuracy: 0.6295\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6441 - accuracy: 0.6389\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6451 - accuracy: 0.6326\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6406 - accuracy: 0.6357\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6480 - accuracy: 0.6276\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6388 - accuracy: 0.6407\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6406 - accuracy: 0.6252\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6338 - accuracy: 0.6463\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6439 - accuracy: 0.6420\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6324 - accuracy: 0.6469\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6515 - accuracy: 0.6264\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6430 - accuracy: 0.6395\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6468 - accuracy: 0.6395\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6500 - accuracy: 0.6208\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6380 - accuracy: 0.6401\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6303 - accuracy: 0.6476\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6412 - accuracy: 0.6283\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6343 - accuracy: 0.6494\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6336 - accuracy: 0.6339\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6482 - accuracy: 0.6295\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6142 - accuracy: 0.6737\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6277 - accuracy: 0.6569\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6372 - accuracy: 0.6326\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6407 - accuracy: 0.6295\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6360 - accuracy: 0.6507\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6353 - accuracy: 0.6476\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6393 - accuracy: 0.6382\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6265 - accuracy: 0.6426\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6356 - accuracy: 0.6351\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6445 - accuracy: 0.6407\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6213 - accuracy: 0.6594\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6390 - accuracy: 0.6382\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6397 - accuracy: 0.6389\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6192 - accuracy: 0.6600\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6318 - accuracy: 0.6389\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6332 - accuracy: 0.6457\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6280 - accuracy: 0.6438\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6272 - accuracy: 0.6519\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.6284 - accuracy: 0.6557\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6199 - accuracy: 0.6712\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6229 - accuracy: 0.6557\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6216 - accuracy: 0.6706\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6190 - accuracy: 0.6631\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6412 - accuracy: 0.6395\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6235 - accuracy: 0.6501\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6279 - accuracy: 0.6463\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6113 - accuracy: 0.6613\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6294 - accuracy: 0.6594\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6137 - accuracy: 0.6650\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5966 - accuracy: 0.6775\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6197 - accuracy: 0.6575\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6134 - accuracy: 0.6606\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6178 - accuracy: 0.6706\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6187 - accuracy: 0.6600\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6114 - accuracy: 0.6856\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6219 - accuracy: 0.6513\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6160 - accuracy: 0.6650\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6135 - accuracy: 0.6762\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6053 - accuracy: 0.6625\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6070 - accuracy: 0.6700\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6197 - accuracy: 0.6700\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6150 - accuracy: 0.6706\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6189 - accuracy: 0.6544\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6049 - accuracy: 0.6781\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6019 - accuracy: 0.6750\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6092 - accuracy: 0.6650\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6027 - accuracy: 0.6700\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6058 - accuracy: 0.6582\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5938 - accuracy: 0.6725\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6142 - accuracy: 0.6663\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6027 - accuracy: 0.6681\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6065 - accuracy: 0.6687\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6062 - accuracy: 0.6656\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6118 - accuracy: 0.6613\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6120 - accuracy: 0.6588\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6210 - accuracy: 0.6582\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5960 - accuracy: 0.6831\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6070 - accuracy: 0.6594\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6002 - accuracy: 0.6800\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5977 - accuracy: 0.6818\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6030 - accuracy: 0.6831\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5858 - accuracy: 0.6924\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5946 - accuracy: 0.6750\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5998 - accuracy: 0.6924\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5951 - accuracy: 0.6800\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6014 - accuracy: 0.6712\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6012 - accuracy: 0.6719\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5890 - accuracy: 0.6800\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5904 - accuracy: 0.6824\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5967 - accuracy: 0.6880\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5999 - accuracy: 0.6743\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5844 - accuracy: 0.6899\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5834 - accuracy: 0.7005\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6032 - accuracy: 0.6706\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5937 - accuracy: 0.6936\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5854 - accuracy: 0.6999\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5819 - accuracy: 0.6980\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5994 - accuracy: 0.6831\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5934 - accuracy: 0.6893\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5847 - accuracy: 0.6849\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5823 - accuracy: 0.6936\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5814 - accuracy: 0.7086\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5815 - accuracy: 0.6955\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.5881 - accuracy: 0.6930\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5796 - accuracy: 0.6831\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5860 - accuracy: 0.6793\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5847 - accuracy: 0.6868\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5907 - accuracy: 0.6831\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5722 - accuracy: 0.6974\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5806 - accuracy: 0.7055\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5928 - accuracy: 0.6918\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5823 - accuracy: 0.6980\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5821 - accuracy: 0.6999\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5849 - accuracy: 0.6924\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5745 - accuracy: 0.6999\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5698 - accuracy: 0.7024\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5897 - accuracy: 0.6800\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5827 - accuracy: 0.6955\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5918 - accuracy: 0.6893\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5675 - accuracy: 0.6974\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5877 - accuracy: 0.6824\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5744 - accuracy: 0.7105\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5752 - accuracy: 0.7049\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5726 - accuracy: 0.7011\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5804 - accuracy: 0.6955\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5638 - accuracy: 0.7173\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5627 - accuracy: 0.7186\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5665 - accuracy: 0.6993\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5748 - accuracy: 0.7011\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.5672 - accuracy: 0.7005\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5754 - accuracy: 0.6899\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5593 - accuracy: 0.7055\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5607 - accuracy: 0.7098\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5671 - accuracy: 0.6974\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5616 - accuracy: 0.7055\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5517 - accuracy: 0.7273\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5587 - accuracy: 0.7223\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5604 - accuracy: 0.7086\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5678 - accuracy: 0.7005\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5735 - accuracy: 0.7130\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5551 - accuracy: 0.7229\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5674 - accuracy: 0.7173\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5661 - accuracy: 0.7049\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5632 - accuracy: 0.7092\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5533 - accuracy: 0.7136\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5504 - accuracy: 0.7242\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5487 - accuracy: 0.7223\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5609 - accuracy: 0.7092\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5622 - accuracy: 0.7105\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5613 - accuracy: 0.7210\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5532 - accuracy: 0.7329\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5495 - accuracy: 0.7080\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5549 - accuracy: 0.7248\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.5674 - accuracy: 0.7154\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5494 - accuracy: 0.7186\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5464 - accuracy: 0.7273\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5499 - accuracy: 0.7198\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5420 - accuracy: 0.7291\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5536 - accuracy: 0.7198\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5575 - accuracy: 0.7260\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5575 - accuracy: 0.7086\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5445 - accuracy: 0.7179\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5621 - accuracy: 0.7055\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5343 - accuracy: 0.7316\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5489 - accuracy: 0.7354\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5545 - accuracy: 0.7117\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5451 - accuracy: 0.7210\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5479 - accuracy: 0.7279\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5443 - accuracy: 0.7117\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5308 - accuracy: 0.7298\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5359 - accuracy: 0.7242\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5502 - accuracy: 0.7267\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5396 - accuracy: 0.7260\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5337 - accuracy: 0.7435\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5397 - accuracy: 0.7229\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5276 - accuracy: 0.7279\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5310 - accuracy: 0.7379\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5225 - accuracy: 0.7372\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5444 - accuracy: 0.7254\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5495 - accuracy: 0.7204\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5251 - accuracy: 0.7416\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5314 - accuracy: 0.7204\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5265 - accuracy: 0.7329\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5262 - accuracy: 0.7372\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.5502 - accuracy: 0.7192\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5361 - accuracy: 0.7273\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5297 - accuracy: 0.7410\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5183 - accuracy: 0.7447\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5272 - accuracy: 0.7360\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5223 - accuracy: 0.7428\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5210 - accuracy: 0.7453\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5295 - accuracy: 0.7304\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5125 - accuracy: 0.7416\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5179 - accuracy: 0.7590\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5252 - accuracy: 0.7316\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5146 - accuracy: 0.7441\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5134 - accuracy: 0.7397\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5169 - accuracy: 0.7422\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5295 - accuracy: 0.7341\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5094 - accuracy: 0.7572\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5244 - accuracy: 0.7522\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5145 - accuracy: 0.7503\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5158 - accuracy: 0.7516\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5059 - accuracy: 0.7621\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5153 - accuracy: 0.7540\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5095 - accuracy: 0.7584\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.4913 - accuracy: 0.7646\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5067 - accuracy: 0.7522\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5059 - accuracy: 0.7491\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5099 - accuracy: 0.7522\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5140 - accuracy: 0.7478\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.4892 - accuracy: 0.7628\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5146 - accuracy: 0.7528\n",
      "準確率 : 0.6890547263681592\n",
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.8387 - accuracy: 0.5187\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7654 - accuracy: 0.5442\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7590 - accuracy: 0.5467\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7337 - accuracy: 0.5430\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7272 - accuracy: 0.5654\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7303 - accuracy: 0.5567\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.7173 - accuracy: 0.5573\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7079 - accuracy: 0.5753\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7136 - accuracy: 0.5778\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7197 - accuracy: 0.5529\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.7080 - accuracy: 0.5772\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6966 - accuracy: 0.5747\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7006 - accuracy: 0.5747\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6986 - accuracy: 0.5710\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.7063 - accuracy: 0.5697\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6999 - accuracy: 0.5828\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6998 - accuracy: 0.5760\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6917 - accuracy: 0.5716\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6858 - accuracy: 0.5866\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7007 - accuracy: 0.5766\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6758 - accuracy: 0.6027\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6864 - accuracy: 0.5909\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6851 - accuracy: 0.5953\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6976 - accuracy: 0.5772\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6777 - accuracy: 0.5909\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6960 - accuracy: 0.5785\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6879 - accuracy: 0.5834\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6824 - accuracy: 0.5897\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6875 - accuracy: 0.5816\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6753 - accuracy: 0.6127\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6812 - accuracy: 0.5996\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6787 - accuracy: 0.5946\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6695 - accuracy: 0.6052\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6890 - accuracy: 0.5859\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6748 - accuracy: 0.6015\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6748 - accuracy: 0.6002\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6798 - accuracy: 0.5940\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6725 - accuracy: 0.6252\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6768 - accuracy: 0.6065\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6768 - accuracy: 0.6096\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6867 - accuracy: 0.5928\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6782 - accuracy: 0.6077\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6719 - accuracy: 0.6034\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6826 - accuracy: 0.5940\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6690 - accuracy: 0.5946\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6801 - accuracy: 0.5984\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6807 - accuracy: 0.5990\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6737 - accuracy: 0.5959\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.6677 - accuracy: 0.6052\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6653 - accuracy: 0.5984\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6650 - accuracy: 0.6115\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6648 - accuracy: 0.6077\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6634 - accuracy: 0.6146\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6589 - accuracy: 0.6127\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6680 - accuracy: 0.6139\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6608 - accuracy: 0.6264\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6598 - accuracy: 0.6083\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6575 - accuracy: 0.6090\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6731 - accuracy: 0.5946\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6596 - accuracy: 0.6127\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6616 - accuracy: 0.6096\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6765 - accuracy: 0.6040\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6668 - accuracy: 0.6052\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6599 - accuracy: 0.6220\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6596 - accuracy: 0.6208\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6640 - accuracy: 0.6245\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6631 - accuracy: 0.6034\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6593 - accuracy: 0.6121\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6720 - accuracy: 0.6040\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6617 - accuracy: 0.6127\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6543 - accuracy: 0.6115\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6524 - accuracy: 0.6289\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6588 - accuracy: 0.6108\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6619 - accuracy: 0.6171\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6506 - accuracy: 0.6283\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6594 - accuracy: 0.6270\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6510 - accuracy: 0.6233\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6422 - accuracy: 0.6339\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6612 - accuracy: 0.6214\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6637 - accuracy: 0.6158\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6541 - accuracy: 0.6301\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6646 - accuracy: 0.6177\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6516 - accuracy: 0.6258\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6579 - accuracy: 0.6127\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6469 - accuracy: 0.6345\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6573 - accuracy: 0.6183\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6424 - accuracy: 0.6333\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6691 - accuracy: 0.6077\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6520 - accuracy: 0.6351\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6507 - accuracy: 0.6283\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6468 - accuracy: 0.6438\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6262 - accuracy: 0.6432\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6529 - accuracy: 0.6345\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6385 - accuracy: 0.6476\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6416 - accuracy: 0.6326\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6429 - accuracy: 0.6376\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6394 - accuracy: 0.6420\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6271 - accuracy: 0.6469\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6345 - accuracy: 0.6413\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6474 - accuracy: 0.6295\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6501 - accuracy: 0.6264\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6348 - accuracy: 0.6463\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6596 - accuracy: 0.6108\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6353 - accuracy: 0.6301\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6424 - accuracy: 0.6382\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6503 - accuracy: 0.6301\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6311 - accuracy: 0.6482\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6389 - accuracy: 0.6420\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6368 - accuracy: 0.6326\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6416 - accuracy: 0.6401\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6433 - accuracy: 0.6351\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6304 - accuracy: 0.6563\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6331 - accuracy: 0.6488\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6426 - accuracy: 0.6364\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6352 - accuracy: 0.6382\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6448 - accuracy: 0.6333\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6325 - accuracy: 0.6432\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6254 - accuracy: 0.6482\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6310 - accuracy: 0.6519\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6324 - accuracy: 0.6482\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6295 - accuracy: 0.6457\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6344 - accuracy: 0.6357\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6258 - accuracy: 0.6407\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6256 - accuracy: 0.6532\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6210 - accuracy: 0.6613\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6199 - accuracy: 0.6550\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6218 - accuracy: 0.6513\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6305 - accuracy: 0.6538\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6281 - accuracy: 0.6445\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6363 - accuracy: 0.6432\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6191 - accuracy: 0.6438\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6256 - accuracy: 0.6557\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6150 - accuracy: 0.6719\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.6244 - accuracy: 0.6426\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6266 - accuracy: 0.6544\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6114 - accuracy: 0.6669\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6174 - accuracy: 0.6638\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6200 - accuracy: 0.6644\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6144 - accuracy: 0.6426\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6195 - accuracy: 0.6438\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6237 - accuracy: 0.6575\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6027 - accuracy: 0.6781\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6110 - accuracy: 0.6613\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6200 - accuracy: 0.6656\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6113 - accuracy: 0.6625\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6185 - accuracy: 0.6538\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6077 - accuracy: 0.6743\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6161 - accuracy: 0.6650\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5961 - accuracy: 0.6731\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6092 - accuracy: 0.6712\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6108 - accuracy: 0.6712\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5989 - accuracy: 0.6806\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6091 - accuracy: 0.6743\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6169 - accuracy: 0.6656\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6112 - accuracy: 0.6762\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6071 - accuracy: 0.6793\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6099 - accuracy: 0.6712\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5966 - accuracy: 0.6793\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6171 - accuracy: 0.6507\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6091 - accuracy: 0.6544\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5966 - accuracy: 0.6743\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6060 - accuracy: 0.6694\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6088 - accuracy: 0.6687\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6092 - accuracy: 0.6650\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6131 - accuracy: 0.6569\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6033 - accuracy: 0.6762\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6008 - accuracy: 0.6768\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5975 - accuracy: 0.6656\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6100 - accuracy: 0.6625\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6172 - accuracy: 0.6507\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6003 - accuracy: 0.6737\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6069 - accuracy: 0.6743\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5978 - accuracy: 0.6737\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5926 - accuracy: 0.6856\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6003 - accuracy: 0.6781\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5980 - accuracy: 0.6750\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5982 - accuracy: 0.6856\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5889 - accuracy: 0.6986\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5915 - accuracy: 0.6831\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6045 - accuracy: 0.6675\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.5898 - accuracy: 0.6949\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5943 - accuracy: 0.6750\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5943 - accuracy: 0.6912\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6045 - accuracy: 0.6675\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5876 - accuracy: 0.6918\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.5927 - accuracy: 0.6743\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5869 - accuracy: 0.6868\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6071 - accuracy: 0.6731\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5978 - accuracy: 0.6719\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5899 - accuracy: 0.6918\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5919 - accuracy: 0.6800\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5795 - accuracy: 0.6868\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5954 - accuracy: 0.6775\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5812 - accuracy: 0.6862\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5918 - accuracy: 0.6843\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5770 - accuracy: 0.7024\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5800 - accuracy: 0.6980\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5830 - accuracy: 0.6899\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5634 - accuracy: 0.7061\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5757 - accuracy: 0.7024\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5821 - accuracy: 0.6912\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5789 - accuracy: 0.7030\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5768 - accuracy: 0.6961\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5750 - accuracy: 0.6955\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5804 - accuracy: 0.6843\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5865 - accuracy: 0.6824\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5723 - accuracy: 0.6955\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5682 - accuracy: 0.6980\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5765 - accuracy: 0.6955\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5663 - accuracy: 0.6943\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5737 - accuracy: 0.6880\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5638 - accuracy: 0.6980\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5595 - accuracy: 0.7042\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5794 - accuracy: 0.7111\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5734 - accuracy: 0.6918\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5844 - accuracy: 0.6912\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5571 - accuracy: 0.7210\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5627 - accuracy: 0.7030\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5710 - accuracy: 0.7067\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5743 - accuracy: 0.6980\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5712 - accuracy: 0.6974\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5722 - accuracy: 0.7042\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5581 - accuracy: 0.7229\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5540 - accuracy: 0.7173\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5575 - accuracy: 0.7098\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5703 - accuracy: 0.6949\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5636 - accuracy: 0.7123\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5608 - accuracy: 0.7223\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5587 - accuracy: 0.7111\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5509 - accuracy: 0.7167\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5715 - accuracy: 0.6955\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5673 - accuracy: 0.7154\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5469 - accuracy: 0.7229\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5660 - accuracy: 0.7073\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5503 - accuracy: 0.7210\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5619 - accuracy: 0.7136\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5559 - accuracy: 0.7161\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5592 - accuracy: 0.7186\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5494 - accuracy: 0.7242\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5519 - accuracy: 0.7173\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5521 - accuracy: 0.7167\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5491 - accuracy: 0.7167\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5581 - accuracy: 0.7111\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5502 - accuracy: 0.7142\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5451 - accuracy: 0.7279\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5419 - accuracy: 0.7254\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5484 - accuracy: 0.7316\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5499 - accuracy: 0.7148\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5473 - accuracy: 0.7323\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5476 - accuracy: 0.7267\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5418 - accuracy: 0.7235\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5394 - accuracy: 0.7148\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5442 - accuracy: 0.7210\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5299 - accuracy: 0.7391\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5367 - accuracy: 0.7316\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5409 - accuracy: 0.7204\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5525 - accuracy: 0.7329\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5488 - accuracy: 0.7273\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5250 - accuracy: 0.7466\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5476 - accuracy: 0.7136\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5461 - accuracy: 0.7260\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5342 - accuracy: 0.7360\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5470 - accuracy: 0.7335\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5353 - accuracy: 0.7372\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5313 - accuracy: 0.7366\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5282 - accuracy: 0.7372\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5232 - accuracy: 0.7416\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5448 - accuracy: 0.7267\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5243 - accuracy: 0.7397\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5280 - accuracy: 0.7360\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5332 - accuracy: 0.7391\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5168 - accuracy: 0.7391\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5217 - accuracy: 0.7460\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5174 - accuracy: 0.7323\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5127 - accuracy: 0.7460\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5184 - accuracy: 0.7422\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5241 - accuracy: 0.7341\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5184 - accuracy: 0.7416\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5266 - accuracy: 0.7466\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5236 - accuracy: 0.7484\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5188 - accuracy: 0.7435\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.5169 - accuracy: 0.7497\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5214 - accuracy: 0.7441\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5170 - accuracy: 0.7435\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5064 - accuracy: 0.7509\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5059 - accuracy: 0.7578\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5204 - accuracy: 0.7503\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5179 - accuracy: 0.7422\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5004 - accuracy: 0.7565\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5121 - accuracy: 0.7372\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5072 - accuracy: 0.7447\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5074 - accuracy: 0.7553\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.4978 - accuracy: 0.7640\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.4969 - accuracy: 0.7584\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.4985 - accuracy: 0.7522\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5073 - accuracy: 0.7578\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.4911 - accuracy: 0.7721\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.4996 - accuracy: 0.7659\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.4904 - accuracy: 0.7684\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5015 - accuracy: 0.7615\n",
      "準確率 : 0.6940298507462687\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.8192 - accuracy: 0.5293\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.7645 - accuracy: 0.5697\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7364 - accuracy: 0.5672\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7270 - accuracy: 0.5741\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7310 - accuracy: 0.5760\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6886 - accuracy: 0.6083\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6946 - accuracy: 0.5884\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.7016 - accuracy: 0.5859\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7031 - accuracy: 0.5890\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7041 - accuracy: 0.5778\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7206 - accuracy: 0.5666\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6988 - accuracy: 0.5766\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6972 - accuracy: 0.5803\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6890 - accuracy: 0.5990\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6941 - accuracy: 0.5953\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6894 - accuracy: 0.5928\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7028 - accuracy: 0.5710\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6807 - accuracy: 0.5940\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6983 - accuracy: 0.6077\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6880 - accuracy: 0.5841\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6799 - accuracy: 0.6021\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6898 - accuracy: 0.5679\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6947 - accuracy: 0.5922\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6865 - accuracy: 0.5884\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6960 - accuracy: 0.5866\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6751 - accuracy: 0.6071\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6770 - accuracy: 0.5990\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6770 - accuracy: 0.5934\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6739 - accuracy: 0.6102\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6804 - accuracy: 0.6034\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6824 - accuracy: 0.6083\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6853 - accuracy: 0.5996\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6816 - accuracy: 0.6021\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6837 - accuracy: 0.5853\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6780 - accuracy: 0.5940\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6720 - accuracy: 0.5946\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6733 - accuracy: 0.6189\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6702 - accuracy: 0.6102\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6662 - accuracy: 0.6102\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6848 - accuracy: 0.6059\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6724 - accuracy: 0.6133\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6563 - accuracy: 0.6139\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6672 - accuracy: 0.6102\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.6666 - accuracy: 0.6108\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6718 - accuracy: 0.5996\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6646 - accuracy: 0.6096\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6557 - accuracy: 0.6202\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6834 - accuracy: 0.5990\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6679 - accuracy: 0.6146\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 1s 350us/step - loss: 0.6711 - accuracy: 0.6021\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.6592 - accuracy: 0.6189\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6722 - accuracy: 0.6183\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6605 - accuracy: 0.6108\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6669 - accuracy: 0.6139\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6591 - accuracy: 0.6139\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6681 - accuracy: 0.6096\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.6515 - accuracy: 0.6308\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6648 - accuracy: 0.6196\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6691 - accuracy: 0.6027\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6696 - accuracy: 0.6077\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6794 - accuracy: 0.6090\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6651 - accuracy: 0.6071\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6604 - accuracy: 0.6158\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.6569 - accuracy: 0.6227\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6578 - accuracy: 0.6245\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6522 - accuracy: 0.6333\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6600 - accuracy: 0.6208\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6745 - accuracy: 0.6077\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6592 - accuracy: 0.6009\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6678 - accuracy: 0.6227\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6521 - accuracy: 0.6264\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6524 - accuracy: 0.6258\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6643 - accuracy: 0.6152\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6493 - accuracy: 0.6183\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6444 - accuracy: 0.6258\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6434 - accuracy: 0.6326\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6437 - accuracy: 0.6252\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6517 - accuracy: 0.6314\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6600 - accuracy: 0.6208\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6509 - accuracy: 0.6407\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6537 - accuracy: 0.6208\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6607 - accuracy: 0.6208\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6564 - accuracy: 0.6164\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6513 - accuracy: 0.6289\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6612 - accuracy: 0.6158\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6556 - accuracy: 0.6146\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6424 - accuracy: 0.6364\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6458 - accuracy: 0.6426\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6410 - accuracy: 0.6364\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6479 - accuracy: 0.6289\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6354 - accuracy: 0.6420\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6521 - accuracy: 0.6320\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6494 - accuracy: 0.6389\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6409 - accuracy: 0.6295\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6469 - accuracy: 0.6382\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6446 - accuracy: 0.6395\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6516 - accuracy: 0.6139\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6394 - accuracy: 0.6376\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6452 - accuracy: 0.6320\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6337 - accuracy: 0.6326\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6398 - accuracy: 0.6401\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6367 - accuracy: 0.6451\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6446 - accuracy: 0.6289\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6382 - accuracy: 0.6451\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6372 - accuracy: 0.6351\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6301 - accuracy: 0.6557\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6350 - accuracy: 0.6526\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6339 - accuracy: 0.6494\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6364 - accuracy: 0.6488\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6358 - accuracy: 0.6582\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6373 - accuracy: 0.6395\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6362 - accuracy: 0.6432\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6394 - accuracy: 0.6370\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6336 - accuracy: 0.6532\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6264 - accuracy: 0.6625\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6190 - accuracy: 0.6557\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6364 - accuracy: 0.6463\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6365 - accuracy: 0.6426\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6167 - accuracy: 0.6582\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6375 - accuracy: 0.6426\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6217 - accuracy: 0.6494\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6277 - accuracy: 0.6513\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6265 - accuracy: 0.6501\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6402 - accuracy: 0.6420\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6236 - accuracy: 0.6550\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6275 - accuracy: 0.6532\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6309 - accuracy: 0.6451\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6288 - accuracy: 0.6351\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6235 - accuracy: 0.6625\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 1s 350us/step - loss: 0.6163 - accuracy: 0.6582\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6257 - accuracy: 0.6526\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6291 - accuracy: 0.6557\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6206 - accuracy: 0.6507\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6323 - accuracy: 0.6488\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6259 - accuracy: 0.6550\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6273 - accuracy: 0.6638\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6284 - accuracy: 0.6513\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6231 - accuracy: 0.6619\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6211 - accuracy: 0.6638\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6224 - accuracy: 0.6519\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6226 - accuracy: 0.6687\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6216 - accuracy: 0.6588\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6167 - accuracy: 0.6582\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6139 - accuracy: 0.6719\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6107 - accuracy: 0.6719\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6162 - accuracy: 0.6544\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6174 - accuracy: 0.6538\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6180 - accuracy: 0.6638\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6202 - accuracy: 0.6631\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6188 - accuracy: 0.6656\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6134 - accuracy: 0.6588\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6162 - accuracy: 0.6619\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6160 - accuracy: 0.6488\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6185 - accuracy: 0.6594\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6150 - accuracy: 0.6494\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6148 - accuracy: 0.6663\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6045 - accuracy: 0.6837\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6081 - accuracy: 0.6706\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6065 - accuracy: 0.6575\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5981 - accuracy: 0.6812\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6069 - accuracy: 0.6737\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 1s 349us/step - loss: 0.6015 - accuracy: 0.6787\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6033 - accuracy: 0.6781\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 1s 350us/step - loss: 0.6088 - accuracy: 0.6656\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6057 - accuracy: 0.6663\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6039 - accuracy: 0.6737\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6120 - accuracy: 0.6743\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6008 - accuracy: 0.6806\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5965 - accuracy: 0.6750\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5923 - accuracy: 0.6818\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6042 - accuracy: 0.6681\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6096 - accuracy: 0.6494\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6064 - accuracy: 0.6687\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6037 - accuracy: 0.6700\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6067 - accuracy: 0.6768\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5972 - accuracy: 0.6687\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.5927 - accuracy: 0.6924\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6054 - accuracy: 0.6787\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5875 - accuracy: 0.6837\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6036 - accuracy: 0.6768\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6007 - accuracy: 0.6775\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5928 - accuracy: 0.6818\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5950 - accuracy: 0.6874\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5919 - accuracy: 0.6694\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5991 - accuracy: 0.6787\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5832 - accuracy: 0.6968\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.5914 - accuracy: 0.6824\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5959 - accuracy: 0.6762\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5842 - accuracy: 0.6874\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5891 - accuracy: 0.6899\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5854 - accuracy: 0.6893\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5985 - accuracy: 0.6675\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5873 - accuracy: 0.6986\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5918 - accuracy: 0.6743\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5901 - accuracy: 0.6806\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5817 - accuracy: 0.6893\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5705 - accuracy: 0.7111\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5893 - accuracy: 0.6918\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5848 - accuracy: 0.6936\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5867 - accuracy: 0.6787\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.5859 - accuracy: 0.6806\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.5870 - accuracy: 0.6843\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5672 - accuracy: 0.7167\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5801 - accuracy: 0.6843\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5744 - accuracy: 0.7080\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5754 - accuracy: 0.7049\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5829 - accuracy: 0.6993\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5755 - accuracy: 0.7080\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.5807 - accuracy: 0.7105\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.5826 - accuracy: 0.6999\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5870 - accuracy: 0.6949\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5706 - accuracy: 0.6974\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.5812 - accuracy: 0.6887\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5664 - accuracy: 0.7024\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.5772 - accuracy: 0.6993\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5616 - accuracy: 0.7192\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5670 - accuracy: 0.6961\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5644 - accuracy: 0.7055\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5723 - accuracy: 0.7055\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5703 - accuracy: 0.7179\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5712 - accuracy: 0.7080\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.5705 - accuracy: 0.7080\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5701 - accuracy: 0.6986\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5746 - accuracy: 0.6912\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5620 - accuracy: 0.7105\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5646 - accuracy: 0.7067\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5668 - accuracy: 0.7117\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5691 - accuracy: 0.7086\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.5764 - accuracy: 0.7067\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.5682 - accuracy: 0.7042\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.5749 - accuracy: 0.6986\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5733 - accuracy: 0.6899\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5694 - accuracy: 0.6974\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.5696 - accuracy: 0.7111\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5639 - accuracy: 0.7117\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5627 - accuracy: 0.6993\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5671 - accuracy: 0.7080\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5669 - accuracy: 0.7030\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.5733 - accuracy: 0.6968\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5510 - accuracy: 0.7298\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5700 - accuracy: 0.7073\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.5540 - accuracy: 0.7173\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5551 - accuracy: 0.7267\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.5578 - accuracy: 0.7186\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.5598 - accuracy: 0.7217\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5517 - accuracy: 0.7042\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5523 - accuracy: 0.7111\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5629 - accuracy: 0.7092\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5523 - accuracy: 0.7105\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5560 - accuracy: 0.7204\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5446 - accuracy: 0.7291\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5397 - accuracy: 0.7329\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5429 - accuracy: 0.7242\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 1s 365us/step - loss: 0.5555 - accuracy: 0.7192\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5512 - accuracy: 0.7323\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5478 - accuracy: 0.7254\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5505 - accuracy: 0.7335\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.5541 - accuracy: 0.7260\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5506 - accuracy: 0.7229\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5408 - accuracy: 0.7285\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5546 - accuracy: 0.7142\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5416 - accuracy: 0.7229\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5601 - accuracy: 0.7086\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5441 - accuracy: 0.7273\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5533 - accuracy: 0.7117\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5517 - accuracy: 0.7123\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5333 - accuracy: 0.7354\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5428 - accuracy: 0.7285\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5502 - accuracy: 0.7067\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5378 - accuracy: 0.7298\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5497 - accuracy: 0.7223\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5448 - accuracy: 0.7329\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5397 - accuracy: 0.7335\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5433 - accuracy: 0.7223\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5367 - accuracy: 0.7260\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5425 - accuracy: 0.7323\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5379 - accuracy: 0.7335\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.5392 - accuracy: 0.7316\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.5322 - accuracy: 0.7354\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5280 - accuracy: 0.7516\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5344 - accuracy: 0.7304\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5357 - accuracy: 0.7441\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5376 - accuracy: 0.7316\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.5259 - accuracy: 0.7522\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5267 - accuracy: 0.7441\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.5281 - accuracy: 0.7410\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.5458 - accuracy: 0.7285\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5211 - accuracy: 0.7428\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5384 - accuracy: 0.7291\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5289 - accuracy: 0.7366\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.5358 - accuracy: 0.7316\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5315 - accuracy: 0.7416\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5282 - accuracy: 0.7347\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5366 - accuracy: 0.7310\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5344 - accuracy: 0.7323\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5342 - accuracy: 0.7403\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5397 - accuracy: 0.7329\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5265 - accuracy: 0.7391\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5316 - accuracy: 0.7279\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5177 - accuracy: 0.7428\n",
      "準確率 : 0.6716417910447762\n",
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.7894 - accuracy: 0.5442\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.7546 - accuracy: 0.5492\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.7317 - accuracy: 0.5772\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.7277 - accuracy: 0.5816\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.7230 - accuracy: 0.5648\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.7176 - accuracy: 0.5679\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.7111 - accuracy: 0.5685\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6948 - accuracy: 0.5928\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6877 - accuracy: 0.5915\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.7054 - accuracy: 0.5785\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6864 - accuracy: 0.5915\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6958 - accuracy: 0.5866\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6943 - accuracy: 0.6015\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.7001 - accuracy: 0.5853\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6757 - accuracy: 0.6046\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6883 - accuracy: 0.5903\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6899 - accuracy: 0.5897\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6831 - accuracy: 0.6021\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.6826 - accuracy: 0.5978\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6969 - accuracy: 0.5760\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6797 - accuracy: 0.5978\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.7006 - accuracy: 0.5890\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6841 - accuracy: 0.5897\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6862 - accuracy: 0.5884\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6981 - accuracy: 0.5697\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6765 - accuracy: 0.6071\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 1s 368us/step - loss: 0.6822 - accuracy: 0.5922\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6810 - accuracy: 0.6052\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6744 - accuracy: 0.6034\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6718 - accuracy: 0.6077\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6719 - accuracy: 0.6046\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 1s 350us/step - loss: 0.6614 - accuracy: 0.6059\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6600 - accuracy: 0.6164\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6610 - accuracy: 0.6208\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6658 - accuracy: 0.6108\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6712 - accuracy: 0.6077\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6797 - accuracy: 0.5984\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6712 - accuracy: 0.6059\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6741 - accuracy: 0.6071\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6703 - accuracy: 0.6046\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6704 - accuracy: 0.6009\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6728 - accuracy: 0.6152\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6737 - accuracy: 0.6127\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6645 - accuracy: 0.5965\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6712 - accuracy: 0.6115\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6682 - accuracy: 0.6121\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6652 - accuracy: 0.6202\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6660 - accuracy: 0.6127\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6595 - accuracy: 0.6264\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6617 - accuracy: 0.6121\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6668 - accuracy: 0.6027\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6735 - accuracy: 0.6252\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6654 - accuracy: 0.6108\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6582 - accuracy: 0.6183\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6467 - accuracy: 0.6295\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6592 - accuracy: 0.6108\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6596 - accuracy: 0.6208\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6539 - accuracy: 0.6276\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6577 - accuracy: 0.6227\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6646 - accuracy: 0.6183\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6568 - accuracy: 0.6183\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6567 - accuracy: 0.6245\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6534 - accuracy: 0.6196\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6531 - accuracy: 0.6382\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6656 - accuracy: 0.6196\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6542 - accuracy: 0.6208\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6557 - accuracy: 0.6308\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6568 - accuracy: 0.6220\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6568 - accuracy: 0.6308\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6618 - accuracy: 0.6177\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6569 - accuracy: 0.6239\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6517 - accuracy: 0.6333\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6516 - accuracy: 0.6339\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6374 - accuracy: 0.6519\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6422 - accuracy: 0.6376\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6588 - accuracy: 0.6258\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6505 - accuracy: 0.6283\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6438 - accuracy: 0.6351\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6559 - accuracy: 0.6407\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6433 - accuracy: 0.6376\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6550 - accuracy: 0.6301\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6489 - accuracy: 0.6413\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6442 - accuracy: 0.6370\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6427 - accuracy: 0.6370\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6461 - accuracy: 0.6401\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6472 - accuracy: 0.6301\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6479 - accuracy: 0.6364\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 1s 350us/step - loss: 0.6524 - accuracy: 0.6314\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6477 - accuracy: 0.6401\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6418 - accuracy: 0.6395\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6415 - accuracy: 0.6364\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6380 - accuracy: 0.6507\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6379 - accuracy: 0.6364\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6449 - accuracy: 0.6233\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6464 - accuracy: 0.6339\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6500 - accuracy: 0.6276\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6410 - accuracy: 0.6457\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6470 - accuracy: 0.6295\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6395 - accuracy: 0.6426\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6473 - accuracy: 0.6326\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6365 - accuracy: 0.6494\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6312 - accuracy: 0.6488\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6314 - accuracy: 0.6469\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6439 - accuracy: 0.6308\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6466 - accuracy: 0.6469\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6370 - accuracy: 0.6401\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6388 - accuracy: 0.6488\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6297 - accuracy: 0.6488\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6383 - accuracy: 0.6389\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6315 - accuracy: 0.6457\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6267 - accuracy: 0.6494\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6301 - accuracy: 0.6407\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.6316 - accuracy: 0.6526\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6319 - accuracy: 0.6438\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6390 - accuracy: 0.6395\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6404 - accuracy: 0.6357\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6381 - accuracy: 0.6438\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6242 - accuracy: 0.6563\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6277 - accuracy: 0.6606\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.6270 - accuracy: 0.6582\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6150 - accuracy: 0.6544\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6246 - accuracy: 0.6588\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.6184 - accuracy: 0.6663\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.6207 - accuracy: 0.6532\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6265 - accuracy: 0.6700\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6117 - accuracy: 0.6619\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6154 - accuracy: 0.6700\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6188 - accuracy: 0.6557\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6361 - accuracy: 0.6476\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6262 - accuracy: 0.6582\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6358 - accuracy: 0.6519\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6228 - accuracy: 0.6663\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6258 - accuracy: 0.6507\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6308 - accuracy: 0.6519\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6228 - accuracy: 0.6426\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6280 - accuracy: 0.6476\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6144 - accuracy: 0.6644\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6219 - accuracy: 0.6532\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6126 - accuracy: 0.6619\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6136 - accuracy: 0.6594\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6080 - accuracy: 0.6619\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6166 - accuracy: 0.6731\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6211 - accuracy: 0.6619\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6230 - accuracy: 0.6538\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6052 - accuracy: 0.6787\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.6200 - accuracy: 0.6544\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.6069 - accuracy: 0.6768\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5967 - accuracy: 0.6675\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6042 - accuracy: 0.6675\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6097 - accuracy: 0.6644\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.6018 - accuracy: 0.6824\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6049 - accuracy: 0.6737\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6006 - accuracy: 0.6843\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6051 - accuracy: 0.6750\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6024 - accuracy: 0.6812\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.6190 - accuracy: 0.6762\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.6072 - accuracy: 0.6831\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6033 - accuracy: 0.6806\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6086 - accuracy: 0.6781\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6025 - accuracy: 0.6743\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5953 - accuracy: 0.6737\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6060 - accuracy: 0.6725\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5993 - accuracy: 0.6781\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5963 - accuracy: 0.6768\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.5950 - accuracy: 0.6818\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5995 - accuracy: 0.6700\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.6036 - accuracy: 0.6787\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5968 - accuracy: 0.6756\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5985 - accuracy: 0.6700\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5953 - accuracy: 0.6843\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5920 - accuracy: 0.6905\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.5856 - accuracy: 0.6918\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5854 - accuracy: 0.6862\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 1s 351us/step - loss: 0.5854 - accuracy: 0.6943\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.5940 - accuracy: 0.6887\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.5842 - accuracy: 0.6968\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5986 - accuracy: 0.6781\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5988 - accuracy: 0.6824\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.5994 - accuracy: 0.6737\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 1s 353us/step - loss: 0.5867 - accuracy: 0.6943\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 1s 363us/step - loss: 0.5967 - accuracy: 0.6687\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5893 - accuracy: 0.6831\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5873 - accuracy: 0.6812\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5804 - accuracy: 0.6905\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5834 - accuracy: 0.6893\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5827 - accuracy: 0.7030\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5918 - accuracy: 0.6980\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5886 - accuracy: 0.6781\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.6011 - accuracy: 0.6694\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5774 - accuracy: 0.7036\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5915 - accuracy: 0.6737\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5845 - accuracy: 0.6918\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5826 - accuracy: 0.6893\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5870 - accuracy: 0.6968\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5862 - accuracy: 0.6818\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5754 - accuracy: 0.7086\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5762 - accuracy: 0.7030\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5712 - accuracy: 0.7017\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5820 - accuracy: 0.7036\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5635 - accuracy: 0.7086\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5777 - accuracy: 0.6955\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5691 - accuracy: 0.7036\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5932 - accuracy: 0.6862\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5646 - accuracy: 0.7154\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 1s 362us/step - loss: 0.5797 - accuracy: 0.7005\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5777 - accuracy: 0.7024\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5745 - accuracy: 0.7092\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5768 - accuracy: 0.6955\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5673 - accuracy: 0.7049\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5762 - accuracy: 0.7098\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 1s 355us/step - loss: 0.5768 - accuracy: 0.6949\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5683 - accuracy: 0.7042\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 1s 361us/step - loss: 0.5666 - accuracy: 0.7105\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5633 - accuracy: 0.7173\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5724 - accuracy: 0.7080\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.5658 - accuracy: 0.6993\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 1s 352us/step - loss: 0.5711 - accuracy: 0.6943\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5741 - accuracy: 0.6943\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5725 - accuracy: 0.6974\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 1s 364us/step - loss: 0.5678 - accuracy: 0.6993\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 1s 368us/step - loss: 0.5574 - accuracy: 0.7086\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.5721 - accuracy: 0.6930\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5553 - accuracy: 0.7142\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5641 - accuracy: 0.7011\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5657 - accuracy: 0.7049\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 1s 360us/step - loss: 0.5543 - accuracy: 0.7148\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 1s 358us/step - loss: 0.5673 - accuracy: 0.7067\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 1s 356us/step - loss: 0.5625 - accuracy: 0.7098\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.5632 - accuracy: 0.7117\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 1s 354us/step - loss: 0.5510 - accuracy: 0.7130\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 1s 357us/step - loss: 0.5485 - accuracy: 0.7161\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5547 - accuracy: 0.7186\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5656 - accuracy: 0.7148\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5477 - accuracy: 0.7198\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5501 - accuracy: 0.7142\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5579 - accuracy: 0.7210\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5733 - accuracy: 0.6999\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5500 - accuracy: 0.7242\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5580 - accuracy: 0.7105\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5540 - accuracy: 0.7223\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5651 - accuracy: 0.7092\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5560 - accuracy: 0.7117\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5520 - accuracy: 0.7130\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5542 - accuracy: 0.7210\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5534 - accuracy: 0.7154\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5515 - accuracy: 0.7136\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5590 - accuracy: 0.7073\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5430 - accuracy: 0.7298\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5451 - accuracy: 0.7341\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5444 - accuracy: 0.7291\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5351 - accuracy: 0.7229\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5580 - accuracy: 0.7167\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5348 - accuracy: 0.7291\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5403 - accuracy: 0.7285\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5428 - accuracy: 0.7273\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5433 - accuracy: 0.7273\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5527 - accuracy: 0.7161\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5366 - accuracy: 0.7341\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5400 - accuracy: 0.7223\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5279 - accuracy: 0.7329\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5410 - accuracy: 0.7223\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5401 - accuracy: 0.7291\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5296 - accuracy: 0.7335\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5240 - accuracy: 0.7360\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5484 - accuracy: 0.7254\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5313 - accuracy: 0.7341\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5536 - accuracy: 0.7273\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5270 - accuracy: 0.7453\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5319 - accuracy: 0.7416\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.5300 - accuracy: 0.7385\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5264 - accuracy: 0.7354\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5418 - accuracy: 0.7335\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5357 - accuracy: 0.7379\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5270 - accuracy: 0.7435\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5234 - accuracy: 0.7397\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5239 - accuracy: 0.7360\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5276 - accuracy: 0.7491\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5290 - accuracy: 0.7347\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5243 - accuracy: 0.7478\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5241 - accuracy: 0.7441\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5357 - accuracy: 0.7422\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5172 - accuracy: 0.7453\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5098 - accuracy: 0.7522\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5426 - accuracy: 0.7291\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5215 - accuracy: 0.7460\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5429 - accuracy: 0.7478\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5081 - accuracy: 0.7522\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5249 - accuracy: 0.7347\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5249 - accuracy: 0.7441\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5255 - accuracy: 0.7385\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5194 - accuracy: 0.7410\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5092 - accuracy: 0.7559\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.5200 - accuracy: 0.7403\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5192 - accuracy: 0.7478\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5353 - accuracy: 0.7291\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5181 - accuracy: 0.7534\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5103 - accuracy: 0.7503\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5084 - accuracy: 0.7460\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5071 - accuracy: 0.7472\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5130 - accuracy: 0.7460\n",
      "準確率 : 0.6691542288557214\n",
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.8109 - accuracy: 0.5473\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7505 - accuracy: 0.5697\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.7639 - accuracy: 0.5392\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7478 - accuracy: 0.5560\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.7147 - accuracy: 0.5816\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7323 - accuracy: 0.5592\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7000 - accuracy: 0.5872\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7171 - accuracy: 0.5872\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7238 - accuracy: 0.5691\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6979 - accuracy: 0.5890\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7007 - accuracy: 0.5809\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6927 - accuracy: 0.5841\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6896 - accuracy: 0.5878\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6966 - accuracy: 0.5803\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6934 - accuracy: 0.5915\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6850 - accuracy: 0.5884\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6789 - accuracy: 0.5978\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6820 - accuracy: 0.6171\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6887 - accuracy: 0.5978\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7045 - accuracy: 0.5766\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6945 - accuracy: 0.6021\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6737 - accuracy: 0.6090\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6674 - accuracy: 0.6177\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6752 - accuracy: 0.6046\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6813 - accuracy: 0.6115\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6799 - accuracy: 0.6034\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6805 - accuracy: 0.6021\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6843 - accuracy: 0.6059\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6806 - accuracy: 0.6009\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6852 - accuracy: 0.5922\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6761 - accuracy: 0.6059\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6677 - accuracy: 0.6177\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6782 - accuracy: 0.5990\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6690 - accuracy: 0.6083\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6629 - accuracy: 0.6027\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6625 - accuracy: 0.6040\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6607 - accuracy: 0.6139\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6771 - accuracy: 0.5946\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6633 - accuracy: 0.6146\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6837 - accuracy: 0.5978\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6824 - accuracy: 0.6034\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6700 - accuracy: 0.6108\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6688 - accuracy: 0.6083\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6702 - accuracy: 0.6065\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6686 - accuracy: 0.6059\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6521 - accuracy: 0.6202\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6773 - accuracy: 0.5978\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6695 - accuracy: 0.6083\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6670 - accuracy: 0.6096\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6677 - accuracy: 0.6071\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6586 - accuracy: 0.6127\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6585 - accuracy: 0.6189\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6454 - accuracy: 0.6413\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6531 - accuracy: 0.6227\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6593 - accuracy: 0.6046\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6632 - accuracy: 0.6146\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6627 - accuracy: 0.6258\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6602 - accuracy: 0.6065\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6576 - accuracy: 0.6214\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6545 - accuracy: 0.6083\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6557 - accuracy: 0.6308\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6657 - accuracy: 0.6158\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6698 - accuracy: 0.5953\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6664 - accuracy: 0.6115\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6561 - accuracy: 0.6264\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6586 - accuracy: 0.6301\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6488 - accuracy: 0.6339\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6594 - accuracy: 0.6320\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6449 - accuracy: 0.6357\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6457 - accuracy: 0.6326\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6522 - accuracy: 0.6202\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6748 - accuracy: 0.6040\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6447 - accuracy: 0.6276\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6614 - accuracy: 0.6102\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6628 - accuracy: 0.5934\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6429 - accuracy: 0.6270\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6668 - accuracy: 0.6258\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6470 - accuracy: 0.6301\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6461 - accuracy: 0.6395\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6509 - accuracy: 0.6295\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6443 - accuracy: 0.6295\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6472 - accuracy: 0.6245\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6629 - accuracy: 0.6258\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6594 - accuracy: 0.6196\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6368 - accuracy: 0.6544\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6531 - accuracy: 0.6364\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6418 - accuracy: 0.6438\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6502 - accuracy: 0.6227\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6436 - accuracy: 0.6370\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6390 - accuracy: 0.6364\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6361 - accuracy: 0.6395\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6414 - accuracy: 0.6376\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6416 - accuracy: 0.6382\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6425 - accuracy: 0.6295\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6400 - accuracy: 0.6320\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6305 - accuracy: 0.6526\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6421 - accuracy: 0.6445\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6375 - accuracy: 0.6438\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6451 - accuracy: 0.6407\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6395 - accuracy: 0.6426\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6492 - accuracy: 0.6308\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6426 - accuracy: 0.6544\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6388 - accuracy: 0.6364\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6391 - accuracy: 0.6519\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6290 - accuracy: 0.6451\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6438 - accuracy: 0.6401\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6446 - accuracy: 0.6401\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6298 - accuracy: 0.6594\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6302 - accuracy: 0.6569\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6317 - accuracy: 0.6432\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6304 - accuracy: 0.6445\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6404 - accuracy: 0.6457\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6213 - accuracy: 0.6569\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6195 - accuracy: 0.6438\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6235 - accuracy: 0.6407\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6280 - accuracy: 0.6476\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6425 - accuracy: 0.6345\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6374 - accuracy: 0.6438\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6272 - accuracy: 0.6526\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6319 - accuracy: 0.6469\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6269 - accuracy: 0.6488\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6392 - accuracy: 0.6389\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6347 - accuracy: 0.6339\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6375 - accuracy: 0.6370\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6299 - accuracy: 0.6563\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.6219 - accuracy: 0.6413\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6300 - accuracy: 0.6519\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6315 - accuracy: 0.6532\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6275 - accuracy: 0.6507\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6196 - accuracy: 0.6488\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6368 - accuracy: 0.6488\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6407 - accuracy: 0.6283\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6283 - accuracy: 0.6619\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6202 - accuracy: 0.6638\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6250 - accuracy: 0.6426\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6189 - accuracy: 0.6463\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6296 - accuracy: 0.6426\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6195 - accuracy: 0.6519\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6266 - accuracy: 0.6625\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6242 - accuracy: 0.6613\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6130 - accuracy: 0.6681\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6113 - accuracy: 0.6550\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6258 - accuracy: 0.6569\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6198 - accuracy: 0.6656\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6230 - accuracy: 0.6544\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6064 - accuracy: 0.6700\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6192 - accuracy: 0.6687\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6267 - accuracy: 0.6501\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6182 - accuracy: 0.6600\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6173 - accuracy: 0.6669\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6159 - accuracy: 0.6625\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6168 - accuracy: 0.6476\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6096 - accuracy: 0.6681\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6198 - accuracy: 0.6631\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6168 - accuracy: 0.6700\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6254 - accuracy: 0.6494\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6250 - accuracy: 0.6457\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6132 - accuracy: 0.6569\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6187 - accuracy: 0.6631\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6097 - accuracy: 0.6638\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6111 - accuracy: 0.6625\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6006 - accuracy: 0.6756\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5993 - accuracy: 0.6880\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6079 - accuracy: 0.6694\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6022 - accuracy: 0.6831\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6097 - accuracy: 0.6731\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6076 - accuracy: 0.6669\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6134 - accuracy: 0.6694\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6084 - accuracy: 0.6700\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6076 - accuracy: 0.6762\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6093 - accuracy: 0.6712\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6116 - accuracy: 0.6656\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5942 - accuracy: 0.6762\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6006 - accuracy: 0.6912\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5892 - accuracy: 0.6800\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5881 - accuracy: 0.6831\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6071 - accuracy: 0.6781\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5967 - accuracy: 0.6862\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5858 - accuracy: 0.7024\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6030 - accuracy: 0.6712\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5942 - accuracy: 0.6880\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5974 - accuracy: 0.6700\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5908 - accuracy: 0.6831\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6006 - accuracy: 0.6818\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6010 - accuracy: 0.6768\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5878 - accuracy: 0.6831\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6046 - accuracy: 0.6768\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5980 - accuracy: 0.6843\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6037 - accuracy: 0.6650\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5897 - accuracy: 0.6912\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5860 - accuracy: 0.6818\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5934 - accuracy: 0.6812\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.5938 - accuracy: 0.6687\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5938 - accuracy: 0.6968\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6040 - accuracy: 0.6837\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5987 - accuracy: 0.6812\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5843 - accuracy: 0.6818\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5836 - accuracy: 0.6862\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5840 - accuracy: 0.6893\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5873 - accuracy: 0.6849\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5819 - accuracy: 0.6893\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5906 - accuracy: 0.6806\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5840 - accuracy: 0.6936\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5918 - accuracy: 0.6936\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5768 - accuracy: 0.6893\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5668 - accuracy: 0.7017\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5838 - accuracy: 0.6936\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5847 - accuracy: 0.6874\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5836 - accuracy: 0.6986\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.5894 - accuracy: 0.6893\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5868 - accuracy: 0.6968\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5873 - accuracy: 0.6837\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5907 - accuracy: 0.6812\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5611 - accuracy: 0.7117\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5831 - accuracy: 0.6899\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5812 - accuracy: 0.6943\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5964 - accuracy: 0.6856\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5941 - accuracy: 0.6949\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5805 - accuracy: 0.7098\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5751 - accuracy: 0.6949\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5737 - accuracy: 0.6912\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5946 - accuracy: 0.6824\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5796 - accuracy: 0.6993\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5938 - accuracy: 0.6924\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5778 - accuracy: 0.6949\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5648 - accuracy: 0.6943\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.5749 - accuracy: 0.7142\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5628 - accuracy: 0.7073\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5716 - accuracy: 0.7030\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5851 - accuracy: 0.6880\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5786 - accuracy: 0.6936\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5742 - accuracy: 0.7017\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5722 - accuracy: 0.7055\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5789 - accuracy: 0.7024\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5776 - accuracy: 0.7042\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5633 - accuracy: 0.7179\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5618 - accuracy: 0.7098\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5668 - accuracy: 0.7055\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5664 - accuracy: 0.7017\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5641 - accuracy: 0.7142\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5795 - accuracy: 0.7042\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5681 - accuracy: 0.7073\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5680 - accuracy: 0.7117\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5574 - accuracy: 0.7092\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5679 - accuracy: 0.7105\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5610 - accuracy: 0.7111\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5541 - accuracy: 0.7161\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5654 - accuracy: 0.7148\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5630 - accuracy: 0.7179\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5587 - accuracy: 0.7073\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5512 - accuracy: 0.7310\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5594 - accuracy: 0.7154\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5556 - accuracy: 0.7173\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5685 - accuracy: 0.7017\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5547 - accuracy: 0.7136\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5648 - accuracy: 0.7086\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5531 - accuracy: 0.7130\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5626 - accuracy: 0.7130\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5584 - accuracy: 0.7067\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5505 - accuracy: 0.7192\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5598 - accuracy: 0.7248\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5595 - accuracy: 0.7167\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5432 - accuracy: 0.7291\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5494 - accuracy: 0.7204\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5504 - accuracy: 0.7154\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5446 - accuracy: 0.7210\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5446 - accuracy: 0.7242\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5476 - accuracy: 0.7198\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5597 - accuracy: 0.7204\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5442 - accuracy: 0.7329\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5469 - accuracy: 0.7254\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.5624 - accuracy: 0.7030\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5352 - accuracy: 0.7291\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5531 - accuracy: 0.7055\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5418 - accuracy: 0.7291\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5422 - accuracy: 0.7310\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5695 - accuracy: 0.7092\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5458 - accuracy: 0.7316\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5371 - accuracy: 0.7323\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5583 - accuracy: 0.7242\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5407 - accuracy: 0.7254\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5360 - accuracy: 0.7391\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5416 - accuracy: 0.7323\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5435 - accuracy: 0.7173\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5382 - accuracy: 0.7223\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5354 - accuracy: 0.7254\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5554 - accuracy: 0.7161\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5414 - accuracy: 0.7285\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5411 - accuracy: 0.7235\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5373 - accuracy: 0.7366\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5470 - accuracy: 0.7341\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5425 - accuracy: 0.7285\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5477 - accuracy: 0.7391\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5421 - accuracy: 0.7186\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5370 - accuracy: 0.7235\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5253 - accuracy: 0.7416\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5350 - accuracy: 0.7360\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5408 - accuracy: 0.7235\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5481 - accuracy: 0.7192\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5283 - accuracy: 0.7385\n",
      "準確率 : 0.6766169154228856\n",
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.8552 - accuracy: 0.5050\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7706 - accuracy: 0.5399\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7528 - accuracy: 0.5548\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7347 - accuracy: 0.5535\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7038 - accuracy: 0.5697\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7146 - accuracy: 0.5704\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.7161 - accuracy: 0.5654\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7091 - accuracy: 0.5791\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7003 - accuracy: 0.5890\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6954 - accuracy: 0.5778\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6883 - accuracy: 0.5853\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7191 - accuracy: 0.5679\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6859 - accuracy: 0.5890\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6767 - accuracy: 0.6015\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7009 - accuracy: 0.5803\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6935 - accuracy: 0.5959\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6986 - accuracy: 0.5616\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6783 - accuracy: 0.6065\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6803 - accuracy: 0.5940\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6846 - accuracy: 0.5760\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6937 - accuracy: 0.5915\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7094 - accuracy: 0.5922\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6936 - accuracy: 0.5841\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6849 - accuracy: 0.6034\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6897 - accuracy: 0.5878\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6925 - accuracy: 0.5778\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6839 - accuracy: 0.6002\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6890 - accuracy: 0.5803\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6786 - accuracy: 0.6015\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6738 - accuracy: 0.5946\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6864 - accuracy: 0.5847\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6705 - accuracy: 0.5884\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6710 - accuracy: 0.6127\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6932 - accuracy: 0.5884\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6878 - accuracy: 0.5841\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6827 - accuracy: 0.5778\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6770 - accuracy: 0.5890\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6843 - accuracy: 0.5953\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6773 - accuracy: 0.6015\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6609 - accuracy: 0.6121\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6710 - accuracy: 0.6021\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6782 - accuracy: 0.5946\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6788 - accuracy: 0.5909\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6715 - accuracy: 0.6083\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6806 - accuracy: 0.5828\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6722 - accuracy: 0.6096\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6807 - accuracy: 0.5978\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6728 - accuracy: 0.6034\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6662 - accuracy: 0.6102\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6656 - accuracy: 0.6133\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6630 - accuracy: 0.6121\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6606 - accuracy: 0.6189\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6739 - accuracy: 0.6071\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6769 - accuracy: 0.5978\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6596 - accuracy: 0.6133\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6581 - accuracy: 0.6220\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6585 - accuracy: 0.6121\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6623 - accuracy: 0.6065\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6724 - accuracy: 0.6096\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6577 - accuracy: 0.6233\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6656 - accuracy: 0.6220\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6555 - accuracy: 0.6152\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6691 - accuracy: 0.6077\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6663 - accuracy: 0.6046\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6666 - accuracy: 0.6183\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6577 - accuracy: 0.6220\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6564 - accuracy: 0.6146\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6679 - accuracy: 0.6108\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6676 - accuracy: 0.6164\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6661 - accuracy: 0.6220\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6577 - accuracy: 0.6245\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6445 - accuracy: 0.6345\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6483 - accuracy: 0.6245\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6673 - accuracy: 0.6227\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6539 - accuracy: 0.6289\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6533 - accuracy: 0.6308\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6539 - accuracy: 0.6314\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6502 - accuracy: 0.6407\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6558 - accuracy: 0.6314\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6633 - accuracy: 0.6208\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6492 - accuracy: 0.6245\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6532 - accuracy: 0.6189\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6398 - accuracy: 0.6258\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6578 - accuracy: 0.6139\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6515 - accuracy: 0.6320\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6488 - accuracy: 0.6376\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6374 - accuracy: 0.6382\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6393 - accuracy: 0.6401\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6577 - accuracy: 0.6345\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6585 - accuracy: 0.6264\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6424 - accuracy: 0.6301\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6516 - accuracy: 0.6171\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6551 - accuracy: 0.6351\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6498 - accuracy: 0.6220\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6303 - accuracy: 0.6382\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6402 - accuracy: 0.6445\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6558 - accuracy: 0.6220\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6509 - accuracy: 0.6333\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6501 - accuracy: 0.6426\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6428 - accuracy: 0.6283\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6431 - accuracy: 0.6264\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6410 - accuracy: 0.6239\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6412 - accuracy: 0.6389\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6434 - accuracy: 0.6364\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6284 - accuracy: 0.6420\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6362 - accuracy: 0.6295\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6411 - accuracy: 0.6426\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6238 - accuracy: 0.6494\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6393 - accuracy: 0.6445\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6430 - accuracy: 0.6357\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6409 - accuracy: 0.6382\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6417 - accuracy: 0.6432\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6325 - accuracy: 0.6482\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6379 - accuracy: 0.6401\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6333 - accuracy: 0.6438\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6403 - accuracy: 0.6283\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6242 - accuracy: 0.6663\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6430 - accuracy: 0.6339\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6334 - accuracy: 0.6420\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6332 - accuracy: 0.6532\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6320 - accuracy: 0.6401\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6252 - accuracy: 0.6538\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6271 - accuracy: 0.6488\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6299 - accuracy: 0.6544\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6333 - accuracy: 0.6301\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6220 - accuracy: 0.6588\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6249 - accuracy: 0.6389\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6167 - accuracy: 0.6569\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6341 - accuracy: 0.6426\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6256 - accuracy: 0.6445\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6145 - accuracy: 0.6532\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6110 - accuracy: 0.6526\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6309 - accuracy: 0.6550\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6328 - accuracy: 0.6432\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6140 - accuracy: 0.6606\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6196 - accuracy: 0.6582\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6205 - accuracy: 0.6389\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6234 - accuracy: 0.6538\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6149 - accuracy: 0.6600\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6200 - accuracy: 0.6644\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6120 - accuracy: 0.6687\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6191 - accuracy: 0.6681\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6259 - accuracy: 0.6501\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6164 - accuracy: 0.6619\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6130 - accuracy: 0.6700\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6210 - accuracy: 0.6501\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6124 - accuracy: 0.6650\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6308 - accuracy: 0.6351\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6194 - accuracy: 0.6469\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6232 - accuracy: 0.6494\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6092 - accuracy: 0.6675\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6184 - accuracy: 0.6569\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6183 - accuracy: 0.6619\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6094 - accuracy: 0.6625\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6103 - accuracy: 0.6706\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5960 - accuracy: 0.6787\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5979 - accuracy: 0.6656\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6093 - accuracy: 0.6613\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6099 - accuracy: 0.6550\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6034 - accuracy: 0.6638\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6106 - accuracy: 0.6694\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6049 - accuracy: 0.6669\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6064 - accuracy: 0.6843\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6102 - accuracy: 0.6743\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6091 - accuracy: 0.6656\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6009 - accuracy: 0.6700\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6023 - accuracy: 0.6762\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6074 - accuracy: 0.6743\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6084 - accuracy: 0.6606\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5992 - accuracy: 0.6750\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5972 - accuracy: 0.6743\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5907 - accuracy: 0.6943\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6173 - accuracy: 0.6706\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6095 - accuracy: 0.6606\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6043 - accuracy: 0.6750\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5759 - accuracy: 0.6986\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6172 - accuracy: 0.6631\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6089 - accuracy: 0.6644\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5912 - accuracy: 0.6893\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5881 - accuracy: 0.6918\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5910 - accuracy: 0.6787\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6148 - accuracy: 0.6756\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5982 - accuracy: 0.6762\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5932 - accuracy: 0.6800\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5936 - accuracy: 0.6980\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5984 - accuracy: 0.6893\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5862 - accuracy: 0.6837\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5961 - accuracy: 0.6800\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5960 - accuracy: 0.6856\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5863 - accuracy: 0.6868\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5932 - accuracy: 0.6793\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5803 - accuracy: 0.6856\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5870 - accuracy: 0.6880\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5806 - accuracy: 0.6831\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5944 - accuracy: 0.6862\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5734 - accuracy: 0.6986\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5817 - accuracy: 0.6880\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5829 - accuracy: 0.7017\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5730 - accuracy: 0.6974\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5942 - accuracy: 0.6887\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5837 - accuracy: 0.6961\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5800 - accuracy: 0.6943\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5897 - accuracy: 0.6899\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5761 - accuracy: 0.6887\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5697 - accuracy: 0.7148\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5802 - accuracy: 0.6899\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5765 - accuracy: 0.6936\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5742 - accuracy: 0.6955\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5774 - accuracy: 0.6999\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5984 - accuracy: 0.6918\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5607 - accuracy: 0.7086\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5681 - accuracy: 0.6993\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5736 - accuracy: 0.7049\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5846 - accuracy: 0.6893\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5819 - accuracy: 0.6880\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5707 - accuracy: 0.7086\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5690 - accuracy: 0.7092\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5740 - accuracy: 0.7005\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5694 - accuracy: 0.7067\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5796 - accuracy: 0.7005\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5752 - accuracy: 0.6980\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5688 - accuracy: 0.7055\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5732 - accuracy: 0.7030\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5536 - accuracy: 0.7186\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5678 - accuracy: 0.7017\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5709 - accuracy: 0.6924\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.5653 - accuracy: 0.6961\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5587 - accuracy: 0.7073\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5599 - accuracy: 0.7105\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5708 - accuracy: 0.6936\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5553 - accuracy: 0.7204\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5632 - accuracy: 0.7061\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5642 - accuracy: 0.7210\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5582 - accuracy: 0.7111\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5524 - accuracy: 0.7186\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5547 - accuracy: 0.7179\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5642 - accuracy: 0.7167\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5538 - accuracy: 0.7092\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5656 - accuracy: 0.7161\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5727 - accuracy: 0.7055\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5563 - accuracy: 0.7210\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5546 - accuracy: 0.7123\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5576 - accuracy: 0.7080\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5487 - accuracy: 0.7148\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5623 - accuracy: 0.7092\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5482 - accuracy: 0.7210\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5407 - accuracy: 0.7260\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5541 - accuracy: 0.7161\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5518 - accuracy: 0.7098\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5481 - accuracy: 0.7304\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5509 - accuracy: 0.7217\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5479 - accuracy: 0.7235\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5373 - accuracy: 0.7242\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5443 - accuracy: 0.7298\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5537 - accuracy: 0.7235\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5530 - accuracy: 0.7248\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5445 - accuracy: 0.7186\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5576 - accuracy: 0.7092\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5533 - accuracy: 0.7210\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5523 - accuracy: 0.7210\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5435 - accuracy: 0.7179\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5514 - accuracy: 0.7080\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5534 - accuracy: 0.7192\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5465 - accuracy: 0.7210\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5375 - accuracy: 0.7316\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5380 - accuracy: 0.7298\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5447 - accuracy: 0.7310\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5470 - accuracy: 0.7217\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5471 - accuracy: 0.7248\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5434 - accuracy: 0.7310\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5406 - accuracy: 0.7279\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5483 - accuracy: 0.7204\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5438 - accuracy: 0.7285\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5351 - accuracy: 0.7329\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5246 - accuracy: 0.7360\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5254 - accuracy: 0.7410\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5345 - accuracy: 0.7285\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5353 - accuracy: 0.7347\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5319 - accuracy: 0.7279\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5378 - accuracy: 0.7422\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.5301 - accuracy: 0.7428\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5382 - accuracy: 0.7366\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5350 - accuracy: 0.7385\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5296 - accuracy: 0.7285\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 1s 339us/step - loss: 0.5203 - accuracy: 0.7354\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5331 - accuracy: 0.7329\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5251 - accuracy: 0.7341\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5233 - accuracy: 0.7354\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5275 - accuracy: 0.7360\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5281 - accuracy: 0.7435\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5218 - accuracy: 0.7410\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5161 - accuracy: 0.7478\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5278 - accuracy: 0.7372\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5228 - accuracy: 0.7329\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5264 - accuracy: 0.7391\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5209 - accuracy: 0.7372\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5158 - accuracy: 0.7472\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5294 - accuracy: 0.7391\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5164 - accuracy: 0.7435\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5318 - accuracy: 0.7341\n",
      "準確率 : 0.6791044776119403\n",
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.8172 - accuracy: 0.5336\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7587 - accuracy: 0.5355\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7444 - accuracy: 0.5498\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7524 - accuracy: 0.5336\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7070 - accuracy: 0.5685\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7250 - accuracy: 0.5504\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7180 - accuracy: 0.5648\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7095 - accuracy: 0.5604\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.7084 - accuracy: 0.5834\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7051 - accuracy: 0.5816\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6960 - accuracy: 0.6034\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6995 - accuracy: 0.5853\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6869 - accuracy: 0.5847\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6956 - accuracy: 0.5778\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.7048 - accuracy: 0.5797\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6946 - accuracy: 0.5747\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6983 - accuracy: 0.5822\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6940 - accuracy: 0.5859\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6956 - accuracy: 0.5903\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6775 - accuracy: 0.5922\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6927 - accuracy: 0.5809\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6866 - accuracy: 0.5809\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6916 - accuracy: 0.6021\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6783 - accuracy: 0.5909\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6745 - accuracy: 0.6002\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6898 - accuracy: 0.5897\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6900 - accuracy: 0.5922\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6929 - accuracy: 0.5922\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6897 - accuracy: 0.5890\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6750 - accuracy: 0.6002\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6834 - accuracy: 0.5984\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6911 - accuracy: 0.5778\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6976 - accuracy: 0.5785\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6790 - accuracy: 0.6108\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6759 - accuracy: 0.6052\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6825 - accuracy: 0.5965\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6838 - accuracy: 0.5803\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6892 - accuracy: 0.5866\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6848 - accuracy: 0.5971\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6752 - accuracy: 0.5996\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6831 - accuracy: 0.5959\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6847 - accuracy: 0.5878\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6860 - accuracy: 0.5797\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6685 - accuracy: 0.6021\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6810 - accuracy: 0.5940\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6733 - accuracy: 0.6040\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6712 - accuracy: 0.6021\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6682 - accuracy: 0.5946\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6660 - accuracy: 0.6220\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6705 - accuracy: 0.6233\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6676 - accuracy: 0.6071\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6703 - accuracy: 0.6102\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6708 - accuracy: 0.6133\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6598 - accuracy: 0.6139\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6660 - accuracy: 0.6027\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6710 - accuracy: 0.6139\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6745 - accuracy: 0.6059\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6564 - accuracy: 0.6326\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6648 - accuracy: 0.6071\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6651 - accuracy: 0.5978\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6571 - accuracy: 0.6389\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6782 - accuracy: 0.5922\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6643 - accuracy: 0.5996\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6544 - accuracy: 0.6220\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6632 - accuracy: 0.6071\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6562 - accuracy: 0.6252\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6702 - accuracy: 0.6065\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6689 - accuracy: 0.6096\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6644 - accuracy: 0.6059\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6592 - accuracy: 0.6295\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6605 - accuracy: 0.6133\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6498 - accuracy: 0.6389\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6678 - accuracy: 0.6139\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6634 - accuracy: 0.6133\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6628 - accuracy: 0.6090\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6609 - accuracy: 0.6102\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6558 - accuracy: 0.6295\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 1s 359us/step - loss: 0.6610 - accuracy: 0.6171\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6524 - accuracy: 0.6301\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6633 - accuracy: 0.6177\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6621 - accuracy: 0.6189\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6465 - accuracy: 0.6121\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6440 - accuracy: 0.6370\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6517 - accuracy: 0.6245\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6404 - accuracy: 0.6364\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6548 - accuracy: 0.6196\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6572 - accuracy: 0.6127\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6555 - accuracy: 0.6146\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6548 - accuracy: 0.6283\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6476 - accuracy: 0.6295\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6663 - accuracy: 0.6214\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6533 - accuracy: 0.6301\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6495 - accuracy: 0.6133\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6489 - accuracy: 0.6233\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6569 - accuracy: 0.6364\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6457 - accuracy: 0.6326\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6609 - accuracy: 0.6127\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6545 - accuracy: 0.6152\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6461 - accuracy: 0.6320\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6592 - accuracy: 0.6189\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6489 - accuracy: 0.6283\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6571 - accuracy: 0.6208\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6541 - accuracy: 0.6177\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6523 - accuracy: 0.6158\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6526 - accuracy: 0.6289\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6509 - accuracy: 0.6339\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6460 - accuracy: 0.6202\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6299 - accuracy: 0.6432\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6498 - accuracy: 0.6270\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6509 - accuracy: 0.6370\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6516 - accuracy: 0.6345\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6522 - accuracy: 0.6295\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6416 - accuracy: 0.6289\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6576 - accuracy: 0.6289\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6452 - accuracy: 0.6308\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6427 - accuracy: 0.6457\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6451 - accuracy: 0.6301\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6425 - accuracy: 0.6457\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6351 - accuracy: 0.6569\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6367 - accuracy: 0.6457\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6530 - accuracy: 0.6283\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6450 - accuracy: 0.6420\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6363 - accuracy: 0.6252\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6367 - accuracy: 0.6457\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6273 - accuracy: 0.6376\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6419 - accuracy: 0.6420\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6461 - accuracy: 0.6382\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6337 - accuracy: 0.6550\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6380 - accuracy: 0.6364\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6302 - accuracy: 0.6507\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6357 - accuracy: 0.6370\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6325 - accuracy: 0.6544\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6372 - accuracy: 0.6407\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6347 - accuracy: 0.6563\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6339 - accuracy: 0.6357\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6394 - accuracy: 0.6463\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6330 - accuracy: 0.6488\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6290 - accuracy: 0.6501\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6353 - accuracy: 0.6370\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6429 - accuracy: 0.6376\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6300 - accuracy: 0.6413\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6365 - accuracy: 0.6488\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6316 - accuracy: 0.6463\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6281 - accuracy: 0.6563\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6272 - accuracy: 0.6445\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6266 - accuracy: 0.6582\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6358 - accuracy: 0.6650\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6264 - accuracy: 0.6463\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6281 - accuracy: 0.6370\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6374 - accuracy: 0.6345\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6221 - accuracy: 0.6606\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6169 - accuracy: 0.6594\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6285 - accuracy: 0.6513\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6245 - accuracy: 0.6606\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6206 - accuracy: 0.6532\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6180 - accuracy: 0.6513\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6266 - accuracy: 0.6569\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6206 - accuracy: 0.6588\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6260 - accuracy: 0.6569\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 1s 348us/step - loss: 0.6285 - accuracy: 0.6457\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6237 - accuracy: 0.6563\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6106 - accuracy: 0.6756\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 1s 350us/step - loss: 0.6107 - accuracy: 0.6656\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6192 - accuracy: 0.6544\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6241 - accuracy: 0.6631\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6313 - accuracy: 0.6532\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6160 - accuracy: 0.6469\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6081 - accuracy: 0.6644\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6169 - accuracy: 0.6706\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6098 - accuracy: 0.6588\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6215 - accuracy: 0.6357\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5997 - accuracy: 0.6793\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6112 - accuracy: 0.6644\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6092 - accuracy: 0.6619\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6130 - accuracy: 0.6837\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6151 - accuracy: 0.6731\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6204 - accuracy: 0.6600\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6102 - accuracy: 0.6631\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6215 - accuracy: 0.6731\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6053 - accuracy: 0.6762\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6106 - accuracy: 0.6638\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6118 - accuracy: 0.6700\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6060 - accuracy: 0.6775\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6058 - accuracy: 0.6806\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6061 - accuracy: 0.6719\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5945 - accuracy: 0.6856\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5924 - accuracy: 0.6874\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6028 - accuracy: 0.6675\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6027 - accuracy: 0.6700\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6089 - accuracy: 0.6606\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5949 - accuracy: 0.6793\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6049 - accuracy: 0.6756\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.6121 - accuracy: 0.6638\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6040 - accuracy: 0.6812\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5906 - accuracy: 0.6806\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5985 - accuracy: 0.6849\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5979 - accuracy: 0.6787\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6044 - accuracy: 0.6787\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6016 - accuracy: 0.6775\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5971 - accuracy: 0.6731\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6025 - accuracy: 0.6700\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5930 - accuracy: 0.6893\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5848 - accuracy: 0.6880\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.6118 - accuracy: 0.6762\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5946 - accuracy: 0.6818\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5947 - accuracy: 0.6824\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5981 - accuracy: 0.6868\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5844 - accuracy: 0.6831\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5929 - accuracy: 0.6993\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5871 - accuracy: 0.6775\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5871 - accuracy: 0.6862\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5974 - accuracy: 0.6986\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5960 - accuracy: 0.6818\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6075 - accuracy: 0.6787\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5948 - accuracy: 0.6893\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5769 - accuracy: 0.6993\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5902 - accuracy: 0.6837\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6001 - accuracy: 0.6737\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5854 - accuracy: 0.6912\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5918 - accuracy: 0.6856\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5906 - accuracy: 0.6868\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5839 - accuracy: 0.7055\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5776 - accuracy: 0.6943\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6009 - accuracy: 0.6812\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5814 - accuracy: 0.6980\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5865 - accuracy: 0.6843\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5836 - accuracy: 0.6936\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5808 - accuracy: 0.6986\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5849 - accuracy: 0.6936\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5918 - accuracy: 0.6837\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5824 - accuracy: 0.6943\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5848 - accuracy: 0.6837\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5731 - accuracy: 0.6999\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5753 - accuracy: 0.7130\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5795 - accuracy: 0.6899\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5745 - accuracy: 0.6993\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5808 - accuracy: 0.7030\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5627 - accuracy: 0.7154\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5774 - accuracy: 0.6980\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5763 - accuracy: 0.6912\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5701 - accuracy: 0.6986\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5776 - accuracy: 0.7036\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5709 - accuracy: 0.7067\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5671 - accuracy: 0.6974\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5699 - accuracy: 0.7011\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5690 - accuracy: 0.7036\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5698 - accuracy: 0.7130\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5665 - accuracy: 0.7167\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5761 - accuracy: 0.6980\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5655 - accuracy: 0.7086\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5651 - accuracy: 0.7130\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.5693 - accuracy: 0.7017\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5711 - accuracy: 0.6986\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5724 - accuracy: 0.7011\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5796 - accuracy: 0.6955\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5736 - accuracy: 0.6999\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5758 - accuracy: 0.7067\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5633 - accuracy: 0.7111\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5626 - accuracy: 0.7148\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5662 - accuracy: 0.7017\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5599 - accuracy: 0.7111\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5724 - accuracy: 0.7092\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5651 - accuracy: 0.7067\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5616 - accuracy: 0.7098\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5604 - accuracy: 0.7086\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5676 - accuracy: 0.7005\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5646 - accuracy: 0.7105\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5527 - accuracy: 0.7186\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5433 - accuracy: 0.7235\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5717 - accuracy: 0.7154\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5602 - accuracy: 0.7055\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5546 - accuracy: 0.7142\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5649 - accuracy: 0.7105\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5584 - accuracy: 0.7248\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5579 - accuracy: 0.7161\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5663 - accuracy: 0.7167\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5727 - accuracy: 0.7011\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5469 - accuracy: 0.7254\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5478 - accuracy: 0.7167\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5636 - accuracy: 0.7111\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5524 - accuracy: 0.7161\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5609 - accuracy: 0.7042\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5553 - accuracy: 0.7111\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5487 - accuracy: 0.7192\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5583 - accuracy: 0.7136\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5427 - accuracy: 0.7254\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5533 - accuracy: 0.7186\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5503 - accuracy: 0.7055\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5475 - accuracy: 0.7360\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5472 - accuracy: 0.7273\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5577 - accuracy: 0.7142\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5515 - accuracy: 0.7254\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5465 - accuracy: 0.7235\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5514 - accuracy: 0.7217\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5447 - accuracy: 0.7254\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5494 - accuracy: 0.7235\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5513 - accuracy: 0.7229\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5534 - accuracy: 0.7167\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5275 - accuracy: 0.7397\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5442 - accuracy: 0.7248\n",
      "準確率 : 0.6791044776119403\n",
      "Epoch 1/300\n",
      "1606/1606 [==============================] - 2s 1ms/step - loss: 0.8109 - accuracy: 0.5131\n",
      "Epoch 2/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.7545 - accuracy: 0.5486\n",
      "Epoch 3/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7303 - accuracy: 0.5604\n",
      "Epoch 4/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.7203 - accuracy: 0.5716\n",
      "Epoch 5/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7400 - accuracy: 0.5486\n",
      "Epoch 6/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7221 - accuracy: 0.5523\n",
      "Epoch 7/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7171 - accuracy: 0.5629\n",
      "Epoch 8/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7117 - accuracy: 0.5479\n",
      "Epoch 9/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7075 - accuracy: 0.5772\n",
      "Epoch 10/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7030 - accuracy: 0.5760\n",
      "Epoch 11/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.7021 - accuracy: 0.5741\n",
      "Epoch 12/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6987 - accuracy: 0.5915\n",
      "Epoch 13/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6906 - accuracy: 0.5809\n",
      "Epoch 14/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6957 - accuracy: 0.5822\n",
      "Epoch 15/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.7017 - accuracy: 0.5785\n",
      "Epoch 16/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6688 - accuracy: 0.6090\n",
      "Epoch 17/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6903 - accuracy: 0.5809\n",
      "Epoch 18/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6881 - accuracy: 0.5903\n",
      "Epoch 19/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6851 - accuracy: 0.6002\n",
      "Epoch 20/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.7092 - accuracy: 0.5834\n",
      "Epoch 21/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6808 - accuracy: 0.5946\n",
      "Epoch 22/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6925 - accuracy: 0.5915\n",
      "Epoch 23/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6922 - accuracy: 0.5847\n",
      "Epoch 24/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6933 - accuracy: 0.5859\n",
      "Epoch 25/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6807 - accuracy: 0.5915\n",
      "Epoch 26/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6838 - accuracy: 0.6096\n",
      "Epoch 27/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6773 - accuracy: 0.6040\n",
      "Epoch 28/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6853 - accuracy: 0.6083\n",
      "Epoch 29/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6680 - accuracy: 0.6121\n",
      "Epoch 30/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6811 - accuracy: 0.5996\n",
      "Epoch 31/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6827 - accuracy: 0.6021\n",
      "Epoch 32/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6905 - accuracy: 0.6021\n",
      "Epoch 33/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6725 - accuracy: 0.5884\n",
      "Epoch 34/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6808 - accuracy: 0.5984\n",
      "Epoch 35/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6727 - accuracy: 0.5971\n",
      "Epoch 36/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6869 - accuracy: 0.6046\n",
      "Epoch 37/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6722 - accuracy: 0.6083\n",
      "Epoch 38/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6609 - accuracy: 0.6233\n",
      "Epoch 39/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6928 - accuracy: 0.5803\n",
      "Epoch 40/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6745 - accuracy: 0.5990\n",
      "Epoch 41/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6749 - accuracy: 0.6021\n",
      "Epoch 42/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6696 - accuracy: 0.6158\n",
      "Epoch 43/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6679 - accuracy: 0.6034\n",
      "Epoch 44/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6663 - accuracy: 0.6027\n",
      "Epoch 45/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6655 - accuracy: 0.6171\n",
      "Epoch 46/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6624 - accuracy: 0.6090\n",
      "Epoch 47/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6734 - accuracy: 0.6052\n",
      "Epoch 48/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6655 - accuracy: 0.6276\n",
      "Epoch 49/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6619 - accuracy: 0.6220\n",
      "Epoch 50/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6780 - accuracy: 0.6090\n",
      "Epoch 51/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6554 - accuracy: 0.6283\n",
      "Epoch 52/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6703 - accuracy: 0.5965\n",
      "Epoch 53/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6616 - accuracy: 0.6214\n",
      "Epoch 54/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6678 - accuracy: 0.6233\n",
      "Epoch 55/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6632 - accuracy: 0.6177\n",
      "Epoch 56/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6614 - accuracy: 0.6252\n",
      "Epoch 57/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6708 - accuracy: 0.6027\n",
      "Epoch 58/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6544 - accuracy: 0.6320\n",
      "Epoch 59/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6572 - accuracy: 0.6339\n",
      "Epoch 60/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6508 - accuracy: 0.6320\n",
      "Epoch 61/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6561 - accuracy: 0.6208\n",
      "Epoch 62/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6541 - accuracy: 0.6270\n",
      "Epoch 63/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6564 - accuracy: 0.6333\n",
      "Epoch 64/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6505 - accuracy: 0.6320\n",
      "Epoch 65/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6674 - accuracy: 0.6171\n",
      "Epoch 66/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6590 - accuracy: 0.6258\n",
      "Epoch 67/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6522 - accuracy: 0.6183\n",
      "Epoch 68/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6531 - accuracy: 0.6214\n",
      "Epoch 69/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6583 - accuracy: 0.6146\n",
      "Epoch 70/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6667 - accuracy: 0.6102\n",
      "Epoch 71/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6636 - accuracy: 0.6121\n",
      "Epoch 72/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6617 - accuracy: 0.6283\n",
      "Epoch 73/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6503 - accuracy: 0.6301\n",
      "Epoch 74/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6591 - accuracy: 0.6183\n",
      "Epoch 75/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6631 - accuracy: 0.6245\n",
      "Epoch 76/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6570 - accuracy: 0.6245\n",
      "Epoch 77/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6570 - accuracy: 0.6183\n",
      "Epoch 78/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6453 - accuracy: 0.6407\n",
      "Epoch 79/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6550 - accuracy: 0.6333\n",
      "Epoch 80/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6562 - accuracy: 0.6295\n",
      "Epoch 81/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6533 - accuracy: 0.6364\n",
      "Epoch 82/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6420 - accuracy: 0.6389\n",
      "Epoch 83/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6585 - accuracy: 0.6320\n",
      "Epoch 84/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6509 - accuracy: 0.6301\n",
      "Epoch 85/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6437 - accuracy: 0.6333\n",
      "Epoch 86/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6481 - accuracy: 0.6376\n",
      "Epoch 87/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6324 - accuracy: 0.6469\n",
      "Epoch 88/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6605 - accuracy: 0.6264\n",
      "Epoch 89/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6552 - accuracy: 0.6270\n",
      "Epoch 90/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6502 - accuracy: 0.6413\n",
      "Epoch 91/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6483 - accuracy: 0.6333\n",
      "Epoch 92/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6458 - accuracy: 0.6289\n",
      "Epoch 93/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6410 - accuracy: 0.6488\n",
      "Epoch 94/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6528 - accuracy: 0.6295\n",
      "Epoch 95/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6399 - accuracy: 0.6333\n",
      "Epoch 96/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6498 - accuracy: 0.6301\n",
      "Epoch 97/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6340 - accuracy: 0.6158\n",
      "Epoch 98/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6562 - accuracy: 0.6227\n",
      "Epoch 99/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6420 - accuracy: 0.6314\n",
      "Epoch 100/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6437 - accuracy: 0.6333\n",
      "Epoch 101/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6502 - accuracy: 0.6345\n",
      "Epoch 102/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6485 - accuracy: 0.6270\n",
      "Epoch 103/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6418 - accuracy: 0.6438\n",
      "Epoch 104/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6487 - accuracy: 0.6227\n",
      "Epoch 105/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6428 - accuracy: 0.6457\n",
      "Epoch 106/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6385 - accuracy: 0.6407\n",
      "Epoch 107/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6377 - accuracy: 0.6463\n",
      "Epoch 108/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6357 - accuracy: 0.6569\n",
      "Epoch 109/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6372 - accuracy: 0.6401\n",
      "Epoch 110/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6383 - accuracy: 0.6320\n",
      "Epoch 111/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6422 - accuracy: 0.6445\n",
      "Epoch 112/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6353 - accuracy: 0.6407\n",
      "Epoch 113/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6308 - accuracy: 0.6389\n",
      "Epoch 114/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6304 - accuracy: 0.6519\n",
      "Epoch 115/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6265 - accuracy: 0.6494\n",
      "Epoch 116/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6387 - accuracy: 0.6451\n",
      "Epoch 117/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6436 - accuracy: 0.6501\n",
      "Epoch 118/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6376 - accuracy: 0.6382\n",
      "Epoch 119/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6174 - accuracy: 0.6731\n",
      "Epoch 120/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6312 - accuracy: 0.6550\n",
      "Epoch 121/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6303 - accuracy: 0.6594\n",
      "Epoch 122/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6351 - accuracy: 0.6326\n",
      "Epoch 123/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6276 - accuracy: 0.6519\n",
      "Epoch 124/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6407 - accuracy: 0.6395\n",
      "Epoch 125/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6417 - accuracy: 0.6507\n",
      "Epoch 126/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6231 - accuracy: 0.6600\n",
      "Epoch 127/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6347 - accuracy: 0.6494\n",
      "Epoch 128/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6337 - accuracy: 0.6550\n",
      "Epoch 129/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6300 - accuracy: 0.6488\n",
      "Epoch 130/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6181 - accuracy: 0.6606\n",
      "Epoch 131/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6213 - accuracy: 0.6613\n",
      "Epoch 132/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6239 - accuracy: 0.6563\n",
      "Epoch 133/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6213 - accuracy: 0.6606\n",
      "Epoch 134/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.6279 - accuracy: 0.6469\n",
      "Epoch 135/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6219 - accuracy: 0.6650\n",
      "Epoch 136/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6331 - accuracy: 0.6438\n",
      "Epoch 137/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6206 - accuracy: 0.6526\n",
      "Epoch 138/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6211 - accuracy: 0.6606\n",
      "Epoch 139/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6223 - accuracy: 0.6463\n",
      "Epoch 140/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6332 - accuracy: 0.6494\n",
      "Epoch 141/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6185 - accuracy: 0.6588\n",
      "Epoch 142/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6134 - accuracy: 0.6719\n",
      "Epoch 143/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6220 - accuracy: 0.6619\n",
      "Epoch 144/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6164 - accuracy: 0.6681\n",
      "Epoch 145/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6197 - accuracy: 0.6700\n",
      "Epoch 146/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6281 - accuracy: 0.6650\n",
      "Epoch 147/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6183 - accuracy: 0.6600\n",
      "Epoch 148/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6007 - accuracy: 0.6731\n",
      "Epoch 149/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6113 - accuracy: 0.6675\n",
      "Epoch 150/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6234 - accuracy: 0.6532\n",
      "Epoch 151/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6152 - accuracy: 0.6606\n",
      "Epoch 152/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6144 - accuracy: 0.6719\n",
      "Epoch 153/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6268 - accuracy: 0.6575\n",
      "Epoch 154/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6253 - accuracy: 0.6613\n",
      "Epoch 155/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6321 - accuracy: 0.6501\n",
      "Epoch 156/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6181 - accuracy: 0.6619\n",
      "Epoch 157/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6092 - accuracy: 0.6631\n",
      "Epoch 158/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6137 - accuracy: 0.6631\n",
      "Epoch 159/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.6097 - accuracy: 0.6787\n",
      "Epoch 160/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5954 - accuracy: 0.6762\n",
      "Epoch 161/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6003 - accuracy: 0.6725\n",
      "Epoch 162/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6129 - accuracy: 0.6712\n",
      "Epoch 163/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6074 - accuracy: 0.6687\n",
      "Epoch 164/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6072 - accuracy: 0.6700\n",
      "Epoch 165/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6095 - accuracy: 0.6694\n",
      "Epoch 166/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6004 - accuracy: 0.6750\n",
      "Epoch 167/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5942 - accuracy: 0.6737\n",
      "Epoch 168/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6060 - accuracy: 0.6806\n",
      "Epoch 169/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6178 - accuracy: 0.6719\n",
      "Epoch 170/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5947 - accuracy: 0.6843\n",
      "Epoch 171/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6074 - accuracy: 0.6650\n",
      "Epoch 172/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6084 - accuracy: 0.6768\n",
      "Epoch 173/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6103 - accuracy: 0.6669\n",
      "Epoch 174/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5986 - accuracy: 0.6756\n",
      "Epoch 175/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5973 - accuracy: 0.6750\n",
      "Epoch 176/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5997 - accuracy: 0.6737\n",
      "Epoch 177/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6014 - accuracy: 0.6737\n",
      "Epoch 178/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5921 - accuracy: 0.6924\n",
      "Epoch 179/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.6150 - accuracy: 0.6687\n",
      "Epoch 180/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.6008 - accuracy: 0.6737\n",
      "Epoch 181/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6045 - accuracy: 0.6687\n",
      "Epoch 182/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5969 - accuracy: 0.6924\n",
      "Epoch 183/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6045 - accuracy: 0.6831\n",
      "Epoch 184/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5806 - accuracy: 0.6787\n",
      "Epoch 185/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5894 - accuracy: 0.6880\n",
      "Epoch 186/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5940 - accuracy: 0.6887\n",
      "Epoch 187/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.6048 - accuracy: 0.6712\n",
      "Epoch 188/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5898 - accuracy: 0.6924\n",
      "Epoch 189/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5955 - accuracy: 0.6856\n",
      "Epoch 190/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5858 - accuracy: 0.7042\n",
      "Epoch 191/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5921 - accuracy: 0.6818\n",
      "Epoch 192/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5732 - accuracy: 0.6999\n",
      "Epoch 193/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5842 - accuracy: 0.6943\n",
      "Epoch 194/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.6015 - accuracy: 0.6806\n",
      "Epoch 195/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5903 - accuracy: 0.6868\n",
      "Epoch 196/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5934 - accuracy: 0.6862\n",
      "Epoch 197/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.5798 - accuracy: 0.7017\n",
      "Epoch 198/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5890 - accuracy: 0.6887\n",
      "Epoch 199/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5823 - accuracy: 0.7042\n",
      "Epoch 200/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5914 - accuracy: 0.7017\n",
      "Epoch 201/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5857 - accuracy: 0.6880\n",
      "Epoch 202/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5719 - accuracy: 0.7173\n",
      "Epoch 203/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5880 - accuracy: 0.6930\n",
      "Epoch 204/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5784 - accuracy: 0.6924\n",
      "Epoch 205/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5834 - accuracy: 0.6849\n",
      "Epoch 206/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5873 - accuracy: 0.6912\n",
      "Epoch 207/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5936 - accuracy: 0.6831\n",
      "Epoch 208/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5766 - accuracy: 0.7086\n",
      "Epoch 209/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5726 - accuracy: 0.7061\n",
      "Epoch 210/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5747 - accuracy: 0.7123\n",
      "Epoch 211/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5750 - accuracy: 0.7073\n",
      "Epoch 212/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5937 - accuracy: 0.6849\n",
      "Epoch 213/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5763 - accuracy: 0.6980\n",
      "Epoch 214/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5736 - accuracy: 0.7005\n",
      "Epoch 215/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5554 - accuracy: 0.7267\n",
      "Epoch 216/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5717 - accuracy: 0.7042\n",
      "Epoch 217/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5804 - accuracy: 0.7011\n",
      "Epoch 218/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5805 - accuracy: 0.6930\n",
      "Epoch 219/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5624 - accuracy: 0.7080\n",
      "Epoch 220/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5698 - accuracy: 0.7136\n",
      "Epoch 221/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5535 - accuracy: 0.7298\n",
      "Epoch 222/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5712 - accuracy: 0.7042\n",
      "Epoch 223/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5858 - accuracy: 0.7011\n",
      "Epoch 224/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5701 - accuracy: 0.7049\n",
      "Epoch 225/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5654 - accuracy: 0.7011\n",
      "Epoch 226/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5585 - accuracy: 0.7161\n",
      "Epoch 227/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5674 - accuracy: 0.7036\n",
      "Epoch 228/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5664 - accuracy: 0.7092\n",
      "Epoch 229/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5637 - accuracy: 0.7186\n",
      "Epoch 230/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5741 - accuracy: 0.7123\n",
      "Epoch 231/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5747 - accuracy: 0.7030\n",
      "Epoch 232/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5666 - accuracy: 0.7123\n",
      "Epoch 233/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5788 - accuracy: 0.7011\n",
      "Epoch 234/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5724 - accuracy: 0.7080\n",
      "Epoch 235/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5631 - accuracy: 0.7080\n",
      "Epoch 236/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5655 - accuracy: 0.7117\n",
      "Epoch 237/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5570 - accuracy: 0.7148\n",
      "Epoch 238/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5669 - accuracy: 0.7123\n",
      "Epoch 239/300\n",
      "1606/1606 [==============================] - 1s 340us/step - loss: 0.5531 - accuracy: 0.7130\n",
      "Epoch 240/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5572 - accuracy: 0.7148\n",
      "Epoch 241/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5598 - accuracy: 0.7130\n",
      "Epoch 242/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5551 - accuracy: 0.7154\n",
      "Epoch 243/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5717 - accuracy: 0.6961\n",
      "Epoch 244/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5599 - accuracy: 0.7011\n",
      "Epoch 245/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5641 - accuracy: 0.7198\n",
      "Epoch 246/300\n",
      "1606/1606 [==============================] - 1s 347us/step - loss: 0.5524 - accuracy: 0.7260\n",
      "Epoch 247/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5638 - accuracy: 0.7086\n",
      "Epoch 248/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5554 - accuracy: 0.7235\n",
      "Epoch 249/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5545 - accuracy: 0.7173\n",
      "Epoch 250/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5504 - accuracy: 0.7260\n",
      "Epoch 251/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5545 - accuracy: 0.7204\n",
      "Epoch 252/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5494 - accuracy: 0.7173\n",
      "Epoch 253/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5648 - accuracy: 0.7154\n",
      "Epoch 254/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5472 - accuracy: 0.7186\n",
      "Epoch 255/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5583 - accuracy: 0.7248\n",
      "Epoch 256/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5414 - accuracy: 0.7267\n",
      "Epoch 257/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5527 - accuracy: 0.7198\n",
      "Epoch 258/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5509 - accuracy: 0.7329\n",
      "Epoch 259/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5488 - accuracy: 0.7310\n",
      "Epoch 260/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5600 - accuracy: 0.7217\n",
      "Epoch 261/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5426 - accuracy: 0.7229\n",
      "Epoch 262/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5492 - accuracy: 0.7329\n",
      "Epoch 263/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5395 - accuracy: 0.7391\n",
      "Epoch 264/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5495 - accuracy: 0.7217\n",
      "Epoch 265/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5413 - accuracy: 0.7285\n",
      "Epoch 266/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5321 - accuracy: 0.7310\n",
      "Epoch 267/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5381 - accuracy: 0.7329\n",
      "Epoch 268/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5371 - accuracy: 0.7273\n",
      "Epoch 269/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5435 - accuracy: 0.7323\n",
      "Epoch 270/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5363 - accuracy: 0.7248\n",
      "Epoch 271/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5423 - accuracy: 0.7329\n",
      "Epoch 272/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5358 - accuracy: 0.7347\n",
      "Epoch 273/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5360 - accuracy: 0.7410\n",
      "Epoch 274/300\n",
      "1606/1606 [==============================] - 1s 346us/step - loss: 0.5297 - accuracy: 0.7273\n",
      "Epoch 275/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5311 - accuracy: 0.7379\n",
      "Epoch 276/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5379 - accuracy: 0.7279\n",
      "Epoch 277/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5303 - accuracy: 0.7310\n",
      "Epoch 278/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5412 - accuracy: 0.7354\n",
      "Epoch 279/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5308 - accuracy: 0.7366\n",
      "Epoch 280/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5378 - accuracy: 0.7391\n",
      "Epoch 281/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5154 - accuracy: 0.7547\n",
      "Epoch 282/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5394 - accuracy: 0.7285\n",
      "Epoch 283/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5253 - accuracy: 0.7285\n",
      "Epoch 284/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5255 - accuracy: 0.7466\n",
      "Epoch 285/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5274 - accuracy: 0.7422\n",
      "Epoch 286/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5177 - accuracy: 0.7559\n",
      "Epoch 287/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5155 - accuracy: 0.7422\n",
      "Epoch 288/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5259 - accuracy: 0.7478\n",
      "Epoch 289/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5208 - accuracy: 0.7484\n",
      "Epoch 290/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5200 - accuracy: 0.7478\n",
      "Epoch 291/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5135 - accuracy: 0.7447\n",
      "Epoch 292/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5229 - accuracy: 0.7310\n",
      "Epoch 293/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5112 - accuracy: 0.7547\n",
      "Epoch 294/300\n",
      "1606/1606 [==============================] - 1s 345us/step - loss: 0.5112 - accuracy: 0.7565\n",
      "Epoch 295/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5087 - accuracy: 0.7522\n",
      "Epoch 296/300\n",
      "1606/1606 [==============================] - 1s 342us/step - loss: 0.5131 - accuracy: 0.7572\n",
      "Epoch 297/300\n",
      "1606/1606 [==============================] - 1s 341us/step - loss: 0.5090 - accuracy: 0.7466\n",
      "Epoch 298/300\n",
      "1606/1606 [==============================] - 1s 343us/step - loss: 0.5089 - accuracy: 0.7565\n",
      "Epoch 299/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5091 - accuracy: 0.7590\n",
      "Epoch 300/300\n",
      "1606/1606 [==============================] - 1s 344us/step - loss: 0.5064 - accuracy: 0.7584\n",
      "準確率 : 0.6890547263681592\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\n",
    "optimizers = adam\n",
    "kernel_init = 'glorot_uniform'\n",
    "recurrent_init = 'glorot_uniform'\n",
    "bias_init ='zero'\n",
    "epochs = 300\n",
    "batches = 80\n",
    "\n",
    "r_count = 1\n",
    "result = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    model_LSTM = create_LSTM_model(optimizer=optimizers, batch_size=batches, kernel_init=kernel_init, \n",
    "                 recurrent_init=recurrent_init, bias_init=bias_init)\n",
    "\n",
    "    history = model_LSTM.fit(_X_train,_y_train,\n",
    "                             epochs=epochs,\n",
    "                             batch_size=batches)\n",
    "\n",
    "\n",
    "    preds = model_LSTM.predict(X_test_std)\n",
    "    actuals = y_test\n",
    "\n",
    "    #格式轉換\n",
    "    change_pred = []\n",
    "    for i in range(len(preds)):\n",
    "        if(preds[i][0]>0.5):\n",
    "            change_pred.append(1)\n",
    "        else:\n",
    "            change_pred.append(0)\n",
    "\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(actuals,change_pred)\n",
    "    print(\"準確率 : \" + str(accuracy))\n",
    "\n",
    "    #如果準確率>70，則將model及loss圖保存下來\n",
    "    if (accuracy > 0.69):\n",
    "        result.append(accuracy)\n",
    "        model_LSTM.save('KLSTM'+str(r_count)+'.h5')\n",
    "        \n",
    "\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.title('model train loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train'], loc='upper right')\n",
    "        plt.savefig('plot'+str(r_count)+'.png')   \n",
    "        plt.show()\n",
    "        \n",
    "        r_count+=1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7562189054726368,\n",
       " 0.746268656716418,\n",
       " 0.6691542288557214,\n",
       " 0.681592039800995,\n",
       " 0.6716417910447762]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
